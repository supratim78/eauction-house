2022-05-06 05:15:05,077 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 05:15:05,077 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Error sending fetch request (sessionId=2022425543, epoch=8760) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 05:15:05,222 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 05:15:07,073 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2-1e6cc21b-b783-4d91-b6ba-f77e44b936e4', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 05:15:07,073 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 05:15:07,074 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 05:15:07,074 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 05:15:07,074 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 05:15:07,075 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 05:15:07,661 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 05:15:07,662 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] (Re-)joining group
2022-05-06 05:15:07,725 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Request joining group due to: need to re-join with the given member-id
2022-05-06 05:15:07,726 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] (Re-)joining group
2022-05-06 05:15:08,947 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2-d0dac9b2-12f0-4670-9c64-88ecef817c44', protocol='range'}
2022-05-06 05:15:08,948 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Finished assignment for group at generation 3: {consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2-d0dac9b2-12f0-4670-9c64-88ecef817c44=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 05:15:09,028 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2-d0dac9b2-12f0-4670-9c64-88ecef817c44', protocol='range'}
2022-05-06 05:15:09,029 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 05:15:09,029 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 05:15:09,032 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db-2, groupId=anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 05:15:09,033 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.6a15829c-ce20-4ea0-b2a5-54c1ab49e2db: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 05:15:12,366 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:20:11,263 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:25:11,280 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:30:11,294 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:35:11,303 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:40:11,307 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:45:11,316 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:50:11,325 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 05:55:11,333 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:00:11,349 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:05:11,362 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:10:11,366 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:15:11,381 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:20:11,388 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:25:11,403 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:30:11,412 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:35:11,426 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:40:11,437 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:45:11,445 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:47:46,839 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 25300 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 06:47:46,839 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 06:47:46,841 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 06:47:46,874 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 06:47:46,874 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 06:47:46,875 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 06:47:46,875 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 06:47:47,385 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 06:47:47,491 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 102 ms. Found 2 MongoDB repository interfaces.
2022-05-06 06:47:47,644 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 06:47:47,652 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 06:47:47,731 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0bb76835-eaf6-3b0e-8d90-3792fddf88bb
2022-05-06 06:47:47,788 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 06:47:47,842 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 06:47:48,388 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 06:47:48,398 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 06:47:48,398 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 06:47:48,398 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 06:47:48,498 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 06:47:48,499 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1623 ms
2022-05-06 06:47:48,630 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 06:47:48,688 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6274773c0aae22376c9b3db6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:29}] to localhost:27017
2022-05-06 06:47:48,688 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6274773c0aae22376c9b3db6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:30}] to localhost:27017
2022-05-06 06:47:48,689 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6274773c0aae22376c9b3db6', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19391700}
2022-05-06 06:47:48,723 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 06:47:48,773 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 06:47:48,804 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 06:47:49,411 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 06:47:49,533 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 06:47:49,546 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 06:47:49,642 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 06:47:49,645 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 06:47:49,646 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 06:47:49,646 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 06:47:49,652 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 06:47:49,748 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 06:47:49,752 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 06:47:49,782 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 06:47:49,782 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 06:47:49,782 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 06:47:49,783 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 06:47:49,783 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 06:47:49,783 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 06:47:49,783 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 06:47:49,982 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 06:47:49,990 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 06:47:49,997 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 06:47:50,012 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651799870011 with initial instances count: 4
2022-05-06 06:47:50,013 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 06:47:50,013 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651799870013, current=UP, previous=STARTING]
2022-05-06 06:47:50,014 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 06:47:50,015 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 06:47:50,046 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 06:47:50,080 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 06:47:50,080 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 06:47:50,081 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 06:47:50,124 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 06:47:50,124 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 06:47:50,124 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 06:47:50,139 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 06:47:50,139 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 06:47:50,139 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 06:47:50,158 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 06:47:50,158 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 06:47:50,158 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 06:47:50,222 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 06:47:50,306 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:47:50,306 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:47:50,306 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651799870304
2022-05-06 06:47:50,714 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 06:47:50,718 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 06:47:50,719 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 06:47:50,719 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 06:47:50,732 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 06:47:50,769 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:47:50,770 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:47:50,770 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651799870769
2022-05-06 06:47:50,778 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-1, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 06:47:50,779 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-1, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 06:47:50,779 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-1, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 06:47:50,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 06:47:50,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 06:47:50,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 06:47:50,782 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-1 unregistered
2022-05-06 06:47:50,803 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec.errors' has 1 subscriber(s).
2022-05-06 06:47:50,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec.errors' has 0 subscriber(s).
2022-05-06 06:47:50,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec.errors' has 1 subscriber(s).
2022-05-06 06:47:50,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec.errors' has 2 subscriber(s).
2022-05-06 06:47:50,819 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 06:47:50,824 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:47:50,824 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:47:50,824 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651799870824
2022-05-06 06:47:50,825 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 06:47:50,829 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@306dcce0
2022-05-06 06:47:50,830 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 06:47:50,837 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 06:47:50,837 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 06:47:50,839 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 06:47:50,840 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 06:47:50,856 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 06:47:50,858 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] (Re-)joining group
2022-05-06 06:47:50,914 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.118 seconds (JVM running for 5.622)
2022-05-06 06:47:50,920 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Request joining group due to: need to re-join with the given member-id
2022-05-06 06:47:50,920 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] (Re-)joining group
2022-05-06 06:47:50,943 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2-26734adc-f0d1-4ba9-9f1f-6a75e826a5f4', protocol='range'}
2022-05-06 06:47:50,945 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Finished assignment for group at generation 1: {consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2-26734adc-f0d1-4ba9-9f1f-6a75e826a5f4=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 06:47:51,051 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2-26734adc-f0d1-4ba9-9f1f-6a75e826a5f4', protocol='range'}
2022-05-06 06:47:51,051 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 06:47:51,054 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 06:47:51,073 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 06:47:51,077 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 06:47:51,099 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec-2, groupId=anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 06:47:51,127 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.abbad234-05fa-4d4c-8bfb-e70ebdbc2cec: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 06:48:01,972 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=38, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=null, bidEndDate=2022-10-10, sellerId=37]
2022-05-06 06:48:02,034 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:31}] to localhost:27017
2022-05-06 06:52:49,796 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:57:49,807 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 06:58:30,517 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 06:58:30,525 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 24152 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 06:58:30,526 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 06:58:30,568 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 06:58:30,568 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 06:58:30,569 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 06:58:30,569 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 06:58:31,116 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 06:58:31,210 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 92 ms. Found 2 MongoDB repository interfaces.
2022-05-06 06:58:31,370 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 06:58:31,378 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 06:58:31,453 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0bb76835-eaf6-3b0e-8d90-3792fddf88bb
2022-05-06 06:58:31,506 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 06:58:31,567 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 06:58:32,084 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 06:58:32,095 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 06:58:32,095 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 06:58:32,095 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 06:58:32,198 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 06:58:32,198 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1628 ms
2022-05-06 06:58:32,332 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 06:58:32,400 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627479c0b84d174a58d07b2c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:44}] to localhost:27017
2022-05-06 06:58:32,400 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627479c0b84d174a58d07b2c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:45}] to localhost:27017
2022-05-06 06:58:32,400 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627479c0b84d174a58d07b2c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=21172800}
2022-05-06 06:58:32,438 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 06:58:32,520 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 06:58:32,557 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 06:58:33,328 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 06:58:33,525 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 06:58:33,550 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 06:58:33,692 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 06:58:33,696 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 06:58:33,696 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 06:58:33,696 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 06:58:33,707 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 06:58:33,816 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 06:58:33,824 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 06:58:33,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 06:58:33,860 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 06:58:34,118 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 06:58:34,125 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 06:58:34,132 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 06:58:34,146 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651800514145 with initial instances count: 4
2022-05-06 06:58:34,147 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 06:58:34,147 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651800514147, current=UP, previous=STARTING]
2022-05-06 06:58:34,149 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 06:58:34,150 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 06:58:34,184 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 06:58:34,218 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 06:58:34,218 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 06:58:34,219 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 06:58:34,276 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 06:58:34,276 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 06:58:34,277 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 06:58:34,302 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 06:58:34,302 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 06:58:34,302 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 06:58:34,329 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 06:58:34,329 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 06:58:34,329 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 06:58:34,393 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 06:58:34,482 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:58:34,483 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:58:34,483 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651800514481
2022-05-06 06:58:34,867 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 06:58:34,872 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 06:58:34,872 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 06:58:34,873 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 06:58:34,885 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 06:58:34,929 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:58:34,929 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:58:34,929 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651800514929
2022-05-06 06:58:34,940 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-1, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 06:58:34,940 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-1, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 06:58:34,940 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-1, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 06:58:34,941 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 06:58:34,941 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 06:58:34,941 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 06:58:34,942 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-1 unregistered
2022-05-06 06:58:34,965 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded.errors' has 1 subscriber(s).
2022-05-06 06:58:34,965 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded.errors' has 0 subscriber(s).
2022-05-06 06:58:34,965 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded.errors' has 1 subscriber(s).
2022-05-06 06:58:34,965 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded.errors' has 2 subscriber(s).
2022-05-06 06:58:34,989 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 06:58:34,996 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 06:58:34,996 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 06:58:34,996 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651800514996
2022-05-06 06:58:34,998 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 06:58:35,006 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@45077863
2022-05-06 06:58:35,009 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 06:58:35,017 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 06:58:35,018 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 06:58:35,019 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 06:58:35,020 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] (Re-)joining group
2022-05-06 06:58:35,028 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 06:58:35,029 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 06:58:35,053 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Request joining group due to: need to re-join with the given member-id
2022-05-06 06:58:35,054 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] (Re-)joining group
2022-05-06 06:58:35,059 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-b76c299b-3d33-497f-abbc-5ea0d99cbd5c', protocol='range'}
2022-05-06 06:58:35,061 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Finished assignment for group at generation 1: {consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-b76c299b-3d33-497f-abbc-5ea0d99cbd5c=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 06:58:35,070 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-b76c299b-3d33-497f-abbc-5ea0d99cbd5c', protocol='range'}
2022-05-06 06:58:35,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 06:58:35,077 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 06:58:35,083 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 06:58:35,088 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 06:58:35,101 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=19, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 06:58:35,110 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 06:58:35,181 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.724 seconds (JVM running for 6.248)
2022-05-06 06:58:59,201 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=39, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=null, bidEndDate=2022-10-10, sellerId=38]
2022-05-06 06:58:59,347 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:46}] to localhost:27017
2022-05-06 07:03:33,868 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:05:03,824 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=40, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=null, bidEndDate=2022-10-10, sellerId=39]
2022-05-06 07:06:10,603 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=41, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=100, bidEndDate=2022-10-10, sellerId=40]
2022-05-06 07:08:33,877 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:13:33,886 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:18:33,888 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:23:33,904 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:28:33,921 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 07:33:33,926 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 08:19:22,502 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 08:19:22,685 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Error sending fetch request (sessionId=1161275151, epoch=4582) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 08:19:23,629 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 08:19:23,651 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 08:19:23,739 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 08:19:24,140 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-b76c299b-3d33-497f-abbc-5ea0d99cbd5c', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 08:19:24,145 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 08:19:24,158 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 08:19:24,158 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 08:19:24,164 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 08:19:24,213 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 08:19:24,221 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 08:19:24,230 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] (Re-)joining group
2022-05-06 08:19:24,563 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Request joining group due to: need to re-join with the given member-id
2022-05-06 08:19:24,564 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] (Re-)joining group
2022-05-06 08:19:24,619 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-787916f8-1bd4-457b-82fa-6641159bd833', protocol='range'}
2022-05-06 08:19:24,621 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Finished assignment for group at generation 3: {consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-787916f8-1bd4-457b-82fa-6641159bd833=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 08:19:25,137 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2-787916f8-1bd4-457b-82fa-6641159bd833', protocol='range'}
2022-05-06 08:19:25,138 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 08:19:25,139 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 08:19:25,503 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded-2, groupId=anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 08:19:25,505 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.f3a1c5b7-20f7-4835-8c85-18cd5d72eded: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 08:20:10,511 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 08:25:10,521 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 08:30:10,525 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 08:35:10,537 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 08:40:12,602 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 23648 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 08:40:12,602 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 08:40:12,604 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 08:40:12,640 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 08:40:12,641 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 08:40:12,642 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 08:40:12,643 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 08:40:13,183 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 08:40:13,279 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 92 ms. Found 3 MongoDB repository interfaces.
2022-05-06 08:40:13,441 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 08:40:13,449 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 08:40:13,532 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=3b2ca7b7-17b9-311a-96cc-b3aec1ef2582
2022-05-06 08:40:13,584 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:40:13,635 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:40:14,246 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 08:40:14,261 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 08:40:14,262 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 08:40:14,262 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 08:40:14,375 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 08:40:14,375 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1732 ms
2022-05-06 08:40:14,502 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 08:40:14,583 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749196cb60c2448e7f3fb8', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:54}] to localhost:27017
2022-05-06 08:40:14,583 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62749196cb60c2448e7f3fb8', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:53}] to localhost:27017
2022-05-06 08:40:14,584 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749196cb60c2448e7f3fb8', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=24402500}
2022-05-06 08:40:14,621 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:40:14,668 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 08:40:14,701 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:40:14,799 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'eauctionHouseListingServiceApplication': Unsatisfied dependency expressed through field 'bidService'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.cts.eauction.microservices.listing.bid.service.BidService' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}
2022-05-06 08:40:14,804 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-06 08:40:14,816 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-06 08:40:14,833 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field bidService in com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication required a bean of type 'com.cts.eauction.microservices.listing.bid.service.BidService' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'com.cts.eauction.microservices.listing.bid.service.BidService' in your configuration.

2022-05-06 08:41:56,678 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 08:41:56,683 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 25488 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 08:41:56,684 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 08:41:56,717 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 08:41:56,717 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 08:41:56,718 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 08:41:56,719 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 08:41:57,203 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 08:41:57,311 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 105 ms. Found 3 MongoDB repository interfaces.
2022-05-06 08:41:57,466 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 08:41:57,474 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 08:41:57,552 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 08:41:57,606 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:41:57,650 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:41:58,037 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 08:41:58,045 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 08:41:58,046 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 08:41:58,046 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 08:41:58,136 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 08:41:58,136 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1417 ms
2022-05-06 08:41:58,237 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 08:41:58,285 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627491febbb13d38cd04dfc6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:56}] to localhost:27017
2022-05-06 08:41:58,285 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627491febbb13d38cd04dfc6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:55}] to localhost:27017
2022-05-06 08:41:58,286 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627491febbb13d38cd04dfc6', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16652500}
2022-05-06 08:41:58,313 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:41:58,358 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 08:41:58,388 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:41:58,971 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 08:41:59,104 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 08:41:59,118 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 08:41:59,210 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 08:41:59,213 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 08:41:59,213 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 08:41:59,214 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 08:41:59,218 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 08:41:59,315 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 08:41:59,320 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 08:41:59,353 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 08:41:59,540 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 08:41:59,546 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 08:41:59,553 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 08:41:59,568 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651806719566 with initial instances count: 6
2022-05-06 08:41:59,570 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 08:41:59,570 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651806719570, current=UP, previous=STARTING]
2022-05-06 08:41:59,571 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 08:41:59,572 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 08:41:59,602 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 08:41:59,630 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 08:41:59,631 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 08:41:59,631 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 08:41:59,669 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 08:41:59,669 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 08:41:59,669 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 08:41:59,684 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 08:41:59,684 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 08:41:59,684 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 08:41:59,711 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 08:41:59,711 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 08:41:59,712 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 08:41:59,759 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 08:41:59,851 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:41:59,852 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:41:59,852 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806719851
2022-05-06 08:42:00,249 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 08:42:00,252 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 08:42:00,252 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 08:42:00,252 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 08:42:00,266 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 08:42:00,307 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:42:00,307 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:42:00,307 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806720307
2022-05-06 08:42:00,315 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-1, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 08:42:00,316 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-1, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 08:42:00,316 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-1, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 08:42:00,317 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 08:42:00,317 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 08:42:00,317 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 08:42:00,319 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-1 unregistered
2022-05-06 08:42:00,340 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9.errors' has 1 subscriber(s).
2022-05-06 08:42:00,340 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9.errors' has 0 subscriber(s).
2022-05-06 08:42:00,341 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9.errors' has 1 subscriber(s).
2022-05-06 08:42:00,341 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9.errors' has 2 subscriber(s).
2022-05-06 08:42:00,359 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 08:42:00,365 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:42:00,365 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:42:00,365 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806720365
2022-05-06 08:42:00,366 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 08:42:00,369 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1fd416b0
2022-05-06 08:42:00,370 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 08:42:00,379 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 08:42:00,380 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 08:42:00,381 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 08:42:00,383 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] (Re-)joining group
2022-05-06 08:42:00,385 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 08:42:00,386 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 08:42:00,399 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Request joining group due to: need to re-join with the given member-id
2022-05-06 08:42:00,399 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] (Re-)joining group
2022-05-06 08:42:00,406 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2-f62193c9-a93a-4758-8c93-508547338d4e', protocol='range'}
2022-05-06 08:42:00,409 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Finished assignment for group at generation 1: {consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2-f62193c9-a93a-4758-8c93-508547338d4e=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 08:42:00,421 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2-f62193c9-a93a-4758-8c93-508547338d4e', protocol='range'}
2022-05-06 08:42:00,421 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 08:42:00,423 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 08:42:00,429 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 08:42:00,432 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 08:42:00,442 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9-2, groupId=anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 08:42:00,453 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.f19223b3-956c-4af5-ae0b-eec09116c1f9: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 08:42:00,473 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.785 seconds (JVM running for 5.27)
2022-05-06 08:43:59,670 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 08:43:59,674 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 17312 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 08:43:59,675 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 08:43:59,707 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 08:43:59,708 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 08:43:59,709 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 08:43:59,709 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 08:44:00,225 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 08:44:00,317 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 88 ms. Found 3 MongoDB repository interfaces.
2022-05-06 08:44:00,484 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 08:44:00,493 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 08:44:00,577 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 08:44:00,631 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:44:00,676 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:44:01,078 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 08:44:01,086 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 08:44:01,086 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 08:44:01,086 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 08:44:01,177 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 08:44:01,178 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1469 ms
2022-05-06 08:44:01,280 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 08:44:01,330 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62749279f94a8422a11f19a2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:57}] to localhost:27017
2022-05-06 08:44:01,330 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749279f94a8422a11f19a2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:58}] to localhost:27017
2022-05-06 08:44:01,330 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749279f94a8422a11f19a2', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15625400}
2022-05-06 08:44:01,361 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:44:01,412 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 08:44:01,441 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:44:02,049 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 08:44:02,171 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 08:44:02,186 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 08:44:02,282 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 08:44:02,285 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 08:44:02,285 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 08:44:02,285 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 08:44:02,292 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 08:44:02,364 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 08:44:02,368 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 08:44:02,396 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 08:44:02,396 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 08:44:02,396 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 08:44:02,397 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 08:44:02,397 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 08:44:02,397 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 08:44:02,397 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 08:44:02,559 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 08:44:02,565 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 08:44:02,573 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 08:44:02,587 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651806842586 with initial instances count: 6
2022-05-06 08:44:02,588 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 08:44:02,588 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651806842588, current=UP, previous=STARTING]
2022-05-06 08:44:02,589 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 08:44:02,590 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 08:44:02,618 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 08:44:02,641 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 08:44:02,642 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 08:44:02,642 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 08:44:02,679 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 08:44:02,679 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 08:44:02,680 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 08:44:02,697 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 08:44:02,697 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 08:44:02,697 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 08:44:02,725 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 08:44:02,725 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 08:44:02,725 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 08:44:02,776 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 08:44:02,827 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:44:02,827 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:44:02,827 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806842826
2022-05-06 08:44:03,058 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 08:44:03,062 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 08:44:03,062 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 08:44:03,062 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 08:44:03,075 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 08:44:03,111 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:44:03,112 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:44:03,112 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806843111
2022-05-06 08:44:03,119 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-1, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 08:44:03,120 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-1, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 08:44:03,120 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-1, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 08:44:03,121 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 08:44:03,121 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 08:44:03,121 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 08:44:03,122 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-1 unregistered
2022-05-06 08:44:03,139 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e.errors' has 1 subscriber(s).
2022-05-06 08:44:03,140 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e.errors' has 0 subscriber(s).
2022-05-06 08:44:03,140 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e.errors' has 1 subscriber(s).
2022-05-06 08:44:03,140 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e.errors' has 2 subscriber(s).
2022-05-06 08:44:03,156 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 08:44:03,162 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 08:44:03,162 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 08:44:03,162 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651806843162
2022-05-06 08:44:03,163 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 08:44:03,167 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@57efef91
2022-05-06 08:44:03,169 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 08:44:03,175 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 08:44:03,175 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 08:44:03,176 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 08:44:03,178 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 08:44:03,178 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] (Re-)joining group
2022-05-06 08:44:03,178 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 08:44:03,193 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Request joining group due to: need to re-join with the given member-id
2022-05-06 08:44:03,194 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] (Re-)joining group
2022-05-06 08:44:03,197 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2-d56c558a-05d2-4af0-bd57-e4a2f968d956', protocol='range'}
2022-05-06 08:44:03,200 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Finished assignment for group at generation 1: {consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2-d56c558a-05d2-4af0-bd57-e4a2f968d956=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 08:44:03,209 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2-d56c558a-05d2-4af0-bd57-e4a2f968d956', protocol='range'}
2022-05-06 08:44:03,210 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 08:44:03,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 08:44:03,219 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 08:44:03,224 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 08:44:03,232 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e-2, groupId=anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 08:44:03,238 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.18a26030-0677-4426-bd1f-be79b2dd6a0e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 08:44:03,260 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.594 seconds (JVM running for 5.076)
2022-05-06 08:48:15,356 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 25080 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 08:48:15,357 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 08:48:15,359 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 08:48:15,391 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 08:48:15,391 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 08:48:15,392 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 08:48:15,393 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 08:48:15,861 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 08:48:15,965 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 100 ms. Found 3 MongoDB repository interfaces.
2022-05-06 08:48:16,126 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 08:48:16,135 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 08:48:16,211 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 08:48:16,266 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:48:16,325 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 08:48:16,789 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 08:48:16,800 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 08:48:16,800 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 08:48:16,801 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 08:48:16,902 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 08:48:16,903 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1510 ms
2022-05-06 08:48:17,006 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 08:48:17,058 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627493794b32ea3c6faeceaf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:59}] to localhost:27017
2022-05-06 08:48:17,058 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627493794b32ea3c6faeceaf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:60}] to localhost:27017
2022-05-06 08:48:17,058 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627493794b32ea3c6faeceaf', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15737500}
2022-05-06 08:48:17,087 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:48:17,130 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 08:48:17,161 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 08:48:17,730 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 08:48:17,867 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 08:48:17,880 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 08:48:17,978 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 08:48:17,979 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'input_bid' available
2022-05-06 08:48:17,986 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-06 08:48:17,998 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-06 08:48:18,014 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

A component required a bean named 'input_bid' that could not be found.


Action:

Consider defining a bean named 'input_bid' in your configuration.

2022-05-06 09:07:41,370 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 09:07:41,373 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 21036 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 09:07:41,374 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 09:07:41,406 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 09:07:41,406 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 09:07:41,407 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 09:07:41,408 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 09:07:41,889 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 09:07:41,988 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 96 ms. Found 3 MongoDB repository interfaces.
2022-05-06 09:07:42,161 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 09:07:42,173 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 09:07:42,251 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=730b88f4-1d33-3a02-b532-ad24823fe279
2022-05-06 09:07:42,303 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 09:07:42,358 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 09:07:42,736 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 09:07:42,743 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 09:07:42,743 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 09:07:42,743 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 09:07:42,831 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 09:07:42,831 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1423 ms
2022-05-06 09:07:42,967 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 09:07:43,032 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749806a7d42415adf24630', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:64}] to localhost:27017
2022-05-06 09:07:43,032 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62749806a7d42415adf24630', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:63}] to localhost:27017
2022-05-06 09:07:43,032 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62749806a7d42415adf24630', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19987500}
2022-05-06 09:07:43,067 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 09:07:43,113 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 09:07:43,145 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 09:07:43,736 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 09:07:43,862 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 09:07:43,875 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 09:07:43,971 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bid_input' has 1 subscriber(s).
2022-05-06 09:07:43,975 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 09:07:43,975 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 09:07:43,975 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 09:07:43,980 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 09:07:44,051 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 09:07:44,057 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 09:07:44,085 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 09:07:44,085 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 09:07:44,085 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 09:07:44,085 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 09:07:44,085 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 09:07:44,086 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 09:07:44,086 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 09:07:44,241 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 09:07:44,247 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 09:07:44,253 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 09:07:44,268 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651808264267 with initial instances count: 6
2022-05-06 09:07:44,269 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 09:07:44,269 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651808264269, current=UP, previous=STARTING]
2022-05-06 09:07:44,270 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 09:07:44,270 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 09:07:44,303 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 09:07:44,334 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 09:07:44,335 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 09:07:44,335 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 09:07:44,385 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 09:07:44,386 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 09:07:44,386 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 09:07:44,402 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 09:07:44,402 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 09:07:44,402 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 09:07:44,421 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 09:07:44,421 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 09:07:44,421 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 09:07:44,471 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 09:07:44,544 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:44,545 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:44,545 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808264544
2022-05-06 09:07:45,026 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 09:07:45,030 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 09:07:45,030 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 09:07:45,030 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 09:07:45,043 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5321c95c-bae2-4993-9848-199466970748
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 09:07:45,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:45,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:45,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808265084
2022-05-06 09:07:45,095 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-1, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 09:07:45,097 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-1, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 09:07:45,097 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-1, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 09:07:45,098 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 09:07:45,098 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 09:07:45,098 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 09:07:45,099 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-1 unregistered
2022-05-06 09:07:45,117 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5321c95c-bae2-4993-9848-199466970748.errors' has 1 subscriber(s).
2022-05-06 09:07:45,118 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5321c95c-bae2-4993-9848-199466970748.errors' has 0 subscriber(s).
2022-05-06 09:07:45,118 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5321c95c-bae2-4993-9848-199466970748.errors' has 1 subscriber(s).
2022-05-06 09:07:45,118 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5321c95c-bae2-4993-9848-199466970748.errors' has 2 subscriber(s).
2022-05-06 09:07:45,133 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5321c95c-bae2-4993-9848-199466970748
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 09:07:45,138 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:45,139 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:45,139 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808265138
2022-05-06 09:07:45,140 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 09:07:45,142 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@633286
2022-05-06 09:07:45,144 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 09:07:45,144 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 09:07:45,144 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 09:07:45,144 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 09:07:45,144 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 09:07:45,145 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 09:07:45,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:45,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:45,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808265149
2022-05-06 09:07:45,153 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 09:07:45,154 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 09:07:45,163 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-06 09:07:45,165 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-06 09:07:45,165 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 09:07:45,166 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-06 09:07:45,166 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 09:07:45,167 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 09:07:45,168 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] (Re-)joining group
2022-05-06 09:07:45,173 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:45,173 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:45,173 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808265173
2022-05-06 09:07:45,177 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-3, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 09:07:45,178 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-3, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 09:07:45,178 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-3, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 09:07:45,178 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 09:07:45,179 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 09:07:45,179 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 09:07:45,180 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-3 unregistered
2022-05-06 09:07:45,181 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f.errors' has 1 subscriber(s).
2022-05-06 09:07:45,181 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f.errors' has 0 subscriber(s).
2022-05-06 09:07:45,182 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f.errors' has 1 subscriber(s).
2022-05-06 09:07:45,182 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f.errors' has 2 subscriber(s).
2022-05-06 09:07:45,182 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 09:07:45,188 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 09:07:45,190 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 09:07:45,190 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651808265188
2022-05-06 09:07:45,190 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 09:07:45,190 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@69bffc7f
2022-05-06 09:07:45,191 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 09:07:45,195 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 09:07:45,195 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 09:07:45,196 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 09:07:45,197 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 09:07:45,203 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Request joining group due to: need to re-join with the given member-id
2022-05-06 09:07:45,203 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] (Re-)joining group
2022-05-06 09:07:45,204 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: need to re-join with the given member-id
2022-05-06 09:07:45,205 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 09:07:45,206 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 09:07:45,207 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 09:07:45,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8d740d09-d484-4522-b268-2ccca4b98620', protocol='range'}
2022-05-06 09:07:45,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-0f85958d-0216-4d7f-b150-34382d03305b', protocol='range'}
2022-05-06 09:07:45,215 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Finished assignment for group at generation 1: {consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-0f85958d-0216-4d7f-b150-34382d03305b=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 09:07:45,215 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Finished assignment for group at generation 1: {consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8d740d09-d484-4522-b268-2ccca4b98620=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 09:07:45,251 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-0f85958d-0216-4d7f-b150-34382d03305b', protocol='range'}
2022-05-06 09:07:45,251 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8d740d09-d484-4522-b268-2ccca4b98620', protocol='range'}
2022-05-06 09:07:45,252 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 09:07:45,252 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 09:07:45,253 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 09:07:45,253 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 09:07:45,264 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 09:07:45,265 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 09:07:45,269 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 09:07:45,269 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 09:07:45,283 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=4, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 09:07:45,283 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 09:07:45,289 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.333 seconds (JVM running for 5.817)
2022-05-06 09:07:45,297 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5321c95c-bae2-4993-9848-199466970748: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 09:07:45,297 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 09:07:57,543 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[214], headers={kafka_offset=4, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4955e0, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651808274434, __TypeId__=[B@67a2b3f1, kafka_groupId=anonymous.5321c95c-bae2-4993-9848-199466970748}]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 more

2022-05-06 09:07:57,549 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for BIDS_PLACED_BY_BUYER-0@4
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[214], headers={kafka_offset=4, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4955e0, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651808274434, __TypeId__=[B@67a2b3f1, kafka_groupId=anonymous.5321c95c-bae2-4993-9848-199466970748}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.BidEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==')
 at [Source: (byte[])""eyJpZCI6Ijk3Y2M4OGM0LWUwZTctNGVkNy05MjhhLTdjOTkzOWUyOGIwZCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDAzOjM3OjU0LjMxMyswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjcsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo4fQ==""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 common frames omitted
2022-05-06 09:13:05,975 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:18:05,980 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:23:05,991 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:28:06,002 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:33:06,014 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:38:06,023 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:43:06,032 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:48:07,086 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:53:07,097 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 09:58:07,104 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:03:07,108 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:08:07,117 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:13:07,127 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:18:07,139 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:23:07,142 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 10:28:07,156 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 14:00:29,852 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Error sending fetch request (sessionId=775314264, epoch=9431) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 14:00:31,230 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Error sending fetch request (sessionId=1114223172, epoch=9427) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 14:00:31,235 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.5321c95c-bae2-4993-9848-199466970748] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 14:00:29,846 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 14:00:32,284 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 14:00:32,287 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 14:00:32,287 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 14:00:32,289 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 14:00:32,291 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 14:00:32,327 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8d740d09-d484-4522-b268-2ccca4b98620', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 14:00:32,327 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-0f85958d-0216-4d7f-b150-34382d03305b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 14:00:32,329 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 14:00:32,328 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 14:00:32,429 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 14:00:32,488 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 14:00:32,493 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 14:00:32,499 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 14:00:32,524 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 14:00:32,524 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-06 14:00:32,619 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5321c95c-bae2-4993-9848-199466970748: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 14:00:32,619 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 14:00:32,625 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5321c95c-bae2-4993-9848-199466970748: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 14:00:32,670 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 14:00:32,670 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 14:00:32,670 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] (Re-)joining group
2022-05-06 14:00:35,670 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: need to re-join with the given member-id
2022-05-06 14:00:35,671 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 14:00:35,677 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Request joining group due to: need to re-join with the given member-id
2022-05-06 14:00:35,677 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] (Re-)joining group
2022-05-06 14:00:35,735 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-a15e2e69-db6e-484c-85e7-6c3ebb48d3ce', protocol='range'}
2022-05-06 14:00:35,736 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Finished assignment for group at generation 3: {consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-a15e2e69-db6e-484c-85e7-6c3ebb48d3ce=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 14:00:35,755 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-84b71778-e4df-4ae6-a5eb-752d4091e64e', protocol='range'}
2022-05-06 14:00:35,756 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Finished assignment for group at generation 3: {consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-84b71778-e4df-4ae6-a5eb-752d4091e64e=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 14:00:35,758 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-a15e2e69-db6e-484c-85e7-6c3ebb48d3ce', protocol='range'}
2022-05-06 14:00:35,759 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2-84b71778-e4df-4ae6-a5eb-752d4091e64e', protocol='range'}
2022-05-06 14:00:35,762 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 14:00:35,762 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 14:00:35,763 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 14:00:35,763 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 14:00:35,883 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 14:00:35,885 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 14:00:35,908 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 14:00:36,011 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5321c95c-bae2-4993-9848-199466970748: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 16:35:07,947 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Error sending fetch request (sessionId=1330786674, epoch=16) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 16:35:07,948 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 16:35:08,288 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Error sending fetch request (sessionId=2056076069, epoch=16) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 16:35:08,295 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.5321c95c-bae2-4993-9848-199466970748] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 16:35:08,536 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:35:08,538 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:35:08,544 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:35:08,553 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5321c95c-bae2-4993-9848-199466970748-2, groupId=anonymous.5321c95c-bae2-4993-9848-199466970748] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:35:10,185 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-a15e2e69-db6e-484c-85e7-6c3ebb48d3ce', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 16:35:10,185 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 16:35:10,186 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 16:35:10,186 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 16:35:10,190 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 16:35:10,190 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 16:35:10,190 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 16:35:10,191 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 16:35:10,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Request joining group due to: need to re-join with the given member-id
2022-05-06 16:35:10,215 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] (Re-)joining group
2022-05-06 16:35:10,232 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8261e171-f81e-439b-95a2-935dff3b4188', protocol='range'}
2022-05-06 16:35:11,055 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Finished assignment for group at generation 5: {consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8261e171-f81e-439b-95a2-935dff3b4188=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 16:35:12,019 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4-8261e171-f81e-439b-95a2-935dff3b4188', protocol='range'}
2022-05-06 16:35:12,020 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 16:35:12,020 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 16:35:12,049 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f-4, groupId=anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 16:35:12,050 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bb501b3e-379b-4bf1-93f8-212917cf307f: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 16:39:13,041 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 16:44:13,071 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 16:46:11,593 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 16:46:11,594 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 16600 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 16:46:11,594 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 16:46:11,633 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 16:46:11,633 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 16:46:11,634 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 16:46:11,635 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 16:46:12,318 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 16:46:12,432 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 110 ms. Found 3 MongoDB repository interfaces.
2022-05-06 16:46:12,609 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 16:46:12,626 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 16:46:12,709 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=730b88f4-1d33-3a02-b532-ad24823fe279
2022-05-06 16:46:12,767 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 16:46:12,842 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 16:46:13,332 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 16:46:13,342 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 16:46:13,342 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 16:46:13,342 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 16:46:13,447 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 16:46:13,448 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1813 ms
2022-05-06 16:46:13,579 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 16:46:13,645 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275037ddb418e0327addfee', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:68}] to localhost:27017
2022-05-06 16:46:13,645 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275037ddb418e0327addfee', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:69}] to localhost:27017
2022-05-06 16:46:13,646 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275037ddb418e0327addfee', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=23051800}
2022-05-06 16:46:13,683 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 16:46:13,734 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 16:46:13,767 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 16:46:14,438 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 16:46:14,576 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 16:46:14,594 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 16:46:14,694 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bid_input' has 1 subscriber(s).
2022-05-06 16:46:14,697 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 16:46:14,697 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 16:46:14,698 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 16:46:14,703 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 16:46:14,803 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 16:46:14,807 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 16:46:14,835 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 16:46:14,836 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 16:46:15,033 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 16:46:15,040 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 16:46:15,047 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 16:46:15,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651835775060 with initial instances count: 6
2022-05-06 16:46:15,063 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 16:46:15,063 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651835775063, current=UP, previous=STARTING]
2022-05-06 16:46:15,065 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 16:46:15,065 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 16:46:15,097 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 16:46:15,128 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 16:46:15,128 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 16:46:15,129 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 16:46:15,178 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 16:46:15,179 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 16:46:15,179 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 16:46:15,195 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 16:46:15,195 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 16:46:15,195 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 16:46:15,215 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 16:46:15,215 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 16:46:15,215 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 16:46:15,265 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 16:46:15,360 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:15,360 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:15,360 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835775359
2022-05-06 16:46:15,841 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 16:46:15,845 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 16:46:15,846 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 16:46:15,846 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 16:46:15,861 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 16:46:15,909 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:15,909 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:15,909 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835775909
2022-05-06 16:46:15,918 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-1, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 16:46:15,920 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-1, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 16:46:15,920 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-1, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 16:46:15,920 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 16:46:15,920 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 16:46:15,920 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 16:46:15,922 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-1 unregistered
2022-05-06 16:46:15,945 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6.errors' has 1 subscriber(s).
2022-05-06 16:46:15,945 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6.errors' has 0 subscriber(s).
2022-05-06 16:46:15,945 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6.errors' has 1 subscriber(s).
2022-05-06 16:46:15,945 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6.errors' has 2 subscriber(s).
2022-05-06 16:46:15,962 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 16:46:15,967 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:15,968 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:15,968 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835775967
2022-05-06 16:46:15,969 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 16:46:15,972 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@27a4979b
2022-05-06 16:46:15,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 16:46:15,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 16:46:15,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 16:46:15,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 16:46:15,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 16:46:15,978 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 16:46:15,982 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:15,983 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:15,983 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 16:46:15,983 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835775982
2022-05-06 16:46:15,983 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 16:46:15,995 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-06 16:46:15,996 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-06 16:46:15,997 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 16:46:15,997 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-06 16:46:15,999 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 16:46:16,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:16,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:16,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835776004
2022-05-06 16:46:16,004 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:46:16,007 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] (Re-)joining group
2022-05-06 16:46:16,008 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-3, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 16:46:16,009 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-3, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 16:46:16,009 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-3, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 16:46:16,009 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 16:46:16,009 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 16:46:16,009 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 16:46:16,010 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-3 unregistered
2022-05-06 16:46:16,012 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce.errors' has 1 subscriber(s).
2022-05-06 16:46:16,013 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce.errors' has 0 subscriber(s).
2022-05-06 16:46:16,013 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce.errors' has 1 subscriber(s).
2022-05-06 16:46:16,013 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce.errors' has 2 subscriber(s).
2022-05-06 16:46:16,015 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 16:46:16,019 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 16:46:16,019 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 16:46:16,019 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651835776019
2022-05-06 16:46:16,019 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 16:46:16,020 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@3f2aa490
2022-05-06 16:46:16,021 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 16:46:16,023 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 16:46:16,023 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 16:46:16,024 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 16:46:16,024 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] (Re-)joining group
2022-05-06 16:46:16,032 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 16:46:16,033 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 16:46:16,055 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Request joining group due to: need to re-join with the given member-id
2022-05-06 16:46:16,055 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Request joining group due to: need to re-join with the given member-id
2022-05-06 16:46:16,056 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] (Re-)joining group
2022-05-06 16:46:16,056 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] (Re-)joining group
2022-05-06 16:46:16,069 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4-c5f20f56-cea0-48df-9d05-a34566678ace', protocol='range'}
2022-05-06 16:46:16,071 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-2eaffb02-5ecd-45d5-b4ca-b8089745431f', protocol='range'}
2022-05-06 16:46:16,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Finished assignment for group at generation 1: {consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4-c5f20f56-cea0-48df-9d05-a34566678ace=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 16:46:16,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Finished assignment for group at generation 1: {consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-2eaffb02-5ecd-45d5-b4ca-b8089745431f=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 16:46:16,120 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 6.094 seconds (JVM running for 6.727)
2022-05-06 16:46:16,123 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-2eaffb02-5ecd-45d5-b4ca-b8089745431f', protocol='range'}
2022-05-06 16:46:16,123 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4-c5f20f56-cea0-48df-9d05-a34566678ace', protocol='range'}
2022-05-06 16:46:16,123 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 16:46:16,123 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 16:46:16,125 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 16:46:16,125 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 16:46:16,134 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 16:46:16,134 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 16:46:16,137 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 16:46:16,137 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 16:46:16,153 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 16:46:16,153 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 16:46:16,172 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 16:46:16,172 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 16:46:31,835 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[214], headers={kafka_offset=5, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@706cc0e0, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651835788691, __TypeId__=[B@4b0a2944, kafka_groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6}]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 more

2022-05-06 16:46:31,840 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for BIDS_PLACED_BY_BUYER-0@5
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[214], headers={kafka_offset=5, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@706cc0e0, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651835788691, __TypeId__=[B@4b0a2944, kafka_groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==')
 at [Source: (byte[])""eyJpZCI6ImNkYjIwYjg2LTEwOTUtNDA4YS1hMTc5LWY2OTMyMjQ1ZWE2MSIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDExOjE2OjI4LjY0NSswMDowMCIsImV2ZW50VHlwZSI6bnVsbCwiYmlkSWQiOjgsInByb2R1Y3RJZCI6MzksImJpZEFtb3VudCI6MjAwLCJidXllcklkIjo5fQ==""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 common frames omitted
2022-05-06 17:22:13,231 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Error sending fetch request (sessionId=1845236602, epoch=515) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 17:22:13,230 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Error sending fetch request (sessionId=540955720, epoch=519) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 17:22:13,239 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 17:22:13,250 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 17:22:14,595 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:22:14,650 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:22:14,691 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:22:14,692 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce-4, groupId=anonymous.2e834b06-1d5b-4cc3-bd37-fd166fff76ce] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:22:15,717 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-2eaffb02-5ecd-45d5-b4ca-b8089745431f', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 17:22:15,718 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 17:22:15,718 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 17:22:15,719 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 17:22:15,720 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-06 17:22:15,721 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:22:15,721 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:22:15,723 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] (Re-)joining group
2022-05-06 17:22:15,726 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:22:15,726 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] (Re-)joining group
2022-05-06 17:22:15,729 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-960f8b9d-4bd6-43f9-8690-05cad222e864', protocol='range'}
2022-05-06 17:22:15,729 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Finished assignment for group at generation 3: {consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-960f8b9d-4bd6-43f9-8690-05cad222e864=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 17:22:15,732 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2-960f8b9d-4bd6-43f9-8690-05cad222e864', protocol='range'}
2022-05-06 17:22:15,732 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 17:22:15,732 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 17:22:15,738 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6-2, groupId=anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 17:22:15,738 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.33a23c3a-5bb3-4673-af6d-18dc278d84f6: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:22:45,097 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 17:27:45,100 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 17:32:45,119 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 17:37:45,130 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 17:39:28,350 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 22932 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 17:39:28,352 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 17:39:28,354 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 17:39:28,393 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 17:39:28,393 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 17:39:28,394 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 17:39:28,395 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 17:39:29,046 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 17:39:29,199 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 149 ms. Found 3 MongoDB repository interfaces.
2022-05-06 17:39:29,403 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 17:39:29,419 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 17:39:29,515 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=730b88f4-1d33-3a02-b532-ad24823fe279
2022-05-06 17:39:29,589 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:39:29,670 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:39:30,248 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 17:39:30,265 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 17:39:30,266 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 17:39:30,266 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 17:39:30,409 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 17:39:30,409 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 2014 ms
2022-05-06 17:39:30,559 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 17:39:30,615 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62750ffa1c975645ee75f2b0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:73}] to localhost:27017
2022-05-06 17:39:30,615 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62750ffa1c975645ee75f2b0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:72}] to localhost:27017
2022-05-06 17:39:30,615 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62750ffa1c975645ee75f2b0', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17551100}
2022-05-06 17:39:30,653 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:39:30,703 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 17:39:30,735 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:39:31,409 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 17:39:31,548 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 17:39:31,563 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 17:39:31,664 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bid_input' has 1 subscriber(s).
2022-05-06 17:39:31,667 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 17:39:31,667 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 17:39:31,667 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 17:39:31,673 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 17:39:31,781 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 17:39:31,786 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 17:39:31,815 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 17:39:32,037 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 17:39:32,044 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 17:39:32,054 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 17:39:32,072 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651838972071 with initial instances count: 6
2022-05-06 17:39:32,074 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 17:39:32,074 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651838972074, current=UP, previous=STARTING]
2022-05-06 17:39:32,075 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 17:39:32,076 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 17:39:32,140 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 17:39:32,141 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:39:32,141 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 17:39:32,167 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 17:39:32,186 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 17:39:32,186 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:39:32,187 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 17:39:32,201 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 17:39:32,201 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:39:32,201 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 17:39:32,224 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 17:39:32,224 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:39:32,224 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:39:32,309 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:39:32,411 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,411 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,412 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972410
2022-05-06 17:39:32,827 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 17:39:32,829 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 17:39:32,830 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:39:32,830 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 17:39:32,841 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.49338718-41ee-4df9-a869-a54fac411aee
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:39:32,882 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,882 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,882 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972882
2022-05-06 17:39:32,890 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-1, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:39:32,890 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-1, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:39:32,891 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-1, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:39:32,891 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:39:32,891 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:39:32,891 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:39:32,893 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-1 unregistered
2022-05-06 17:39:32,922 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.49338718-41ee-4df9-a869-a54fac411aee.errors' has 1 subscriber(s).
2022-05-06 17:39:32,922 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.49338718-41ee-4df9-a869-a54fac411aee.errors' has 0 subscriber(s).
2022-05-06 17:39:32,923 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.49338718-41ee-4df9-a869-a54fac411aee.errors' has 1 subscriber(s).
2022-05-06 17:39:32,923 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.49338718-41ee-4df9-a869-a54fac411aee.errors' has 2 subscriber(s).
2022-05-06 17:39:32,942 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.49338718-41ee-4df9-a869-a54fac411aee
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:39:32,947 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,947 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,947 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972947
2022-05-06 17:39:32,948 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 17:39:32,952 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@108102eb
2022-05-06 17:39:32,953 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:39:32,953 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:39:32,953 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:39:32,953 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:39:32,954 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:39:32,955 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:39:32,957 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 17:39:32,957 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,957 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,958 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972957
2022-05-06 17:39:32,958 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:39:32,967 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-06 17:39:32,968 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-06 17:39:32,968 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:39:32,969 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-06 17:39:32,969 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:39:32,973 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,973 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,973 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972973
2022-05-06 17:39:32,976 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-3, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:39:32,977 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-3, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:39:32,978 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-3, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:39:32,978 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:39:32,978 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:39:32,978 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:39:32,978 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:39:32,979 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-3 unregistered
2022-05-06 17:39:32,979 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] (Re-)joining group
2022-05-06 17:39:32,980 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1.errors' has 1 subscriber(s).
2022-05-06 17:39:32,980 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1.errors' has 0 subscriber(s).
2022-05-06 17:39:32,980 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1.errors' has 1 subscriber(s).
2022-05-06 17:39:32,980 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1.errors' has 2 subscriber(s).
2022-05-06 17:39:32,981 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:39:32,985 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:39:32,985 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:39:32,985 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651838972985
2022-05-06 17:39:32,986 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 17:39:32,986 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7869c03d
2022-05-06 17:39:32,987 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 17:39:32,989 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 17:39:32,990 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:39:32,990 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:39:32,990 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] (Re-)joining group
2022-05-06 17:39:33,000 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 17:39:33,001 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 17:39:33,017 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:39:33,017 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:39:33,017 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] (Re-)joining group
2022-05-06 17:39:33,017 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] (Re-)joining group
2022-05-06 17:39:33,037 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2-fd3dbeb3-1300-4000-8422-c9ee9bcec38c', protocol='range'}
2022-05-06 17:39:33,038 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4-119c29db-e21f-41f7-a271-443400660131', protocol='range'}
2022-05-06 17:39:33,039 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Finished assignment for group at generation 1: {consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2-fd3dbeb3-1300-4000-8422-c9ee9bcec38c=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 17:39:33,039 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Finished assignment for group at generation 1: {consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4-119c29db-e21f-41f7-a271-443400660131=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 17:39:33,087 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 6.463 seconds (JVM running for 7.062)
2022-05-06 17:39:33,102 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2-fd3dbeb3-1300-4000-8422-c9ee9bcec38c', protocol='range'}
2022-05-06 17:39:33,102 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4-119c29db-e21f-41f7-a271-443400660131', protocol='range'}
2022-05-06 17:39:33,103 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 17:39:33,103 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 17:39:33,105 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 17:39:33,105 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 17:39:33,115 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:39:33,115 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:39:33,121 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:39:33,121 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:39:33,133 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.49338718-41ee-4df9-a869-a54fac411aee-2, groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:39:33,133 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1-4, groupId=anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:39:33,147 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.49338718-41ee-4df9-a869-a54fac411aee: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:39:33,147 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe3419e5-0733-4a3a-801e-8cd0817ac0c1: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 17:40:20,271 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[222], headers={kafka_offset=6, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@2a4a4b5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651839017096, __TypeId__=[B@7aaa0b2d, kafka_groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee}]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 more

2022-05-06 17:40:20,280 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for BIDS_PLACED_BY_BUYER-0@6
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[222], headers={kafka_offset=6, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@2a4a4b5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651839017096, __TypeId__=[B@7aaa0b2d, kafka_groupId=anonymous.49338718-41ee-4df9-a869-a54fac411aee}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=')
 at [Source: (byte[])""eyJpZCI6IjcxNjgzMDRmLTkwMDctNGRmOS1iMWVjLWVkYjU0MDk0MWIxOCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjEwOjE3LjA3NCswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEwLCJiaWRJZCI6OX0=""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 43 common frames omitted
2022-05-06 17:41:53,501 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 17:41:53,504 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 29316 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 17:41:53,505 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 17:41:53,538 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 17:41:53,538 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 17:41:53,539 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 17:41:53,539 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 17:41:54,038 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 17:41:54,140 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 99 ms. Found 3 MongoDB repository interfaces.
2022-05-06 17:41:54,296 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 17:41:54,305 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 17:41:54,383 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=730b88f4-1d33-3a02-b532-ad24823fe279
2022-05-06 17:41:54,437 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:41:54,494 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:41:54,944 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 17:41:54,956 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 17:41:54,956 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 17:41:54,956 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 17:41:55,060 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 17:41:55,060 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1520 ms
2022-05-06 17:41:55,164 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 17:41:55,208 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275108b23398225c363c5dc', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:75}] to localhost:27017
2022-05-06 17:41:55,208 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275108b23398225c363c5dc', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:74}] to localhost:27017
2022-05-06 17:41:55,209 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275108b23398225c363c5dc', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14517700}
2022-05-06 17:41:55,247 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:41:55,294 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 17:41:55,326 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:41:55,922 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 17:41:56,047 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 17:41:56,061 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 17:41:56,150 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bid_input' has 1 subscriber(s).
2022-05-06 17:41:56,154 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 17:41:56,154 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 17:41:56,154 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 17:41:56,158 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 17:41:56,259 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 17:41:56,263 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 17:41:56,292 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 17:41:56,292 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 17:41:56,292 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 17:41:56,293 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 17:41:56,293 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 17:41:56,293 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 17:41:56,293 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 17:41:56,482 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 17:41:56,489 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 17:41:56,495 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 17:41:56,509 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651839116508 with initial instances count: 6
2022-05-06 17:41:56,510 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 17:41:56,510 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651839116510, current=UP, previous=STARTING]
2022-05-06 17:41:56,511 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 17:41:56,512 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 17:41:56,544 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 17:41:56,570 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 17:41:56,571 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:41:56,571 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 17:41:56,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 17:41:56,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:41:56,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 17:41:56,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 17:41:56,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:41:56,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 17:41:56,645 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 17:41:56,645 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:41:56,645 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:41:56,692 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:41:56,768 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:56,768 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:56,768 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839116767
2022-05-06 17:41:57,153 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 17:41:57,156 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 17:41:57,156 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:41:57,156 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 17:41:57,171 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:41:57,205 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:57,205 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:57,205 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839117205
2022-05-06 17:41:57,212 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-1, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:41:57,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-1, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:41:57,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-1, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:41:57,213 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:41:57,213 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:41:57,214 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:41:57,215 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-1 unregistered
2022-05-06 17:41:57,234 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c.errors' has 1 subscriber(s).
2022-05-06 17:41:57,234 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c.errors' has 0 subscriber(s).
2022-05-06 17:41:57,234 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c.errors' has 1 subscriber(s).
2022-05-06 17:41:57,234 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c.errors' has 2 subscriber(s).
2022-05-06 17:41:57,250 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:41:57,255 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:57,255 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:57,256 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839117255
2022-05-06 17:41:57,257 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 17:41:57,260 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@40dc2cc0
2022-05-06 17:41:57,262 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:41:57,262 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:41:57,262 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:41:57,262 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:41:57,262 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:41:57,264 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:41:57,267 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:57,267 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 17:41:57,267 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:57,267 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839117267
2022-05-06 17:41:57,267 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:41:57,268 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:41:57,269 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] (Re-)joining group
2022-05-06 17:41:57,280 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-06 17:41:57,280 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-06 17:41:57,280 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:41:57,280 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-06 17:41:57,281 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:41:57,283 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:41:57,283 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] (Re-)joining group
2022-05-06 17:41:57,286 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:57,286 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:57,286 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839117286
2022-05-06 17:41:57,287 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2-9dcb10f7-93e5-4636-a089-30d9ad7269e7', protocol='range'}
2022-05-06 17:41:57,288 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Finished assignment for group at generation 1: {consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2-9dcb10f7-93e5-4636-a089-30d9ad7269e7=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 17:41:57,289 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-3, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:41:57,289 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-3, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:41:57,289 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-3, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:41:57,290 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:41:57,290 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:41:57,290 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:41:57,291 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-3 unregistered
2022-05-06 17:41:57,292 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105.errors' has 1 subscriber(s).
2022-05-06 17:41:57,293 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105.errors' has 0 subscriber(s).
2022-05-06 17:41:57,293 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105.errors' has 1 subscriber(s).
2022-05-06 17:41:57,293 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105.errors' has 2 subscriber(s).
2022-05-06 17:41:57,295 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:41:57,300 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2-9dcb10f7-93e5-4636-a089-30d9ad7269e7', protocol='range'}
2022-05-06 17:41:57,300 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:41:57,300 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:41:57,300 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839117300
2022-05-06 17:41:57,300 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 17:41:57,300 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 17:41:57,301 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@4968aef7
2022-05-06 17:41:57,301 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 17:41:57,303 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 17:41:57,304 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 17:41:57,305 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:41:57,305 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:41:57,305 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] (Re-)joining group
2022-05-06 17:41:57,307 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:41:57,311 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:41:57,311 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] (Re-)joining group
2022-05-06 17:41:57,311 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:41:57,313 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 17:41:57,313 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4-161771dc-e5cf-409c-a029-dfc1d8a4be69', protocol='range'}
2022-05-06 17:41:57,314 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Finished assignment for group at generation 1: {consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4-161771dc-e5cf-409c-a029-dfc1d8a4be69=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 17:41:57,314 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 17:41:57,318 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4-161771dc-e5cf-409c-a029-dfc1d8a4be69', protocol='range'}
2022-05-06 17:41:57,319 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 17:41:57,319 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 17:41:57,320 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:41:57,321 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c-2, groupId=anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:41:57,321 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:41:57,325 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105-4, groupId=anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:41:57,326 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.02674161-b936-4c9b-a9aa-7db96e8bd19c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:41:57,329 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a78f16e9-e75f-48f7-ac98-eb75f9ad0105: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 17:41:57,399 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.941 seconds (JVM running for 5.428)
2022-05-06 17:44:24,216 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 10392 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 17:44:24,218 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 17:44:24,218 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 17:44:24,249 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 17:44:24,249 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 17:44:24,250 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 17:44:24,250 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 17:44:24,743 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 17:44:24,841 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 94 ms. Found 3 MongoDB repository interfaces.
2022-05-06 17:44:24,993 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 17:44:25,000 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 17:44:25,071 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-06 17:44:25,125 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:44:25,180 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 17:44:25,562 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 17:44:25,571 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 17:44:25,572 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 17:44:25,572 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 17:44:25,662 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 17:44:25,662 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1411 ms
2022-05-06 17:44:25,768 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 17:44:25,811 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627511210b83867ae8471a75', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:76}] to localhost:27017
2022-05-06 17:44:25,811 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627511210b83867ae8471a75', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:77}] to localhost:27017
2022-05-06 17:44:25,812 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627511210b83867ae8471a75', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15832600}
2022-05-06 17:44:25,845 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:44:25,894 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 17:44:25,928 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 17:44:26,506 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 17:44:26,636 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 17:44:26,650 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 17:44:26,736 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-06 17:44:26,740 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 17:44:26,740 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 17:44:26,740 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 17:44:26,746 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 17:44:26,816 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 17:44:26,821 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 17:44:26,846 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 17:44:26,846 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 17:44:26,846 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 17:44:26,847 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 17:44:26,847 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 17:44:26,847 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 17:44:26,847 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 17:44:27,002 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 17:44:27,009 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 17:44:27,017 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 17:44:27,038 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651839267037 with initial instances count: 6
2022-05-06 17:44:27,039 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 17:44:27,039 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651839267039, current=UP, previous=STARTING]
2022-05-06 17:44:27,040 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 17:44:27,042 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 17:44:27,069 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 17:44:27,097 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 17:44:27,097 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:44:27,098 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 17:44:27,138 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 17:44:27,138 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:44:27,138 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 17:44:27,152 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 17:44:27,152 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:44:27,152 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 17:44:27,170 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 17:44:27,170 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:44:27,171 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:44:27,216 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:44:27,297 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,297 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,297 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267296
2022-05-06 17:44:27,688 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 17:44:27,690 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 17:44:27,690 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:44:27,690 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 17:44:27,701 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe5393b3-e887-4495-a37a-410f4f291964
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:44:27,737 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,737 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,737 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267737
2022-05-06 17:44:27,744 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-1, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:44:27,744 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-1, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:44:27,744 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-1, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:44:27,744 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:44:27,745 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:44:27,745 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:44:27,746 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-1 unregistered
2022-05-06 17:44:27,762 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe5393b3-e887-4495-a37a-410f4f291964.errors' has 1 subscriber(s).
2022-05-06 17:44:27,762 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe5393b3-e887-4495-a37a-410f4f291964.errors' has 0 subscriber(s).
2022-05-06 17:44:27,762 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe5393b3-e887-4495-a37a-410f4f291964.errors' has 1 subscriber(s).
2022-05-06 17:44:27,762 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe5393b3-e887-4495-a37a-410f4f291964.errors' has 2 subscriber(s).
2022-05-06 17:44:27,777 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe5393b3-e887-4495-a37a-410f4f291964
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:44:27,781 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,781 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,781 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267781
2022-05-06 17:44:27,782 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 17:44:27,784 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@37a362cd
2022-05-06 17:44:27,786 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 17:44:27,787 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:44:27,787 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 17:44:27,787 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 17:44:27,788 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 17:44:27,789 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 17:44:27,792 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,792 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 17:44:27,792 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,793 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267792
2022-05-06 17:44:27,793 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:44:27,793 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:44:27,795 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] (Re-)joining group
2022-05-06 17:44:27,804 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-06 17:44:27,807 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-06 17:44:27,807 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:44:27,807 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-06 17:44:27,808 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:44:27,808 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:44:27,808 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] (Re-)joining group
2022-05-06 17:44:27,812 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-abaaff71-2aea-418c-944a-18a7c41ccefc', protocol='range'}
2022-05-06 17:44:27,814 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,814 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Finished assignment for group at generation 1: {consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-abaaff71-2aea-418c-944a-18a7c41ccefc=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 17:44:27,814 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,814 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267814
2022-05-06 17:44:27,818 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-3, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:44:27,818 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-3, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 17:44:27,818 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-3, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 17:44:27,820 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 17:44:27,820 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 17:44:27,820 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 17:44:27,821 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-3 unregistered
2022-05-06 17:44:27,822 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-abaaff71-2aea-418c-944a-18a7c41ccefc', protocol='range'}
2022-05-06 17:44:27,822 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 17:44:27,822 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814.errors' has 1 subscriber(s).
2022-05-06 17:44:27,822 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814.errors' has 0 subscriber(s).
2022-05-06 17:44:27,822 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814.errors' has 1 subscriber(s).
2022-05-06 17:44:27,823 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814.errors' has 2 subscriber(s).
2022-05-06 17:44:27,824 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 17:44:27,825 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 17:44:27,830 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:44:27,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 17:44:27,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 17:44:27,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651839267831
2022-05-06 17:44:27,831 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 17:44:27,832 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1f9c6143
2022-05-06 17:44:27,832 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 17:44:27,834 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 17:44:27,835 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 17:44:27,836 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 17:44:27,836 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:44:27,837 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] (Re-)joining group
2022-05-06 17:44:27,841 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:44:27,842 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] (Re-)joining group
2022-05-06 17:44:27,843 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:44:27,845 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4-5cae748d-8f88-47ac-858c-45df4ed6c0bb', protocol='range'}
2022-05-06 17:44:27,846 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Finished assignment for group at generation 1: {consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4-5cae748d-8f88-47ac-858c-45df4ed6c0bb=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 17:44:27,848 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 17:44:27,848 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 17:44:27,848 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe5393b3-e887-4495-a37a-410f4f291964: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:44:27,849 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4-5cae748d-8f88-47ac-858c-45df4ed6c0bb', protocol='range'}
2022-05-06 17:44:27,849 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 17:44:27,849 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 17:44:27,851 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:44:27,853 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 17:44:27,858 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 17:44:27,860 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 17:44:27,921 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.105 seconds (JVM running for 5.574)
2022-05-06 17:49:26,856 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 17:58:57,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.fe5393b3-e887-4495-a37a-410f4f291964] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 17:58:57,822 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Error sending fetch request (sessionId=2056626156, epoch=677) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 17:58:57,822 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Error sending fetch request (sessionId=1156001522, epoch=677) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 17:58:57,823 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 17:58:57,926 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:58:57,926 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814-4, groupId=anonymous.e1f3620e-fbe1-4fe9-b71f-207077044814] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 17:58:58,390 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-abaaff71-2aea-418c-944a-18a7c41ccefc', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 17:58:58,391 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 17:58:58,391 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 17:58:58,391 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 17:58:58,391 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-06 17:58:58,392 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe5393b3-e887-4495-a37a-410f4f291964: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:58:58,393 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe5393b3-e887-4495-a37a-410f4f291964: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 17:58:58,393 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] (Re-)joining group
2022-05-06 17:58:58,397 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Request joining group due to: need to re-join with the given member-id
2022-05-06 17:58:58,397 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] (Re-)joining group
2022-05-06 17:58:58,403 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-4a2b9b91-4d17-462a-9e67-2779d2e8d776', protocol='range'}
2022-05-06 17:58:58,403 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Finished assignment for group at generation 3: {consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-4a2b9b91-4d17-462a-9e67-2779d2e8d776=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 17:58:58,409 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2-4a2b9b91-4d17-462a-9e67-2779d2e8d776', protocol='range'}
2022-05-06 17:58:58,410 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 17:58:58,410 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 17:58:58,414 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe5393b3-e887-4495-a37a-410f4f291964-2, groupId=anonymous.fe5393b3-e887-4495-a37a-410f4f291964] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 17:58:58,415 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe5393b3-e887-4495-a37a-410f4f291964: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 18:02:51,708 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 18:02:51,711 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 1892 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 18:02:51,711 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 18:02:51,745 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 18:02:51,746 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 18:02:51,747 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 18:02:52,291 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 18:02:52,407 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 111 ms. Found 3 MongoDB repository interfaces.
2022-05-06 18:02:52,605 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 18:02:52,621 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 18:02:52,703 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 18:02:52,766 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 18:02:52,839 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 18:02:53,301 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8080 (http)
2022-05-06 18:02:53,314 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8080"]
2022-05-06 18:02:53,314 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 18:02:53,315 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 18:02:53,432 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 18:02:53,433 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1686 ms
2022-05-06 18:02:53,582 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 18:02:53,638 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627515752b4c320603e6dc55', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:81}] to localhost:27017
2022-05-06 18:02:53,638 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627515752b4c320603e6dc55', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:80}] to localhost:27017
2022-05-06 18:02:53,639 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627515752b4c320603e6dc55', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17904700}
2022-05-06 18:02:53,673 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 18:02:53,729 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 18:02:53,760 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 18:02:54,374 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 18:02:54,508 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 18:02:54,525 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 18:02:54,622 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 18:02:54,626 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 18:02:54,626 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 18:02:54,627 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 18:02:54,631 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 18:02:54,730 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region us-east-1
2022-05-06 18:02:54,735 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 18:02:54,762 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 18:02:54,762 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 18:02:54,762 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 18:02:54,763 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 18:02:54,763 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 18:02:54,763 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 18:02:54,763 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 18:02:59,054 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [restartedMain] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on GET request for "http://localhost:8761/eureka/apps/": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8761/eureka/apps/": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplications(RestTemplateEurekaHttpClient.java:135)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1101)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1014)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:441)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:283)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:279)
	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:66)
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:295)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:638)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1352)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1195)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:374)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:376)
	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:371)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:127)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:115)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:282)
	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:485)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$EnhancerBySpringCGLIB$$76f4db6d.getEurekaClient(<generated>)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:54)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:38)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:83)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:935)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:586)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:740)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:415)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 73 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 86 more

2022-05-06 18:02:59,055 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [restartedMain] Request execution failed with message: I/O error on GET request for "http://localhost:8761/eureka/apps/": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-06 18:02:59,055 INFO com.netflix.discovery.DiscoveryClient [restartedMain] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing - was unable to refresh its cache! This periodic background refresh will be retried in 30 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)
	at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1101)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1014)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:441)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:283)
	at com.netflix.discovery.DiscoveryClient.<init>(DiscoveryClient.java:279)
	at org.springframework.cloud.netflix.eureka.CloudEurekaClient.<init>(CloudEurekaClient.java:66)
	at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:295)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)
	at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:638)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1352)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1195)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$1(AbstractBeanFactory.java:374)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:376)
	at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:179)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:371)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:127)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:115)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:282)
	at org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:485)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration$$EnhancerBySpringCGLIB$$76f4db6d.getEurekaClient(<generated>)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:54)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:38)
	at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:83)
	at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:178)
	at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:54)
	at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:356)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:155)
	at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:123)
	at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:935)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:586)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:740)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:415)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)

2022-05-06 18:02:59,056 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initial registry fetch from primary servers failed
2022-05-06 18:02:59,056 WARN com.netflix.discovery.DiscoveryClient$1 [restartedMain] Using default backup registry implementation which does not do anything.
2022-05-06 18:02:59,057 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initial registry fetch from backup servers failed
2022-05-06 18:02:59,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 18:02:59,069 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 18:02:59,088 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651840379084 with initial instances count: 0
2022-05-06 18:02:59,092 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 18:02:59,094 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651840379094, current=UP, previous=STARTING]
2022-05-06 18:02:59,097 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing: registering service...
2022-05-06 18:02:59,098 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 18:02:59,163 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 18:02:59,163 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 18:02:59,163 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 18:02:59,208 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 18:02:59,208 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 18:02:59,208 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 18:02:59,221 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 18:02:59,221 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 18:02:59,222 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 18:02:59,240 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 18:02:59,241 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 18:02:59,241 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 18:02:59,297 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 18:02:59,387 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:02:59,387 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:02:59,387 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651840379386
2022-05-06 18:02:59,771 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 18:02:59,775 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 18:02:59,775 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 18:02:59,775 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 18:02:59,786 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 18:02:59,817 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:02:59,817 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:02:59,817 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651840379817
2022-05-06 18:02:59,823 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-1, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 18:02:59,824 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-1, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 18:02:59,824 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-1, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 18:02:59,824 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 18:02:59,824 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 18:02:59,824 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 18:02:59,826 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-1 unregistered
2022-05-06 18:02:59,846 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'input.anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f.errors' has 1 subscriber(s).
2022-05-06 18:02:59,846 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'input.anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f.errors' has 0 subscriber(s).
2022-05-06 18:02:59,846 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'input.anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f.errors' has 1 subscriber(s).
2022-05-06 18:02:59,846 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'input.anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f.errors' has 2 subscriber(s).
2022-05-06 18:02:59,861 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 18:02:59,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:02:59,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:02:59,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651840379866
2022-05-06 18:02:59,867 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Subscribed to topic(s): input
2022-05-06 18:02:59,871 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@33d69293
2022-05-06 18:02:59,872 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8080"]
2022-05-06 18:02:59,878 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Resetting the last seen epoch of partition input-0 to 0 since the associated topicId changed from null to yPjY5m_OQCm533TER30Asg
2022-05-06 18:02:59,879 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 18:02:59,881 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 18:02:59,882 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8080 (http) with context path ''
2022-05-06 18:02:59,882 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8080
2022-05-06 18:02:59,883 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] (Re-)joining group
2022-05-06 18:02:59,915 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Request joining group due to: need to re-join with the given member-id
2022-05-06 18:02:59,916 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] (Re-)joining group
2022-05-06 18:02:59,926 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2-53601f35-90d9-45b3-9dc4-61c509159124', protocol='range'}
2022-05-06 18:02:59,928 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Finished assignment for group at generation 1: {consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2-53601f35-90d9-45b3-9dc4-61c509159124=Assignment(partitions=[input-0])}
2022-05-06 18:02:59,945 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2-53601f35-90d9-45b3-9dc4-61c509159124', protocol='range'}
2022-05-06 18:02:59,946 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Notifying assignor about the new Assignment(partitions=[input-0])
2022-05-06 18:02:59,948 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Adding newly assigned partitions: input-0
2022-05-06 18:02:59,953 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Found no committed offset for partition input-0
2022-05-06 18:02:59,956 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Found no committed offset for partition input-0
2022-05-06 18:02:59,961 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 9.813 seconds (JVM running for 10.407)
2022-05-06 18:02:59,964 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-06 18:02:59,965 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Resetting offset for partition input-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 18:02:59,972 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f: partitions assigned: [input-0]
2022-05-06 18:02:59,983 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.cloud.config.client.ConfigClientFailFastException: Could not locate PropertySource and the resource is not optional, failing
	at org.springframework.cloud.config.client.ConfigServerConfigDataLoader.doLoad(ConfigServerConfigDataLoader.java:201)
	at org.springframework.cloud.config.client.ConfigClientRetryBootstrapper.lambda$null$1(ConfigClientRetryBootstrapper.java:50)
	at org.springframework.cloud.config.client.ConfigServerConfigDataLoader.load(ConfigServerConfigDataLoader.java:96)
	at org.springframework.cloud.config.client.ConfigServerConfigDataLoader.load(ConfigServerConfigDataLoader.java:61)
	at org.springframework.boot.context.config.ConfigDataLoaders.load(ConfigDataLoaders.java:107)
	at org.springframework.boot.context.config.ConfigDataImporter.load(ConfigDataImporter.java:128)
	at org.springframework.boot.context.config.ConfigDataImporter.resolveAndLoad(ConfigDataImporter.java:86)
	at org.springframework.boot.context.config.ConfigDataEnvironmentContributors.withProcessedImports(ConfigDataEnvironmentContributors.java:116)
	at org.springframework.boot.context.config.ConfigDataEnvironment.processWithProfiles(ConfigDataEnvironment.java:311)
	at org.springframework.boot.context.config.ConfigDataEnvironment.processAndApply(ConfigDataEnvironment.java:232)
	at org.springframework.boot.context.config.ConfigDataEnvironmentPostProcessor.postProcessEnvironment(ConfigDataEnvironmentPostProcessor.java:102)
	at org.springframework.boot.context.config.ConfigDataEnvironmentPostProcessor.postProcessEnvironment(ConfigDataEnvironmentPostProcessor.java:94)
	at org.springframework.boot.env.EnvironmentPostProcessorApplicationListener.onApplicationEnvironmentPreparedEvent(EnvironmentPostProcessorApplicationListener.java:102)
	at org.springframework.boot.env.EnvironmentPostProcessorApplicationListener.onApplicationEvent(EnvironmentPostProcessorApplicationListener.java:87)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.doInvokeListener(SimpleApplicationEventMulticaster.java:176)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:169)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:143)
	at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:131)
	at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:85)
	at org.springframework.boot.SpringApplicationRunListeners.lambda$environmentPrepared$2(SpringApplicationRunListeners.java:66)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:120)
	at org.springframework.boot.SpringApplicationRunListeners.doWithListeners(SpringApplicationRunListeners.java:114)
	at org.springframework.boot.SpringApplicationRunListeners.environmentPrepared(SpringApplicationRunListeners.java:65)
	at org.springframework.boot.SpringApplication.prepareEnvironment(SpringApplication.java:339)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:297)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.web.client.HttpServerErrorException$InternalServerError: 500 : "{"timestamp":"2022-05-06T12:32:51.487+00:00","status":500,"error":"Internal Server Error","trace":"org.springframework.cloud.config.server.environment.FailedToConstructEnvironmentException: Could not construct context for config=listing profile=dev label=null includeOrigin=true; nested exception is while constructing a mapping\n in 'reader', line 23, column 9:\n            input:\n            ^\nfound duplicate key input\n in 'reader', line 25, column 9:\n            input:\n            ^\n\r\n\tat org.springframework.cloud.config.server.environment.NativeEnvironmentRepository.findOne(NativeEnvironmentRepository.java:159)\r\n\tat org.springframework.cloud.config.server.environment.CompositeEnvironmentRepository.findOne(CompositeEnvironmentRepository.java:64)\r\n\tat org.springframework.cloud.config.server.environment.EnvironmentEncryptorEnvironmentRepository.findOne(EnvironmentEncryptorEnvironmentRepository.java:61)\r\n\tat org.springframework.cloud.config.server.environment.EnvironmentController.getEnvironment(EnvironmentController.java:134)\r\n\tat org.springframework.cloud.config.server.environment.EnvironmentController.defaultLabelIncludeOrigin(EnvironmentController.java:116)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\r\n\tat org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:282)\r\n\tat org.springframework.cloud.context.scope.GenericScope$LockedScopedProxyFactoryBean.invoke(GenericScope.java:485)\r\n\tat org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)\r\n\tat org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:763)\r\n\tat org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:708)\r\n\tat org.springframework.cloud.config.server.environment.EnvironmentController$$EnhancerBySpringCGLIB$$2eeae73f.defaultLabelIncludeOrigin(<generated>)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\r\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)\r\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)\r\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)\r\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)\r\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)\r\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)\r\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:655)\r\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:764)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:327)\r\n\tat org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)\r\n\tat org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)\r\n\tat org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)\r\n\tat org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.www.BasicAuthenticationFilter.doFilterInternal(BasicAuthenticationFilter.java:181)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.ui.DefaultLogoutPageGeneratingFilter.doFilterInternal(DefaultLogoutPageGeneratingFilter.java:58)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter.doFilter(DefaultLoginPageGeneratingFilter.java:237)\r\n\tat org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter.doFilter(DefaultLoginPageGeneratingFilter.java:223)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:219)\r\n\tat org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java:213)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)\r\n\tat org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.csrf.CsrfFilter.doFilterInternal(CsrfFilter.java:117)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)\r\n\tat org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:110)\r\n\tat org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:80)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:336)\r\n\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:211)\r\n\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:183)\r\n\tat org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)\r\n\tat org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)\r\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)\r\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)\r\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)\r\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)\r\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)\r\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)\r\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)\r\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)\r\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)\r\n\tat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)\r\n\tat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)\r\n\tat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)\r\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)\r\n\tat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\r\n\tat org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)\r\n\tat org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)\r\n\tat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\r\n\tat java.base/java.lang.Thread.run(Thread.java:832)\r\nCaused by: while constructing a mapping\n in 'reader', line 23, column 9:\n            input:\n            ^\nfound duplicate key input\n in 'reader', line 25, column 9:\n            input:\n            ^\n\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.processDuplicateKeys(SafeConstructor.java:105)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.flattenMapping(SafeConstructor.java:76)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.constructMapping2ndStep(SafeConstructor.java:189)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping(BaseConstructor.java:461)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor$ConstructYamlMap.construct(SafeConstructor.java:556)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:220)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.constructObject(OriginTrackedYamlLoader.java:119)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping2ndStep(BaseConstructor.java:480)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.constructMapping2ndStep(SafeConstructor.java:190)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping(BaseConstructor.java:461)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor$ConstructYamlMap.construct(SafeConstructor.java:556)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:220)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.constructObject(OriginTrackedYamlLoader.java:119)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping2ndStep(BaseConstructor.java:480)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.constructMapping2ndStep(SafeConstructor.java:190)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping(BaseConstructor.java:461)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor$ConstructYamlMap.construct(SafeConstructor.java:556)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:220)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.constructObject(OriginTrackedYamlLoader.java:119)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping2ndStep(BaseConstructor.java:480)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.constructMapping2ndStep(SafeConstructor.java:190)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping(BaseConstructor.java:461)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor$ConstructYamlMap.construct(SafeConstructor.java:556)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:220)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.constructObject(OriginTrackedYamlLoader.java:119)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping2ndStep(BaseConstructor.java:480)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor.constructMapping2ndStep(SafeConstructor.java:190)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructMapping(BaseConstructor.java:461)\r\n\tat org.yaml.snakeyaml.constructor.SafeConstructor$ConstructYamlMap.construct(SafeConstructor.java:556)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObjectNoCheck(BaseConstructor.java:230)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructObject(BaseConstructor.java:220)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.constructObject(OriginTrackedYamlLoader.java:119)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.constructDocument(BaseConstructor.java:174)\r\n\tat org.yaml.snakeyaml.constructor.BaseConstructor.getData(BaseConstructor.java:139)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader$OriginTrackingConstructor.getData(OriginTrackedYamlLoader.java:99)\r\n\tat org.yaml.snakeyaml.Yaml$1.next(Yaml.java:514)\r\n\tat org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:198)\r\n\tat org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:166)\r\n\tat org.springframework.boot.env.OriginTrackedYamlLoader.load(OriginTrackedYamlLoader.java:84)\r\n\tat org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:50)\r\n\tat org.springframework.boot.context.config.StandardConfigDataLoader.load(StandardConfigDataLoader.java:54)\r\n\tat org.springframework.boot.context.config.StandardConfigDataLoader.load(StandardConfigDataLoader.java:36)\r\n\tat org.springframework.boot.context.config.ConfigDataLoaders.load(ConfigDataLoaders.java:107)\r\n\tat org.springframework.boot.context.config.ConfigDataImporter.load(ConfigDataImporter.java:128)\r\n\tat org.springframework.boot.context.config.ConfigDataImporter.resolveAndLoad(ConfigDataImporter.java:86)\r\n\tat org.springframework.boot.context.config.ConfigDataEnvironmentContributors.withProcessedImports(ConfigDataEnvironmentContributors.java:116)\r\n\tat org.springframework.boot.context.config.ConfigDataEnvironment.processWithProfiles(ConfigDataEnvironment.java:311)\r\n\tat org.springframework.boot.context.config.ConfigDataEnvironment.processAndApply(ConfigDataEnvironment.java:232)\r\n\tat org.springframework.boot.context.config.ConfigDataEnvironmentPostProcessor.postProcessEnvironment(ConfigDataEnvironmentPostProcessor.java:102)\r\n\tat org.springframework.boot.context.config.ConfigDataEnvironmentPostProcessor.applyTo(ConfigDataEnvironmentPostProcessor.java:201)\r\n\tat org.springframework.cloud.config.server.environment.NativeEnvironmentRepository.findOne(NativeEnvironmentRepository.java:140)\r\n\t... 114 more\r\n","message":"Could not construct context for config=listing profile=dev label=null includeOrigin=true; nested exception is while constructing a mapping\n in 'reader', line 23, column 9:\n            input:\n            ^\nfound duplicate key input\n in 'reader', line 25, column 9:\n            input:\n            ^\n","path":"/listing/dev"}"
	at org.springframework.web.client.HttpServerErrorException.create(HttpServerErrorException.java:100)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:170)
	at org.springframework.web.client.DefaultResponseErrorHandler.handleError(DefaultResponseErrorHandler.java:122)
	at org.springframework.web.client.ResponseErrorHandler.handleError(ResponseErrorHandler.java:63)
	at org.springframework.web.client.RestTemplate.handleResponse(RestTemplate.java:819)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:777)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.config.client.ConfigServerConfigDataLoader.getRemoteEnvironment(ConfigServerConfigDataLoader.java:307)
	at org.springframework.cloud.config.client.ConfigServerConfigDataLoader.doLoad(ConfigServerConfigDataLoader.java:122)
	... 33 common frames omitted
2022-05-06 18:02:59,987 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Unregistering application LISTING with eureka with status DOWN
2022-05-06 18:02:59,987 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651840379987, current=DOWN, previous=UP]
2022-05-06 18:03:00,007 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Revoke previously assigned partitions input-0
2022-05-06 18:03:00,007 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f: partitions revoked: [input-0]
2022-05-06 18:03:00,008 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Member consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2-53601f35-90d9-45b3-9dc4-61c509159124 sending LeaveGroup request to coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2022-05-06 18:03:00,008 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 18:03:00,009 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 18:03:00,009 INFO org.apache.kafka.clients.consumer.KafkaConsumer [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Unsubscribed all topics or patterns and assigned partitions
2022-05-06 18:03:00,009 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 18:03:00,009 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2, groupId=anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 18:03:00,284 INFO org.apache.kafka.common.metrics.Metrics [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] Metrics scheduler closed
2022-05-06 18:03:00,284 INFO org.apache.kafka.common.metrics.Metrics [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 18:03:00,284 INFO org.apache.kafka.common.metrics.Metrics [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] Metrics reporters closed
2022-05-06 18:03:00,285 INFO org.apache.kafka.common.utils.AppInfoParser [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] App info kafka.consumer for consumer-anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f-2 unregistered
2022-05-06 18:03:00,286 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='input', partitions=1, dlqName='null'}.container-0-C-1] anonymous.61c68320-f14b-44ab-a101-ca03d1d8214f: Consumer stopped
2022-05-06 18:03:00,286 INFO org.springframework.core.log.LogAccessor [restartedMain] stopped org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@33d69293
2022-05-06 18:03:00,287 INFO org.springframework.core.log.LogAccessor [restartedMain] Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 18:03:00,287 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 0 subscriber(s).
2022-05-06 18:03:00,287 INFO org.springframework.core.log.LogAccessor [restartedMain] stopped bean '_org.springframework.integration.errorLogger'
2022-05-06 18:03:00,293 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Shutting down DiscoveryClient ...
2022-05-06 18:03:03,233 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-InstanceInfoReplicator-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 22 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 35 more

2022-05-06 18:03:03,233 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-InstanceInfoReplicator-0] Request execution failed with message: I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-06 18:03:03,234 WARN com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing - registration failed Cannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-06 18:03:03,234 WARN com.netflix.discovery.InstanceInfoReplicator [DiscoveryClient-InstanceInfoReplicator-0] There was a problem with the instance info replicator
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-06 18:03:03,235 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing: registering service...
2022-05-06 18:03:03,305 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Unregistering ...
2022-05-06 18:03:07,339 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-InstanceInfoReplicator-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.register(RestTemplateEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 22 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 35 more

2022-05-06 18:03:07,340 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-InstanceInfoReplicator-0] Request execution failed with message: I/O error on POST request for "http://localhost:8761/eureka/apps/LISTING": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-06 18:03:07,340 WARN com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing - registration failed Cannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-06 18:03:07,340 WARN com.netflix.discovery.InstanceInfoReplicator [DiscoveryClient-InstanceInfoReplicator-0] There was a problem with the instance info replicator
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56)
	at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:876)
	at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:121)
	at com.netflix.discovery.InstanceInfoReplicator$1.run(InstanceInfoReplicator.java:101)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-06 18:03:07,416 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [restartedMain] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8761/eureka/}, exception=I/O error on DELETE request for "http://localhost:8761/eureka/apps/LISTING/DESKTOP-UP4G20T:listing": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on DELETE request for "http://localhost:8761/eureka/apps/LISTING/DESKTOP-UP4G20T:listing": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.cancel(RestTemplateEurekaHttpClient.java:87)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.DiscoveryClient.unregister(DiscoveryClient.java:972)
	at com.netflix.discovery.DiscoveryClient.shutdown(DiscoveryClient.java:948)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeDestroyMethods(InitDestroyAnnotationBeanPostProcessor.java:347)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeDestruction(InitDestroyAnnotationBeanPostProcessor.java:177)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:197)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.run(DisposableBeanAdapter.java:190)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.destroy(GenericScope.java:390)
	at org.springframework.cloud.context.scope.GenericScope.destroy(GenericScope.java:136)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:213)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:587)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:559)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1161)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:520)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1154)
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1106)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1075)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.doClose(ServletWebServerApplicationContext.java:172)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:1021)
	at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:796)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 46 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 59 more

2022-05-06 18:03:07,416 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [restartedMain] Request execution failed with message: I/O error on DELETE request for "http://localhost:8761/eureka/apps/LISTING/DESKTOP-UP4G20T:listing": Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8761 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-06 18:03:07,418 ERROR com.netflix.discovery.DiscoveryClient [restartedMain] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing - de-registration failedCannot execute request on any known server
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$2.execute(EurekaHttpClientDecorator.java:74)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.cancel(EurekaHttpClientDecorator.java:71)
	at com.netflix.discovery.DiscoveryClient.unregister(DiscoveryClient.java:972)
	at com.netflix.discovery.DiscoveryClient.shutdown(DiscoveryClient.java:948)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleElement.invoke(InitDestroyAnnotationBeanPostProcessor.java:389)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor$LifecycleMetadata.invokeDestroyMethods(InitDestroyAnnotationBeanPostProcessor.java:347)
	at org.springframework.beans.factory.annotation.InitDestroyAnnotationBeanPostProcessor.postProcessBeforeDestruction(InitDestroyAnnotationBeanPostProcessor.java:177)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:197)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.run(DisposableBeanAdapter.java:190)
	at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.destroy(GenericScope.java:390)
	at org.springframework.cloud.context.scope.GenericScope.destroy(GenericScope.java:136)
	at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:213)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:587)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:559)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:1161)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:520)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:1154)
	at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1106)
	at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:1075)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.doClose(ServletWebServerApplicationContext.java:172)
	at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:1021)
	at org.springframework.boot.SpringApplication.handleRunFailure(SpringApplication.java:796)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:313)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
2022-05-06 18:03:07,489 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Completed shut down of DiscoveryClient
2022-05-06 18:15:20,800 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 18:15:20,804 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 27292 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 18:15:20,805 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 18:15:20,838 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 18:15:20,838 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 18:15:20,839 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 18:15:20,840 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 18:15:21,326 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 18:15:21,420 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 91 ms. Found 3 MongoDB repository interfaces.
2022-05-06 18:15:21,581 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 18:15:21,592 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 18:15:21,665 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 18:15:21,719 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 18:15:21,778 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 18:15:22,167 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 18:15:22,175 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 18:15:22,176 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 18:15:22,176 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 18:15:22,270 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 18:15:22,270 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1429 ms
2022-05-06 18:15:22,402 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 18:15:22,466 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627518624814df5ca5be1b22', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:83}] to localhost:27017
2022-05-06 18:15:22,466 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627518624814df5ca5be1b22', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:82}] to localhost:27017
2022-05-06 18:15:22,466 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627518624814df5ca5be1b22', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19525300}
2022-05-06 18:15:22,503 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 18:15:22,545 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 18:15:22,580 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 18:15:23,173 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 18:15:23,299 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 18:15:23,310 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 18:15:23,407 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 18:15:23,410 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 18:15:23,410 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 18:15:23,411 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 18:15:23,415 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 18:15:23,490 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 18:15:23,495 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 18:15:23,520 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 18:15:23,521 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 18:15:23,522 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 18:15:23,522 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 18:15:23,522 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 18:15:23,522 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 18:15:23,522 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 18:15:23,672 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 18:15:23,679 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 18:15:23,685 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 18:15:23,700 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651841123699 with initial instances count: 6
2022-05-06 18:15:23,701 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 18:15:23,701 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651841123701, current=UP, previous=STARTING]
2022-05-06 18:15:23,703 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 18:15:23,703 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 18:15:23,734 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 18:15:23,777 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 18:15:23,777 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 18:15:23,777 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 18:15:23,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 18:15:23,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 18:15:23,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 18:15:23,828 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 18:15:23,828 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 18:15:23,828 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 18:15:23,847 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 18:15:23,848 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 18:15:23,848 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 18:15:23,900 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 18:15:23,977 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:15:23,977 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:15:23,977 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651841123975
2022-05-06 18:15:24,368 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 18:15:24,371 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 18:15:24,371 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 18:15:24,372 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 18:15:24,383 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 18:15:24,418 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:15:24,418 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:15:24,418 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651841124418
2022-05-06 18:15:24,427 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-1, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 18:15:24,428 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-1, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 18:15:24,428 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-1, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 18:15:24,428 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 18:15:24,429 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 18:15:24,429 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 18:15:24,430 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-1 unregistered
2022-05-06 18:15:24,446 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e.errors' has 1 subscriber(s).
2022-05-06 18:15:24,446 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e.errors' has 0 subscriber(s).
2022-05-06 18:15:24,446 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e.errors' has 1 subscriber(s).
2022-05-06 18:15:24,446 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e.errors' has 2 subscriber(s).
2022-05-06 18:15:24,463 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 18:15:24,468 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 18:15:24,468 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 18:15:24,468 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651841124468
2022-05-06 18:15:24,469 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-06 18:15:24,473 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@bc0716e
2022-05-06 18:15:24,475 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 18:15:24,487 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-06 18:15:24,488 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 18:15:24,489 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 18:15:24,491 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 18:15:24,493 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 18:15:24,494 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 18:15:24,508 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: need to re-join with the given member-id
2022-05-06 18:15:24,509 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 18:15:24,515 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-5d238870-bb24-4712-947a-bee7d1751f3b', protocol='range'}
2022-05-06 18:15:24,518 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Finished assignment for group at generation 1: {consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-5d238870-bb24-4712-947a-bee7d1751f3b=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 18:15:24,526 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-5d238870-bb24-4712-947a-bee7d1751f3b', protocol='range'}
2022-05-06 18:15:24,527 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 18:15:24,529 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 18:15:24,534 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 18:15:24,539 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-06 18:15:24,546 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 18:15:24,552 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 18:15:24,579 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.128 seconds (JVM running for 5.59)
2022-05-06 18:16:01,219 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[222], headers={kafka_offset=22, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@de6065b, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651841158074, __TypeId__=[B@7a77a408, kafka_groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e}]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.cloud.stream.binding.DispatchingStreamListenerMessageHandler.handleRequestMessage(DispatchingStreamListenerMessageHandler.java:88)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 46 more

2022-05-06 18:16:01,224 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@22
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1], failedMessage=GenericMessage [payload=byte[222], headers={kafka_offset=22, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@de6065b, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651841158074, __TypeId__=[B@7a77a408, kafka_groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.converter.MessageConversionException: Could not read JSON: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]; nested exception is com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:237)
	at org.springframework.cloud.stream.converter.ApplicationJsonMessageMarshallingConverter.convertFromInternal(ApplicationJsonMessageMarshallingConverter.java:113)
	at org.springframework.messaging.converter.AbstractMessageConverter.fromMessage(AbstractMessageConverter.java:185)
	at org.springframework.messaging.converter.CompositeMessageConverter.fromMessage(CompositeMessageConverter.java:70)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.convertPayload(SmartMessageMethodArgumentResolver.java:129)
	at org.springframework.cloud.stream.config.SmartMessageMethodArgumentResolver.resolveArgument(SmartMessageMethodArgumentResolver.java:87)
	at org.springframework.messaging.handler.invocation.HandlerMethodArgumentResolverComposite.resolveArgument(HandlerMethodArgumentResolverComposite.java:118)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.getMethodArgumentValues(InvocableHandlerMethod.java:147)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:115)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.cloud.stream.binding.DispatchingStreamListenerMessageHandler.handleRequestMessage(DispatchingStreamListenerMessageHandler.java:88)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot construct instance of `com.cts.eauction.events.ProductEvent` (although at least one Creator exists): no String-argument constructor/factory method to deserialize from String value ('eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9')
 at [Source: (byte[])""eyJpZCI6ImIzYTY0OTkzLWQxMzMtNDhkNC05ZmVkLTI0ZDkwNTU5ZjAwMCIsImNyZWF0ZWQiOiIyMDIyLTA1LTA2VDEyOjQ1OjU4LjA1OSswMDowMCIsImV2ZW50VHlwZSI6IlBMQUNFQklEIiwicHJvZHVjdElkIjozOSwiYmlkQW1vdW50IjoyMDAsImJ1eWVySWQiOjEzLCJiaWRJZCI6MTJ9""; line: 1, column: 1]
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:63)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1728)
	at com.fasterxml.jackson.databind.DeserializationContext.handleMissingInstantiator(DeserializationContext.java:1353)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._deserializeFromString(StdDeserializer.java:311)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromString(BeanDeserializerBase.java:1495)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:196)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:186)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:322)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3723)
	at org.springframework.messaging.converter.MappingJackson2MessageConverter.convertFromInternal(MappingJackson2MessageConverter.java:223)
	... 46 common frames omitted
2022-05-06 18:17:57,568 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=42, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=100, bidEndDate=2022-10-10, sellerId=41]
2022-05-06 18:17:57,730 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:84}] to localhost:27017
2022-05-06 18:24:42,241 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Error sending fetch request (sessionId=674658274, epoch=439) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 18:24:42,242 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-06 18:24:42,292 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 18:24:42,295 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 18:24:42,684 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-5d238870-bb24-4712-947a-bee7d1751f3b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 18:24:42,684 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 18:24:42,685 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 18:24:42,685 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 18:24:42,685 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 18:24:42,687 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 18:24:42,687 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 18:24:42,688 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 18:24:42,722 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: need to re-join with the given member-id
2022-05-06 18:24:42,725 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 18:24:42,750 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-1190ce95-a78b-4682-9cd5-8ed245fcd6e0', protocol='range'}
2022-05-06 18:24:42,819 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Finished assignment for group at generation 3: {consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-1190ce95-a78b-4682-9cd5-8ed245fcd6e0=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 18:24:42,828 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-1190ce95-a78b-4682-9cd5-8ed245fcd6e0', protocol='range'}
2022-05-06 18:24:42,829 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 18:24:42,829 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 18:24:42,833 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=24, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 18:24:42,834 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 18:25:53,607 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 21:39:48,699 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Error sending fetch request (sessionId=588989172, epoch=535) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 21:39:48,706 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 21:39:48,958 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 21:39:51,174 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-1190ce95-a78b-4682-9cd5-8ed245fcd6e0', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 21:39:51,176 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 21:39:51,176 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 21:39:51,176 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 21:39:51,176 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 21:39:51,177 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 21:39:51,177 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 21:39:51,177 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 21:39:51,198 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: need to re-join with the given member-id
2022-05-06 21:39:51,199 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 21:39:51,205 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-8e91a4ab-ee7d-486b-9c38-0ebd5f7fefb1', protocol='range'}
2022-05-06 21:39:51,207 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Finished assignment for group at generation 5: {consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-8e91a4ab-ee7d-486b-9c38-0ebd5f7fefb1=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 21:39:51,212 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-8e91a4ab-ee7d-486b-9c38-0ebd5f7fefb1', protocol='range'}
2022-05-06 21:39:51,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 21:39:51,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 21:39:51,222 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=24, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 21:39:51,223 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 21:39:58,665 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Error sending fetch request (sessionId=1839206705, epoch=11) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 22:46:51,184 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-06 22:46:51,188 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Error sending fetch request (sessionId=1839206705, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-06 22:46:51,189 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-06 22:46:51,619 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 22:46:54,548 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Attempt to heartbeat with Generation{generationId=5, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-8e91a4ab-ee7d-486b-9c38-0ebd5f7fefb1', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-06 22:46:54,550 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 22:46:54,551 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-06 22:46:54,552 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-06 22:46:54,561 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-06 22:46:54,564 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions lost: [PRODUCT_TOPIC-0]
2022-05-06 22:46:54,565 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-06 22:46:54,566 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 22:46:56,035 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Request joining group due to: need to re-join with the given member-id
2022-05-06 22:46:56,037 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] (Re-)joining group
2022-05-06 22:46:56,495 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully joined group with generation Generation{generationId=7, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-705ad0b3-badd-4fbd-ae4a-cfd470488e39', protocol='range'}
2022-05-06 22:46:56,495 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Finished assignment for group at generation 7: {consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-705ad0b3-badd-4fbd-ae4a-cfd470488e39=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-06 22:46:56,607 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Successfully synced group in generation Generation{generationId=7, memberId='consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2-705ad0b3-badd-4fbd-ae4a-cfd470488e39', protocol='range'}
2022-05-06 22:46:56,608 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-06 22:46:56,608 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-06 22:46:56,692 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e-2, groupId=anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=24, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-06 22:46:56,693 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.af9102a4-b14e-4ad9-b9ff-c8b199f3e06e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-06 22:48:17,101 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 22:50:24,003 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-06 22:50:24,005 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 27384 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-06 22:50:24,006 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-06 22:50:24,040 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-06 22:50:24,040 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-06 22:50:24,041 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-06 22:50:24,041 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-06 22:50:24,552 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-06 22:50:24,655 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 99 ms. Found 3 MongoDB repository interfaces.
2022-05-06 22:50:24,898 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-06 22:50:24,920 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-06 22:50:25,001 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-06 22:50:25,057 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 22:50:25,134 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-06 22:50:25,600 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-06 22:50:25,610 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-06 22:50:25,611 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-06 22:50:25,611 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-06 22:50:25,710 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-06 22:50:25,711 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1668 ms
2022-05-06 22:50:25,842 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-06 22:50:25,906 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627558d9377bad43cd8ec6a0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:89}] to localhost:27017
2022-05-06 22:50:25,906 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627558d9377bad43cd8ec6a0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:90}] to localhost:27017
2022-05-06 22:50:25,906 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627558d9377bad43cd8ec6a0', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=20759000}
2022-05-06 22:50:25,945 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 22:50:25,997 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-06 22:50:26,030 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-06 22:50:26,641 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-06 22:50:26,772 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-06 22:50:26,787 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-06 22:50:26,884 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-06 22:50:26,886 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-06 22:50:26,887 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-06 22:50:26,887 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-06 22:50:26,893 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-06 22:50:26,988 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-06 22:50:26,992 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-06 22:50:27,018 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-06 22:50:27,207 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-06 22:50:27,215 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-06 22:50:27,223 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-06 22:50:27,240 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651857627238 with initial instances count: 6
2022-05-06 22:50:27,241 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-06 22:50:27,242 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651857627242, current=UP, previous=STARTING]
2022-05-06 22:50:27,243 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-06 22:50:27,244 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-06 22:50:27,274 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-06 22:50:27,305 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-06 22:50:27,305 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-06 22:50:27,306 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-06 22:50:27,353 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-06 22:50:27,353 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 22:50:27,353 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-06 22:50:27,369 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-06 22:50:27,369 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-06 22:50:27,369 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-06 22:50:27,390 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-06 22:50:27,390 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-06 22:50:27,390 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-06 22:50:27,444 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-06 22:50:27,539 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 22:50:27,540 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 22:50:27,540 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651857627538
2022-05-06 22:50:28,063 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-06 22:50:28,066 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-06 22:50:28,066 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 22:50:28,066 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-06 22:50:28,078 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 22:50:28,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 22:50:28,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 22:50:28,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651857628116
2022-05-06 22:50:28,125 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-1, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 22:50:28,128 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-1, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Resetting generation due to: consumer pro-actively leaving the group
2022-05-06 22:50:28,128 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-1, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: consumer pro-actively leaving the group
2022-05-06 22:50:28,128 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-06 22:50:28,128 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-06 22:50:28,128 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-06 22:50:28,129 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-1 unregistered
2022-05-06 22:50:28,156 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9.errors' has 1 subscriber(s).
2022-05-06 22:50:28,157 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9.errors' has 0 subscriber(s).
2022-05-06 22:50:28,157 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9.errors' has 1 subscriber(s).
2022-05-06 22:50:28,157 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9.errors' has 2 subscriber(s).
2022-05-06 22:50:28,176 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-06 22:50:28,183 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-06 22:50:28,183 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-06 22:50:28,184 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651857628183
2022-05-06 22:50:28,185 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-06 22:50:28,189 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@4836b1a9
2022-05-06 22:50:28,191 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-06 22:50:28,199 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-06 22:50:28,200 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-06 22:50:28,202 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-06 22:50:28,202 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-06 22:50:28,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-06 22:50:28,219 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-06 22:50:28,262 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: need to re-join with the given member-id
2022-05-06 22:50:28,262 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-06 22:50:28,282 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.788 seconds (JVM running for 6.322)
2022-05-06 22:50:28,283 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-91640d9d-5618-4828-8e2f-7f994b6ecf72', protocol='range'}
2022-05-06 22:50:28,284 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Finished assignment for group at generation 1: {consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-91640d9d-5618-4828-8e2f-7f994b6ecf72=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-06 22:50:28,396 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [kafka-coordinator-heartbeat-thread | anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-91640d9d-5618-4828-8e2f-7f994b6ecf72', protocol='range'}
2022-05-06 22:50:28,396 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-06 22:50:28,400 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-06 22:50:28,411 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 22:50:28,414 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-06 22:50:28,435 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-06 22:50:28,467 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-06 22:55:27,032 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-06 23:00:37,624 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
