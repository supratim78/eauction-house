2022-05-07 02:21:10,108 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 02:21:10,156 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=432942430, epoch=1276) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 02:21:10,275 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 02:21:10,277 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 02:21:12,386 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-91640d9d-5618-4828-8e2f-7f994b6ecf72', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 02:21:12,387 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 02:21:12,390 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 02:21:12,391 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 02:21:12,392 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 02:21:12,399 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 02:21:12,401 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 02:21:12,404 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-07 02:21:12,438 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: need to re-join with the given member-id
2022-05-07 02:21:12,440 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-07 02:21:12,850 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-b46c92aa-0cbb-477f-859f-7bdeaa53f309', protocol='range'}
2022-05-07 02:21:12,917 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Finished assignment for group at generation 3: {consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-b46c92aa-0cbb-477f-859f-7bdeaa53f309=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 02:21:13,529 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-b46c92aa-0cbb-477f-859f-7bdeaa53f309', protocol='range'}
2022-05-07 02:21:13,530 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 02:21:13,530 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 02:21:13,588 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 02:21:13,590 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 02:21:18,372 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=600657361, epoch=12) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 02:21:18,447 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 02:21:18,448 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=600657361, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 02:21:18,560 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 02:21:18,561 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=600657361, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:53:46,006 WARN org.apache.kafka.clients.NetworkClient [kafka-coordinator-heartbeat-thread | anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 04:53:46,007 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 04:53:46,437 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 04:53:47,245 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 04:53:48,451 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 04:53:53,302 WARN com.netflix.discovery.TimedSupervisorTask [DiscoveryClient-0] task supervisor timed out
java.util.concurrent.TimeoutException: null
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 04:54:23,179 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.4:9092) could not be established. Broker may not be available.
2022-05-07 04:54:23,180 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=600657361, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:54:24,204 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 04:54:24,210 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-b46c92aa-0cbb-477f-859f-7bdeaa53f309', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 04:54:24,211 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 04:54:24,212 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 04:54:24,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 04:54:24,214 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 04:54:24,216 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 04:54:24,216 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 04:54:24,217 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-07 04:54:24,225 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Request joining group due to: need to re-join with the given member-id
2022-05-07 04:54:24,225 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] (Re-)joining group
2022-05-07 04:54:24,234 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-2b273acd-5ac4-469d-ad16-4102edfe107c', protocol='range'}
2022-05-07 04:54:24,235 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Finished assignment for group at generation 5: {consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-2b273acd-5ac4-469d-ad16-4102edfe107c=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 04:54:24,242 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2-2b273acd-5ac4-469d-ad16-4102edfe107c', protocol='range'}
2022-05-07 04:54:24,242 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 04:54:24,243 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 04:54:24,248 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 04:54:24,250 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 04:54:43,863 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=38) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:54:43,863 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 04:54:45,986 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:48,109 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:48,110 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:54:50,383 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:52,822 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:52,823 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:54:55,782 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:58,682 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:54:58,682 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:01,619 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:04,785 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:07,815 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:07,816 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:10,774 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:13,872 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:13,873 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:19,973 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:22,128 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:22,129 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:24,351 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:26,638 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:29,099 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:31,997 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:31,999 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:34,908 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:37,819 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:37,830 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:41,021 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:43,929 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:43,933 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:46,418 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8010/eureka/} exception=I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:155)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 22 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 35 more

2022-05-07 04:55:46,419 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution failed with message: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-07 04:55:47,020 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:47,020 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:47,082 WARN com.netflix.discovery.TimedSupervisorTask [DiscoveryClient-0] task supervisor timed out
java.util.concurrent.TimeoutException: null
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
	at com.netflix.discovery.TimedSupervisorTask.run(TimedSupervisorTask.java:68)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 04:55:50,110 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:50,546 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8010/eureka/}, exception=I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:155)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 23 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 36 more

2022-05-07 04:55:50,548 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution failed with message: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-07 04:55:50,551 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-CacheRefreshExecutor-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - was unable to refresh its cache! This periodic background refresh will be retried in 5 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)

2022-05-07 04:55:53,073 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:53,073 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:55:56,295 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:55:59,343 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:56:00,494 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-HeartbeatExecutor-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8010/eureka/} exception=I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:99)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:91)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 19 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 32 more

2022-05-07 04:56:00,495 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-HeartbeatExecutor-0] Request execution failed with message: I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-07 04:56:01,224 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8010/eureka/}, exception=I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getApplicationsInternal(RestTemplateEurekaHttpClient.java:145)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.getDelta(RestTemplateEurekaHttpClient.java:155)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 23 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 36 more

2022-05-07 04:56:01,225 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-CacheRefreshExecutor-0] Request execution failed with message: I/O error on GET request for "http://localhost:8010/eureka/apps/delta": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-07 04:56:01,226 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-CacheRefreshExecutor-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - was unable to refresh its cache! This periodic background refresh will be retried in 5 seconds. status = Cannot execute request on any known server stacktrace = com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$7.execute(EurekaHttpClientDecorator.java:152)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getDelta(EurekaHttpClientDecorator.java:149)
	at com.netflix.discovery.DiscoveryClient.getAndUpdateDelta(DiscoveryClient.java:1135)
	at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:1016)
	at com.netflix.discovery.DiscoveryClient.refreshRegistry(DiscoveryClient.java:1531)
	at com.netflix.discovery.DiscoveryClient$CacheRefreshThread.run(DiscoveryClient.java:1498)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)

2022-05-07 04:56:02,295 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:56:02,295 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Error sending fetch request (sessionId=1329025107, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 04:56:04,601 INFO com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient [DiscoveryClient-HeartbeatExecutor-0] Request execution error. endpoint=DefaultEndpoint{ serviceUrl='http://localhost:8010/eureka/}, exception=I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect stacktrace=org.springframework.web.client.ResourceAccessException: I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:785)
	at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:711)
	at org.springframework.web.client.RestTemplate.exchange(RestTemplate.java:602)
	at org.springframework.cloud.netflix.eureka.http.RestTemplateEurekaHttpClient.sendHeartBeat(RestTemplateEurekaHttpClient.java:99)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:121)
	at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:80)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:120)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:156)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at org.springframework.http.client.HttpComponentsClientHttpRequest.executeInternal(HttpComponentsClientHttpRequest.java:87)
	at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)
	at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:66)
	at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:776)
	... 20 more
Caused by: java.net.ConnectException: Connection refused: connect
	at java.base/sun.nio.ch.Net.connect0(Native Method)
	at java.base/sun.nio.ch.Net.connect(Net.java:574)
	at java.base/sun.nio.ch.Net.connect(Net.java:563)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:588)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:333)
	at java.base/java.net.Socket.connect(Socket.java:648)
	at org.apache.http.conn.socket.PlainConnectionSocketFactory.connectSocket(PlainConnectionSocketFactory.java:75)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	... 33 more

2022-05-07 04:56:04,602 WARN com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient [DiscoveryClient-HeartbeatExecutor-0] Request execution failed with message: I/O error on PUT request for "http://localhost:8010/eureka/apps/LISTING/DESKTOP-UP4G20T:listing:8060": Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect; nested exception is org.apache.http.conn.HttpHostConnectException: Connect to localhost:8010 [localhost/127.0.0.1, localhost/0:0:0:0:0:0:0:1] failed: Connection refused: connect
2022-05-07 04:56:04,604 ERROR com.netflix.discovery.DiscoveryClient [DiscoveryClient-HeartbeatExecutor-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - was unable to send heartbeat!
com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server
	at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:112)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)
	at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)
	at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)
	at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:893)
	at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1457)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 04:56:05,519 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9-2, groupId=anonymous.2292b57a-4877-4bd0-a2dc-1dbbbda70ad9] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 04:58:57,342 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 04:58:57,343 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 30292 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 04:58:57,344 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 04:58:57,377 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 04:58:57,378 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 04:58:57,379 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 04:58:57,379 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 04:58:57,886 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 04:58:57,986 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 97 ms. Found 3 MongoDB repository interfaces.
2022-05-07 04:58:58,151 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 04:58:58,159 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 04:58:58,241 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-07 04:58:58,292 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 04:58:58,346 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 04:58:58,827 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 04:58:58,838 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 04:58:58,839 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 04:58:58,839 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 04:58:58,949 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 04:58:58,949 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1569 ms
2022-05-07 04:58:59,080 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 04:58:59,152 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275af3b1ddb6854bea33acc', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:93}] to localhost:27017
2022-05-07 04:58:59,152 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275af3b1ddb6854bea33acc', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:94}] to localhost:27017
2022-05-07 04:58:59,153 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275af3b1ddb6854bea33acc', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=23614100}
2022-05-07 04:58:59,190 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 04:58:59,244 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 04:58:59,292 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 04:58:59,896 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 04:59:00,041 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 04:59:00,053 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 04:59:00,143 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 04:59:00,148 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 04:59:00,149 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 04:59:00,149 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 04:59:00,157 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 04:59:00,255 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 04:59:00,260 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 04:59:00,286 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 04:59:00,286 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 04:59:00,286 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 04:59:00,286 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 04:59:00,286 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 04:59:00,287 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 04:59:00,287 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 04:59:00,484 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 04:59:00,492 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 04:59:00,500 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 04:59:00,519 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651879740518 with initial instances count: 3
2022-05-07 04:59:00,520 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 04:59:00,521 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651879740521, current=UP, previous=STARTING]
2022-05-07 04:59:00,522 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 04:59:00,523 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 04:59:00,562 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 04:59:00,591 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 04:59:00,591 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 04:59:00,592 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 04:59:00,635 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 04:59:00,635 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 04:59:00,635 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 04:59:00,649 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 04:59:00,649 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 04:59:00,649 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 04:59:00,668 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 04:59:00,668 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 04:59:00,669 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 04:59:00,721 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 04:59:00,806 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 04:59:00,806 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 04:59:00,806 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651879740804
2022-05-07 04:59:01,260 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 04:59:01,263 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 04:59:01,263 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 04:59:01,263 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 04:59:01,274 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 04:59:01,309 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 04:59:01,310 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 04:59:01,310 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651879741309
2022-05-07 04:59:01,321 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-1, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 04:59:01,324 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-1, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 04:59:01,324 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-1, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 04:59:01,324 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 04:59:01,324 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 04:59:01,324 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 04:59:01,326 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-1 unregistered
2022-05-07 04:59:01,352 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50.errors' has 1 subscriber(s).
2022-05-07 04:59:01,353 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50.errors' has 0 subscriber(s).
2022-05-07 04:59:01,353 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50.errors' has 1 subscriber(s).
2022-05-07 04:59:01,353 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50.errors' has 2 subscriber(s).
2022-05-07 04:59:01,369 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 04:59:01,374 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 04:59:01,375 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 04:59:01,375 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651879741374
2022-05-07 04:59:01,376 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 04:59:01,381 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@4dfc272a
2022-05-07 04:59:01,383 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 04:59:01,390 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 04:59:01,391 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 04:59:01,393 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 04:59:01,395 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 04:59:01,412 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 04:59:01,413 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] (Re-)joining group
2022-05-07 04:59:01,477 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Request joining group due to: need to re-join with the given member-id
2022-05-07 04:59:01,477 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] (Re-)joining group
2022-05-07 04:59:01,485 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.072 seconds (JVM running for 5.601)
2022-05-07 04:59:01,521 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2-4d06eeee-cff9-4516-bdbb-ff9f17d9a43c', protocol='range'}
2022-05-07 04:59:01,523 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Finished assignment for group at generation 1: {consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2-4d06eeee-cff9-4516-bdbb-ff9f17d9a43c=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 04:59:01,587 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2-4d06eeee-cff9-4516-bdbb-ff9f17d9a43c', protocol='range'}
2022-05-07 04:59:01,588 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 04:59:01,590 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 04:59:01,629 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 04:59:01,636 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 04:59:01,698 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50-2, groupId=anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 04:59:01,753 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5a420605-6996-4b8e-a79e-dbdf9ccc2c50: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 05:04:00,301 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:09:00,338 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:14:00,352 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:14:38,399 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 05:14:38,403 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 17064 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 05:14:38,403 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 05:14:38,438 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 05:14:38,438 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 05:14:38,439 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 05:14:38,440 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 05:14:38,911 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 05:14:39,009 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 95 ms. Found 3 MongoDB repository interfaces.
2022-05-07 05:14:39,191 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 05:14:39,205 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 05:14:39,291 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-07 05:14:39,350 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 05:14:39,400 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 05:14:39,881 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 05:14:39,890 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 05:14:39,891 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 05:14:39,891 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 05:14:39,990 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 05:14:39,990 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1550 ms
2022-05-07 05:14:40,107 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 05:14:40,164 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275b2e8c6c69f16b477dcc2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:96}] to localhost:27017
2022-05-07 05:14:40,164 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275b2e8c6c69f16b477dcc2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:95}] to localhost:27017
2022-05-07 05:14:40,165 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275b2e8c6c69f16b477dcc2', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=20275500}
2022-05-07 05:14:40,195 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 05:14:40,241 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 05:14:40,272 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 05:14:40,892 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 05:14:41,008 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 05:14:41,021 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 05:14:41,108 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 05:14:41,111 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 05:14:41,111 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 05:14:41,112 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 05:14:41,120 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 05:14:41,221 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 05:14:41,227 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 05:14:41,262 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 05:14:41,262 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 05:14:41,262 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 05:14:41,262 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 05:14:41,263 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 05:14:41,263 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 05:14:41,263 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 05:14:41,449 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 05:14:41,456 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 05:14:41,462 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 05:14:41,476 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651880681475 with initial instances count: 6
2022-05-07 05:14:41,477 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 05:14:41,477 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651880681477, current=UP, previous=STARTING]
2022-05-07 05:14:41,478 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 05:14:41,479 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 05:14:41,507 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 05:14:41,534 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 05:14:41,534 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 05:14:41,534 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 05:14:41,582 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 05:14:41,582 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 05:14:41,582 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 05:14:41,598 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 05:14:41,599 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 05:14:41,599 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 05:14:41,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 05:14:41,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 05:14:41,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 05:14:41,670 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 05:14:41,742 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:14:41,742 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:14:41,742 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651880681741
2022-05-07 05:14:42,162 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 05:14:42,164 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 05:14:42,166 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 05:14:42,166 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 05:14:42,176 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 05:14:42,210 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:14:42,211 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:14:42,211 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651880682210
2022-05-07 05:14:42,219 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-1, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 05:14:42,220 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-1, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 05:14:42,220 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-1, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 05:14:42,220 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 05:14:42,220 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 05:14:42,221 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 05:14:42,222 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-1 unregistered
2022-05-07 05:14:42,248 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa.errors' has 1 subscriber(s).
2022-05-07 05:14:42,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa.errors' has 0 subscriber(s).
2022-05-07 05:14:42,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa.errors' has 1 subscriber(s).
2022-05-07 05:14:42,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa.errors' has 2 subscriber(s).
2022-05-07 05:14:42,266 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 05:14:42,271 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:14:42,271 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:14:42,272 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651880682271
2022-05-07 05:14:42,274 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 05:14:42,277 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@502c76b9
2022-05-07 05:14:42,279 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 05:14:42,287 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 05:14:42,287 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 05:14:42,289 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 05:14:42,291 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] (Re-)joining group
2022-05-07 05:14:42,291 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 05:14:42,292 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 05:14:42,319 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Request joining group due to: need to re-join with the given member-id
2022-05-07 05:14:42,319 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] (Re-)joining group
2022-05-07 05:14:42,325 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2-1ede4e30-24db-4266-b32b-eb54fd520430', protocol='range'}
2022-05-07 05:14:42,328 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Finished assignment for group at generation 1: {consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2-1ede4e30-24db-4266-b32b-eb54fd520430=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 05:14:42,338 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2-1ede4e30-24db-4266-b32b-eb54fd520430', protocol='range'}
2022-05-07 05:14:42,339 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 05:14:42,342 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 05:14:42,351 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 05:14:42,356 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 05:14:42,368 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 05:14:42,374 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 05:14:42,385 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.98 seconds (JVM running for 5.574)
2022-05-07 05:19:41,273 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:24:41,289 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:29:41,305 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:33:04,810 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 05:33:04,925 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=2149) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:06,916 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:06,917 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:09,069 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:11,358 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:11,359 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:13,879 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:16,724 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:16,725 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:19,863 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:23,018 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:25,929 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:25,932 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:28,839 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:31,940 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:31,941 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:34,908 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:37,991 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:41,021 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:41,022 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:45,944 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:48,091 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:50,322 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:50,323 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:33:52,607 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:55,014 WARN org.apache.kafka.clients.NetworkClient [kafka-coordinator-heartbeat-thread | anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:33:57,726 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:01,002 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:01,002 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:04,160 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:07,332 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:10,431 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:10,433 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:13,457 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:16,667 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:16,667 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:19,747 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:22,725 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:25,753 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:25,754 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:28,904 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:32,166 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:35,448 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:35,448 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:38,352 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:41,310 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 05:34:41,310 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:41,310 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:44,283 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:47,325 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:50,359 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:50,364 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:53,331 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:56,539 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:34:56,540 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:34:59,436 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:02,650 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:05,556 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:05,557 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:08,776 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:11,934 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:11,935 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:14,906 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:17,811 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:20,851 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:20,852 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:24,070 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:27,167 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:27,167 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:30,065 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:33,344 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:36,302 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:36,303 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:39,267 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:42,235 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:42,236 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:45,137 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:48,417 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:51,501 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:35:51,502 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=1885640156, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:35:54,111 WARN org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error while fetching metadata with correlation id 2604 : {BIDS_PLACED_BY_BUYER=LEADER_NOT_AVAILABLE}
2022-05-07 05:35:54,223 WARN org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error while fetching metadata with correlation id 2606 : {BIDS_PLACED_BY_BUYER=LEADER_NOT_AVAILABLE}
2022-05-07 05:35:54,335 WARN org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error while fetching metadata with correlation id 2608 : {BIDS_PLACED_BY_BUYER=LEADER_NOT_AVAILABLE}
2022-05-07 05:35:54,443 WARN org.apache.kafka.clients.NetworkClient$DefaultMetadataUpdater [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error while fetching metadata with correlation id 2610 : {BIDS_PLACED_BY_BUYER=LEADER_NOT_AVAILABLE}
2022-05-07 05:35:54,551 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 05:35:54,556 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 05:38:41,599 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=90785339, epoch=325) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:38:41,599 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 05:38:43,750 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:38:45,913 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:38:45,914 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=90785339, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:38:48,131 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:38:50,651 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.7:9092) could not be established. Broker may not be available.
2022-05-07 05:38:50,651 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa-2, groupId=anonymous.eb823f01-99de-4895-81d1-a740bc8b4cfa] Error sending fetch request (sessionId=90785339, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 05:52:56,242 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 05:52:56,244 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 20548 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 05:52:56,245 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 05:52:56,284 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 05:52:56,284 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 05:52:56,285 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 05:52:56,285 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 05:52:56,880 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 05:52:56,985 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 101 ms. Found 3 MongoDB repository interfaces.
2022-05-07 05:52:57,165 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 05:52:57,173 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 05:52:57,258 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-07 05:52:57,312 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 05:52:57,368 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 05:52:57,902 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 05:52:57,913 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 05:52:57,913 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 05:52:57,913 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 05:52:58,042 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 05:52:58,042 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1756 ms
2022-05-07 05:52:58,220 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 05:52:58,317 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275bbe2ce2fba798d4d1306', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:2}] to localhost:27017
2022-05-07 05:52:58,317 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275bbe2ce2fba798d4d1306', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:1}] to localhost:27017
2022-05-07 05:52:58,318 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275bbe2ce2fba798d4d1306', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=48014100}
2022-05-07 05:52:58,329 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 05:52:58,382 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 05:52:58,418 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 05:52:59,102 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 05:52:59,229 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 05:52:59,242 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 05:52:59,353 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 05:52:59,357 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 05:52:59,357 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 05:52:59,357 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 05:52:59,362 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 05:52:59,451 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 05:52:59,456 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 05:52:59,483 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 05:52:59,483 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 05:52:59,483 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 05:52:59,484 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 05:52:59,484 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 05:52:59,484 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 05:52:59,484 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 05:52:59,688 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 05:52:59,694 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 05:52:59,701 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 05:52:59,717 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651882979716 with initial instances count: 4
2022-05-07 05:52:59,719 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 05:52:59,719 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651882979719, current=UP, previous=STARTING]
2022-05-07 05:52:59,721 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 05:52:59,721 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 05:52:59,765 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 05:52:59,789 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 05:52:59,790 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 05:52:59,790 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 05:52:59,839 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 05:52:59,839 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 05:52:59,839 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 05:52:59,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 05:52:59,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 05:52:59,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 05:52:59,875 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 05:52:59,875 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 05:52:59,875 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 05:52:59,931 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 05:53:00,008 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:53:00,008 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:53:00,008 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651882980006
2022-05-07 05:53:00,461 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 05:53:00,463 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 05:53:00,464 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 05:53:00,464 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 05:53:00,475 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 05:53:00,514 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:53:00,515 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:53:00,515 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651882980514
2022-05-07 05:53:00,524 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-1, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 05:53:00,525 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-1, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 05:53:00,525 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-1, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 05:53:00,526 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 05:53:00,526 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 05:53:00,526 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 05:53:00,528 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-1 unregistered
2022-05-07 05:53:00,551 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c.errors' has 1 subscriber(s).
2022-05-07 05:53:00,551 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c.errors' has 0 subscriber(s).
2022-05-07 05:53:00,551 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c.errors' has 1 subscriber(s).
2022-05-07 05:53:00,553 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c.errors' has 2 subscriber(s).
2022-05-07 05:53:00,570 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 05:53:00,576 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 05:53:00,576 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 05:53:00,576 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651882980576
2022-05-07 05:53:00,577 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 05:53:00,582 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1691bab8
2022-05-07 05:53:00,583 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 05:53:00,591 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 05:53:00,591 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 05:53:00,594 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 05:53:00,596 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 05:53:00,661 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 05:53:00,664 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] (Re-)joining group
2022-05-07 05:53:00,686 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.585 seconds (JVM running for 6.15)
2022-05-07 05:53:00,789 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Request joining group due to: need to re-join with the given member-id
2022-05-07 05:53:00,789 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] (Re-)joining group
2022-05-07 05:53:00,865 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2-a344ee6d-5221-4b37-8bf0-4bf382c5e889', protocol='range'}
2022-05-07 05:53:00,868 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Finished assignment for group at generation 1: {consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2-a344ee6d-5221-4b37-8bf0-4bf382c5e889=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 05:53:00,982 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2-a344ee6d-5221-4b37-8bf0-4bf382c5e889', protocol='range'}
2022-05-07 05:53:00,982 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 05:53:00,984 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 05:53:01,018 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 05:53:01,022 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 05:53:01,059 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c-2, groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=14, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 05:53:01,111 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 05:55:10,739 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [BidId=null, productId=null, bidAmount=null, buyerId=null], headers={kafka_offset=14, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4ecd2e2a, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651883110540, __TypeId__=[B@714ecf1a, kafka_groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c}]
2022-05-07 05:57:59,501 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:02:35,334 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [BidId=null, productId=null, bidAmount=null, buyerId=null], headers={kafka_offset=15, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4ecd2e2a, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651883555325, __TypeId__=[B@5747c1d3, kafka_groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c}]
2022-05-07 06:02:59,513 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:07:59,516 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:08:16,881 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [BidId=null, productId=null, bidAmount=null, buyerId=null], headers={kafka_offset=16, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4ecd2e2a, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651883896826, __TypeId__=[B@52287760, kafka_groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c}]
2022-05-07 06:12:49,926 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [BidId=null, productId=null, bidAmount=null, buyerId=null], headers={kafka_offset=17, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4ecd2e2a, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651884169870, __TypeId__=[B@76ff6317, kafka_groupId=anonymous.a49bec04-da01-40b9-8732-f2df3a2b1b1c}]
2022-05-07 06:12:59,523 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:16:30,000 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 15892 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:16:30,001 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:16:30,003 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:16:30,043 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:16:30,043 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:16:30,044 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:16:30,045 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:16:30,673 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:16:30,778 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 100 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:16:30,940 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:16:30,948 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:16:31,031 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-07 06:16:31,084 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:16:31,149 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:16:31,624 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:16:31,634 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:16:31,635 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:16:31,635 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:16:31,746 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:16:31,746 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1701 ms
2022-05-07 06:16:31,892 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:16:31,975 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c167c79a34248d22fee5', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:3}] to localhost:27017
2022-05-07 06:16:31,975 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c167c79a34248d22fee5', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
2022-05-07 06:16:31,976 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c167c79a34248d22fee5', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=28129400}
2022-05-07 06:16:32,019 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:16:32,096 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:16:32,131 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:16:32,792 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:16:32,947 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:16:32,962 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:16:33,056 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 06:16:33,060 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 06:16:33,061 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 06:16:33,061 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 06:16:33,066 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 06:16:33,181 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 06:16:33,187 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 06:16:33,218 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 06:16:33,218 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 06:16:33,218 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 06:16:33,218 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 06:16:33,219 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 06:16:33,219 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 06:16:33,219 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 06:16:33,420 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 06:16:33,428 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 06:16:33,436 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 06:16:33,453 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651884393453 with initial instances count: 6
2022-05-07 06:16:33,454 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 06:16:33,455 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651884393455, current=UP, previous=STARTING]
2022-05-07 06:16:33,456 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 06:16:33,457 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 06:16:33,497 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 06:16:33,535 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 06:16:33,535 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:16:33,536 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 06:16:33,587 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 06:16:33,587 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:16:33,587 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 06:16:33,607 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 06:16:33,607 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:16:33,607 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 06:16:33,630 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 06:16:33,631 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:16:33,631 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:16:33,684 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:16:33,769 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:16:33,770 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:16:33,770 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651884393768
2022-05-07 06:16:34,214 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 06:16:34,217 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 06:16:34,217 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:16:34,217 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 06:16:34,231 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.aaa30f56-947b-4733-844b-395e027234fd
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:16:34,270 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:16:34,270 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:16:34,270 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651884394270
2022-05-07 06:16:34,279 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-1, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:16:34,280 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-1, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:16:34,280 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-1, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:16:34,281 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:16:34,281 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:16:34,281 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:16:34,282 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-1 unregistered
2022-05-07 06:16:34,303 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.aaa30f56-947b-4733-844b-395e027234fd.errors' has 1 subscriber(s).
2022-05-07 06:16:34,303 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.aaa30f56-947b-4733-844b-395e027234fd.errors' has 0 subscriber(s).
2022-05-07 06:16:34,304 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.aaa30f56-947b-4733-844b-395e027234fd.errors' has 1 subscriber(s).
2022-05-07 06:16:34,304 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.aaa30f56-947b-4733-844b-395e027234fd.errors' has 2 subscriber(s).
2022-05-07 06:16:34,353 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.aaa30f56-947b-4733-844b-395e027234fd
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:16:34,364 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:16:34,364 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:16:34,364 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651884394364
2022-05-07 06:16:34,366 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 06:16:34,374 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@66a326d6
2022-05-07 06:16:34,377 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 06:16:34,384 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 06:16:34,385 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:16:34,394 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 06:16:34,394 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:16:34,396 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 06:16:34,397 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] (Re-)joining group
2022-05-07 06:16:34,445 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:16:34,446 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] (Re-)joining group
2022-05-07 06:16:34,459 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2-2724c88e-e24f-495f-9e86-a5637502b5f7', protocol='range'}
2022-05-07 06:16:34,461 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Finished assignment for group at generation 1: {consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2-2724c88e-e24f-495f-9e86-a5637502b5f7=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 06:16:34,477 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2-2724c88e-e24f-495f-9e86-a5637502b5f7', protocol='range'}
2022-05-07 06:16:34,478 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 06:16:34,481 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 06:16:34,483 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 6.291 seconds (JVM running for 6.862)
2022-05-07 06:16:34,488 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:16:34,492 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:16:34,508 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.aaa30f56-947b-4733-844b-395e027234fd-2, groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=18, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:16:34,513 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.aaa30f56-947b-4733-844b-395e027234fd: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 06:16:41,430 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [BidId=null, productId=null, bidAmount=null, buyerId=null], headers={kafka_offset=18, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@7b1ed623, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651884401385, __TypeId__=[B@725a6b55, kafka_groupId=anonymous.aaa30f56-947b-4733-844b-395e027234fd}]
2022-05-07 06:21:33,235 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:26:33,237 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:31:33,240 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:35:26,080 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:35:26,082 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 20784 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:35:26,084 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:35:26,118 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:35:26,119 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:35:26,120 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:35:26,120 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:35:26,577 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:35:26,661 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 81 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:35:26,808 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:35:26,816 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:35:26,889 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=89c04742-706b-323a-8c89-379a6eb54cc4
2022-05-07 06:35:26,938 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:35:26,976 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:35:27,352 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:35:27,359 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:35:27,359 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:35:27,359 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:35:27,444 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:35:27,444 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1324 ms
2022-05-07 06:35:27,542 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:35:27,589 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c5d769b2d14d601cd0cf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:6}] to localhost:27017
2022-05-07 06:35:27,589 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c5d769b2d14d601cd0cf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:5}] to localhost:27017
2022-05-07 06:35:27,589 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c5d769b2d14d601cd0cf', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16286100}
2022-05-07 06:35:27,618 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:35:27,656 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:35:27,684 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:35:28,220 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:35:28,333 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:35:28,345 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:35:28,439 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 06:35:28,441 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 06:35:28,441 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 06:35:28,442 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 06:35:28,447 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 06:35:28,513 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 06:35:28,517 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 06:35:28,538 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 06:35:28,676 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 06:35:28,682 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 06:35:28,687 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 06:35:28,700 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651885528699 with initial instances count: 6
2022-05-07 06:35:28,701 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 06:35:28,701 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651885528701, current=UP, previous=STARTING]
2022-05-07 06:35:28,702 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 06:35:28,703 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 06:35:28,733 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 06:35:28,753 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 06:35:28,753 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:35:28,754 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 06:35:28,801 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 06:35:28,801 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:35:28,801 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 06:35:28,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 06:35:28,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:35:28,815 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 06:35:28,832 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 06:35:28,832 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:35:28,832 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:35:28,874 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:35:28,940 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:35:28,940 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:35:28,940 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885528939
2022-05-07 06:35:29,178 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 06:35:29,181 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 06:35:29,181 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:35:29,181 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 06:35:29,191 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:35:29,225 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:35:29,225 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:35:29,225 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885529225
2022-05-07 06:35:29,232 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-1, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:35:29,232 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-1, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:35:29,233 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-1, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:35:29,233 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:35:29,233 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:35:29,233 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:35:29,234 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-1 unregistered
2022-05-07 06:35:29,248 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e.errors' has 1 subscriber(s).
2022-05-07 06:35:29,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e.errors' has 0 subscriber(s).
2022-05-07 06:35:29,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e.errors' has 1 subscriber(s).
2022-05-07 06:35:29,249 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e.errors' has 2 subscriber(s).
2022-05-07 06:35:29,263 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:35:29,268 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:35:29,268 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:35:29,268 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885529267
2022-05-07 06:35:29,269 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 06:35:29,271 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@6622fd5f
2022-05-07 06:35:29,272 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 06:35:29,277 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 06:35:29,277 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:35:29,279 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:35:29,281 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 06:35:29,281 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] (Re-)joining group
2022-05-07 06:35:29,281 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 06:35:29,297 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:35:29,298 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] (Re-)joining group
2022-05-07 06:35:29,302 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2-5c14a35d-42e8-4d15-bd77-7beb0debaad7', protocol='range'}
2022-05-07 06:35:29,304 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Finished assignment for group at generation 1: {consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2-5c14a35d-42e8-4d15-bd77-7beb0debaad7=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 06:35:29,312 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2-5c14a35d-42e8-4d15-bd77-7beb0debaad7', protocol='range'}
2022-05-07 06:35:29,312 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 06:35:29,315 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 06:35:29,319 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:35:29,323 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:35:29,340 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e-2, groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=19, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:35:29,348 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 06:35:29,378 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.162 seconds (JVM running for 4.623)
2022-05-07 06:35:41,553 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [bidId=23, productId=39, bidAmount=200, buyerId=24, id=f935c6ae-ee6d-4a39-aa2d-11df3303bda8, created=Sat May 07 06:35:41 IST 2022, eventType=PLACEBID], headers={kafka_offset=19, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@50210884, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885541461, kafka_groupId=anonymous.d9cc40c5-c68e-4b17-9fee-f19e243ce14e}]
2022-05-07 06:35:41,555 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Bid consumed from topic Bid [id=23, productid=39, bidAmount=200, sellerId=24]
2022-05-07 06:35:41,665 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:7}] to localhost:27017
2022-05-07 06:40:28,551 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:41:25,991 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:41:25,994 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 22160 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:41:25,995 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:41:26,026 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:41:26,026 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:41:26,027 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:41:26,027 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:41:26,507 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:41:26,608 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 95 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:41:26,750 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:41:26,758 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:41:26,834 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 06:41:26,887 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:41:26,938 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:41:27,376 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:41:27,385 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:41:27,386 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:41:27,386 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:41:27,482 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:41:27,483 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1454 ms
2022-05-07 06:41:27,582 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:41:27,627 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c73fc8acfa23e5909584', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:21}] to localhost:27017
2022-05-07 06:41:27,627 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c73fc8acfa23e5909584', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:20}] to localhost:27017
2022-05-07 06:41:27,628 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c73fc8acfa23e5909584', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14653300}
2022-05-07 06:41:27,663 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:41:27,708 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:41:27,737 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:41:28,285 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:41:28,401 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:41:28,415 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:41:28,498 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 06:41:28,501 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 06:41:28,501 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 06:41:28,501 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 06:41:28,506 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 06:41:28,597 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 06:41:28,601 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 06:41:28,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 06:41:28,833 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 06:41:28,841 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 06:41:28,847 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 06:41:28,860 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651885888859 with initial instances count: 6
2022-05-07 06:41:28,861 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 06:41:28,862 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651885888862, current=UP, previous=STARTING]
2022-05-07 06:41:28,863 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 06:41:28,864 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 06:41:28,893 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 06:41:28,919 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 06:41:28,919 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:41:28,919 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 06:41:28,962 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 06:41:28,962 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:41:28,962 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 06:41:28,976 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 06:41:28,976 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:41:28,976 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 06:41:29,001 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 06:41:29,002 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:41:29,002 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:41:29,055 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:41:29,124 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:29,124 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:29,124 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885889123
2022-05-07 06:41:30,007 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 06:41:30,011 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 06:41:30,011 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:41:30,011 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 06:41:30,021 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:41:30,055 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:30,056 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:30,056 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885890055
2022-05-07 06:41:30,064 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-1, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:41:30,065 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-1, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:41:30,066 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-1, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:41:30,066 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:41:30,066 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:41:30,066 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:41:30,067 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-1 unregistered
2022-05-07 06:41:30,083 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47.errors' has 1 subscriber(s).
2022-05-07 06:41:30,084 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47.errors' has 0 subscriber(s).
2022-05-07 06:41:30,084 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47.errors' has 1 subscriber(s).
2022-05-07 06:41:30,084 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47.errors' has 2 subscriber(s).
2022-05-07 06:41:30,099 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:41:30,103 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:30,103 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:30,103 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885890103
2022-05-07 06:41:30,104 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Subscribed to topic(s): bidinput
2022-05-07 06:41:30,107 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7f1a2ed7
2022-05-07 06:41:30,108 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:41:30,108 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:41:30,109 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:41:30,109 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:41:30,109 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:41:30,110 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:41:30,113 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:30,114 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:30,114 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885890113
2022-05-07 06:41:30,114 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Resetting the last seen epoch of partition bidinput-0 to 0 since the associated topicId changed from null to 6T_Z8KcQTdOuaemCJ51LDw
2022-05-07 06:41:30,114 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:41:30,115 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:41:30,117 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] (Re-)joining group
2022-05-07 06:41:30,125 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 06:41:30,126 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 06:41:30,126 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:41:30,126 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 06:41:30,127 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.7ffbd424-8125-4804-ac10-41a2386ee272
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:41:30,129 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:41:30,129 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] (Re-)joining group
2022-05-07 06:41:30,131 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:30,132 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:30,132 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885890131
2022-05-07 06:41:30,132 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2-6b71db01-c940-4b04-9d12-b8a2da6b27e1', protocol='range'}
2022-05-07 06:41:30,134 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Finished assignment for group at generation 1: {consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2-6b71db01-c940-4b04-9d12-b8a2da6b27e1=Assignment(partitions=[bidinput-0])}
2022-05-07 06:41:30,136 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-3, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:41:30,137 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-3, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:41:30,137 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-3, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:41:30,138 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:41:30,138 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:41:30,138 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:41:30,139 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-3 unregistered
2022-05-07 06:41:30,141 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.7ffbd424-8125-4804-ac10-41a2386ee272.errors' has 1 subscriber(s).
2022-05-07 06:41:30,142 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.7ffbd424-8125-4804-ac10-41a2386ee272.errors' has 0 subscriber(s).
2022-05-07 06:41:30,142 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.7ffbd424-8125-4804-ac10-41a2386ee272.errors' has 1 subscriber(s).
2022-05-07 06:41:30,142 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.7ffbd424-8125-4804-ac10-41a2386ee272.errors' has 2 subscriber(s).
2022-05-07 06:41:30,142 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2-6b71db01-c940-4b04-9d12-b8a2da6b27e1', protocol='range'}
2022-05-07 06:41:30,142 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Notifying assignor about the new Assignment(partitions=[bidinput-0])
2022-05-07 06:41:30,143 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.7ffbd424-8125-4804-ac10-41a2386ee272
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:41:30,144 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Adding newly assigned partitions: bidinput-0
2022-05-07 06:41:30,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:41:30,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:41:30,149 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651885890149
2022-05-07 06:41:30,149 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 06:41:30,150 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Found no committed offset for partition bidinput-0
2022-05-07 06:41:30,150 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@6037c36d
2022-05-07 06:41:30,152 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 06:41:30,155 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Found no committed offset for partition bidinput-0
2022-05-07 06:41:30,156 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 06:41:30,156 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:41:30,157 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:41:30,158 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] (Re-)joining group
2022-05-07 06:41:30,163 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:41:30,164 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] (Re-)joining group
2022-05-07 06:41:30,165 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47-2, groupId=anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47] Resetting offset for partition bidinput-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:41:30,166 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4-b4cf4fdd-6f37-4b2e-ae95-436e53df5766', protocol='range'}
2022-05-07 06:41:30,166 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Finished assignment for group at generation 1: {consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4-b4cf4fdd-6f37-4b2e-ae95-436e53df5766=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 06:41:30,171 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 06:41:30,172 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 06:41:30,175 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4-b4cf4fdd-6f37-4b2e-ae95-436e53df5766', protocol='range'}
2022-05-07 06:41:30,175 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a746a31d-ebec-4c18-a06b-8a9008338e47: partitions assigned: [bidinput-0]
2022-05-07 06:41:30,175 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 06:41:30,175 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 06:41:30,176 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:41:30,178 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:41:30,183 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7ffbd424-8125-4804-ac10-41a2386ee272-4, groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=20, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:41:30,186 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.7ffbd424-8125-4804-ac10-41a2386ee272: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 06:41:30,242 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.096 seconds (JVM running for 5.552)
2022-05-07 06:41:38,936 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'listing.input'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}], failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:76)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:139)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	... 28 more

2022-05-07 06:41:38,945 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for BIDS_PLACED_BY_BUYER-0@20
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'listing.input'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}], failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'listing.input'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[165], headers={kafka_offset=20, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@34ff90d5, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651885895894, kafka_groupId=anonymous.7ffbd424-8125-4804-ac10-41a2386ee272}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:76)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:139)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	... 28 common frames omitted
2022-05-07 06:46:28,637 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 06:46:43,515 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:46:43,516 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 17352 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:46:43,518 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:46:43,551 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:46:43,551 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:46:43,552 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:46:43,553 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:46:44,063 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:46:44,170 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 104 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:46:44,325 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:46:44,333 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:46:44,409 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=659815e2-f104-32a8-bc35-ffef4d0c56e8
2022-05-07 06:46:44,458 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:46:44,516 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:46:45,073 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:46:45,083 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:46:45,083 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:46:45,083 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:46:45,185 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:46:45,185 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1632 ms
2022-05-07 06:46:45,290 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:46:45,335 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c87d0c5889767cf38265', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:22}] to localhost:27017
2022-05-07 06:46:45,335 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c87d0c5889767cf38265', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:23}] to localhost:27017
2022-05-07 06:46:45,336 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c87d0c5889767cf38265', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15440000}
2022-05-07 06:46:45,368 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:46:45,411 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:46:45,441 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:46:46,020 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:46:46,170 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:46:46,183 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:46:46,277 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 06:46:46,280 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 06:46:46,280 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 06:46:46,280 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 06:46:46,286 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 06:46:46,380 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 06:46:46,385 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 06:46:46,411 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 06:46:46,582 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 06:46:46,589 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 06:46:46,596 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 06:46:46,611 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651886206609 with initial instances count: 6
2022-05-07 06:46:46,612 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 06:46:46,612 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651886206612, current=UP, previous=STARTING]
2022-05-07 06:46:46,614 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 06:46:46,614 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 06:46:46,643 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 06:46:46,670 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 06:46:46,670 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:46:46,670 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 06:46:46,716 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 06:46:46,716 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:46:46,716 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 06:46:46,731 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 06:46:46,731 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:46:46,731 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 06:46:46,750 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 06:46:46,751 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:46:46,751 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:46:46,800 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:46:46,874 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:46:46,874 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:46:46,874 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886206873
2022-05-07 06:46:47,217 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 06:46:47,220 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 06:46:47,220 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:46:47,220 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 06:46:47,231 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:46:47,269 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:46:47,269 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:46:47,269 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886207269
2022-05-07 06:46:47,277 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-1, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:46:47,277 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-1, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:46:47,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-1, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:46:47,278 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:46:47,278 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:46:47,278 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:46:47,280 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-1 unregistered
2022-05-07 06:46:47,295 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f.errors' has 1 subscriber(s).
2022-05-07 06:46:47,295 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f.errors' has 0 subscriber(s).
2022-05-07 06:46:47,295 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f.errors' has 1 subscriber(s).
2022-05-07 06:46:47,295 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'bidinput.anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f.errors' has 2 subscriber(s).
2022-05-07 06:46:47,309 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:46:47,314 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:46:47,314 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:46:47,314 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886207314
2022-05-07 06:46:47,315 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Subscribed to topic(s): bidinput
2022-05-07 06:46:47,318 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@306dcce0
2022-05-07 06:46:47,319 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 06:46:47,324 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Resetting the last seen epoch of partition bidinput-0 to 0 since the associated topicId changed from null to 6T_Z8KcQTdOuaemCJ51LDw
2022-05-07 06:46:47,325 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:46:47,325 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:46:47,328 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] (Re-)joining group
2022-05-07 06:46:47,329 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 06:46:47,329 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 06:46:47,342 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:46:47,342 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] (Re-)joining group
2022-05-07 06:46:47,346 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2-47610c98-7ea0-4c75-8a48-81b98bfe4e6d', protocol='range'}
2022-05-07 06:46:47,348 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Finished assignment for group at generation 1: {consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2-47610c98-7ea0-4c75-8a48-81b98bfe4e6d=Assignment(partitions=[bidinput-0])}
2022-05-07 06:46:47,354 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2-47610c98-7ea0-4c75-8a48-81b98bfe4e6d', protocol='range'}
2022-05-07 06:46:47,355 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Notifying assignor about the new Assignment(partitions=[bidinput-0])
2022-05-07 06:46:47,357 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Adding newly assigned partitions: bidinput-0
2022-05-07 06:46:47,361 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Found no committed offset for partition bidinput-0
2022-05-07 06:46:47,366 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Found no committed offset for partition bidinput-0
2022-05-07 06:46:47,376 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f-2, groupId=anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f] Resetting offset for partition bidinput-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:46:47,382 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='bidinput', partitions=1, dlqName='null'}.container-0-C-1] anonymous.c22c2827-6af3-4539-92f5-dd2866076f8f: partitions assigned: [bidinput-0]
2022-05-07 06:46:47,418 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.905 seconds (JVM running for 5.407)
2022-05-07 06:51:53,023 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:51:53,024 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 22252 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:51:53,025 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:51:53,058 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:51:53,058 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:51:53,059 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:51:53,060 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:51:53,593 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:51:53,691 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 95 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:51:53,851 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:51:53,860 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:51:53,937 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=659815e2-f104-32a8-bc35-ffef4d0c56e8
2022-05-07 06:51:53,989 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:51:54,040 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:51:54,505 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:51:54,515 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:51:54,515 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:51:54,515 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:51:54,616 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:51:54,616 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1556 ms
2022-05-07 06:51:54,728 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:51:54,778 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c9b2b5281a133814f79a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:24}] to localhost:27017
2022-05-07 06:51:54,778 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c9b2b5281a133814f79a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:25}] to localhost:27017
2022-05-07 06:51:54,778 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c9b2b5281a133814f79a', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16504600}
2022-05-07 06:51:54,808 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:51:54,858 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:51:54,888 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:51:55,499 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:51:55,631 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:51:55,644 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:51:55,736 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 06:51:55,737 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'input' available
2022-05-07 06:51:55,744 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-07 06:51:55,757 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-07 06:51:55,774 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

A component required a bean named 'input' that could not be found.


Action:

Consider defining a bean named 'input' in your configuration.

2022-05-07 06:52:52,572 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:52:52,575 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 7416 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:52:52,576 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:52:52,609 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:52:52,609 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:52:52,610 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:52:52,611 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:52:53,106 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:52:53,202 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 93 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:52:53,392 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:52:53,402 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:52:53,480 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=659815e2-f104-32a8-bc35-ffef4d0c56e8
2022-05-07 06:52:53,532 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:52:53,587 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:52:53,982 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:52:53,992 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:52:53,992 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:52:53,992 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:52:54,090 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:52:54,091 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1479 ms
2022-05-07 06:52:54,219 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:52:54,279 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275c9eeaa7ebc5503980254', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:26}] to localhost:27017
2022-05-07 06:52:54,279 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c9eeaa7ebc5503980254', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:27}] to localhost:27017
2022-05-07 06:52:54,280 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275c9eeaa7ebc5503980254', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16833300}
2022-05-07 06:52:54,312 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:52:54,360 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:52:54,393 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:52:55,108 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:52:55,335 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:52:55,357 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:52:55,516 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'input' available
2022-05-07 06:52:55,527 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-07 06:52:55,547 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-07 06:52:55,571 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

A component required a bean named 'input' that could not be found.


Action:

Consider defining a bean named 'input' in your configuration.

2022-05-07 06:54:03,410 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 06:54:03,411 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 18016 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 06:54:03,411 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 06:54:03,442 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 06:54:03,442 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 06:54:03,443 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 06:54:03,444 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 06:54:03,920 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 06:54:04,013 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 91 ms. Found 3 MongoDB repository interfaces.
2022-05-07 06:54:04,163 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 06:54:04,171 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 06:54:04,245 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 06:54:04,294 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:54:04,350 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 06:54:04,745 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 06:54:04,751 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 06:54:04,751 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 06:54:04,752 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 06:54:04,838 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 06:54:04,838 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1394 ms
2022-05-07 06:54:04,955 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 06:54:05,009 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275ca34311fec425ce50072', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:29}] to localhost:27017
2022-05-07 06:54:05,009 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275ca34311fec425ce50072', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:28}] to localhost:27017
2022-05-07 06:54:05,009 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275ca34311fec425ce50072', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17086200}
2022-05-07 06:54:05,037 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:54:05,081 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 06:54:05,112 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 06:54:05,710 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 06:54:05,846 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 06:54:05,860 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 06:54:05,960 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 06:54:05,960 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 06:54:05,964 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 06:54:05,964 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 06:54:05,964 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 06:54:05,971 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 06:54:06,036 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 06:54:06,041 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 06:54:06,063 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 06:54:06,064 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 06:54:06,213 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 06:54:06,219 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 06:54:06,225 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 06:54:06,237 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651886646237 with initial instances count: 6
2022-05-07 06:54:06,238 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 06:54:06,239 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651886646239, current=UP, previous=STARTING]
2022-05-07 06:54:06,240 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 06:54:06,240 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 06:54:06,270 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 06:54:06,292 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 06:54:06,294 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:54:06,294 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 06:54:06,338 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 06:54:06,338 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:54:06,338 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 06:54:06,351 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 06:54:06,352 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:54:06,352 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 06:54:06,369 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 06:54:06,370 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:54:06,370 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:54:06,417 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:54:06,493 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,493 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,493 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646491
2022-05-07 06:54:06,827 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 06:54:06,830 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 06:54:06,830 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:54:06,830 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 06:54:06,843 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:54:06,879 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,879 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,880 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646879
2022-05-07 06:54:06,887 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-1, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:54:06,888 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-1, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:54:06,888 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-1, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:54:06,888 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:54:06,888 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:54:06,888 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:54:06,890 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-1 unregistered
2022-05-07 06:54:06,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6.errors' has 1 subscriber(s).
2022-05-07 06:54:06,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6.errors' has 0 subscriber(s).
2022-05-07 06:54:06,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6.errors' has 1 subscriber(s).
2022-05-07 06:54:06,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6.errors' has 2 subscriber(s).
2022-05-07 06:54:06,928 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:54:06,932 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,932 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,932 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646932
2022-05-07 06:54:06,933 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 06:54:06,935 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@365fb870
2022-05-07 06:54:06,937 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 06:54:06,937 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:54:06,937 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 06:54:06,937 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 06:54:06,937 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 06:54:06,938 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 06:54:06,941 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,941 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,941 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646941
2022-05-07 06:54:06,942 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 06:54:06,943 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:54:06,944 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:54:06,945 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] (Re-)joining group
2022-05-07 06:54:06,953 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 06:54:06,954 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 06:54:06,954 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:54:06,954 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 06:54:06,955 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:54:06,957 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:54:06,958 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] (Re-)joining group
2022-05-07 06:54:06,960 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,960 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,960 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646960
2022-05-07 06:54:06,963 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-2f24a846-121f-4c49-9931-a84640423419', protocol='range'}
2022-05-07 06:54:06,964 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-3, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:54:06,965 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-3, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 06:54:06,965 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-3, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 06:54:06,965 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 06:54:06,966 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 06:54:06,966 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 06:54:06,966 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Finished assignment for group at generation 1: {consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-2f24a846-121f-4c49-9931-a84640423419=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 06:54:06,967 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-3 unregistered
2022-05-07 06:54:06,969 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32.errors' has 1 subscriber(s).
2022-05-07 06:54:06,969 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32.errors' has 0 subscriber(s).
2022-05-07 06:54:06,969 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32.errors' has 1 subscriber(s).
2022-05-07 06:54:06,969 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32.errors' has 2 subscriber(s).
2022-05-07 06:54:06,970 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 06:54:06,976 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-2f24a846-121f-4c49-9931-a84640423419', protocol='range'}
2022-05-07 06:54:06,977 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 06:54:06,980 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 06:54:06,980 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 06:54:06,981 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 06:54:06,981 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651886646980
2022-05-07 06:54:06,981 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 06:54:06,983 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1c20576
2022-05-07 06:54:06,983 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 06:54:06,986 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:54:06,987 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 06:54:06,988 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 06:54:06,988 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 06:54:06,989 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] (Re-)joining group
2022-05-07 06:54:06,990 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 06:54:06,993 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Request joining group due to: need to re-join with the given member-id
2022-05-07 06:54:06,993 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] (Re-)joining group
2022-05-07 06:54:06,995 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 06:54:06,996 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 06:54:06,998 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4-fb318526-ad06-4c91-9f92-578defa6a09d', protocol='range'}
2022-05-07 06:54:06,998 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Finished assignment for group at generation 1: {consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4-fb318526-ad06-4c91-9f92-578defa6a09d=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 06:54:07,002 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=22, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:54:07,003 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4-fb318526-ad06-4c91-9f92-578defa6a09d', protocol='range'}
2022-05-07 06:54:07,003 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 06:54:07,003 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 06:54:07,004 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 06:54:07,005 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 06:54:07,005 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 06:54:07,009 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=24, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 06:54:07,013 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 06:54:07,080 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.928 seconds (JVM running for 5.372)
2022-05-07 06:54:20,504 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] start executing consumeBidEvents GenericMessage [payload=BidEvent [bidId=26, productId=39, bidAmount=200, buyerId=27, id=107994b6-72db-4837-84cf-5525d010b090, created=Sat May 07 06:54:20 IST 2022, eventType=PLACEBID], headers={kafka_offset=22, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@68f79fa3, deliveryAttempt=1, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=BIDS_PLACED_BY_BUYER, kafka_receivedTimestamp=1651886660471, kafka_groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6}]
2022-05-07 06:54:20,505 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Bid consumed from topic Bid [id=26, productid=39, bidAmount=200, sellerId=27]
2022-05-07 06:54:20,570 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:30}] to localhost:27017
2022-05-07 06:54:53,381 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=43, productName=Test Product10, shortDescription=This is product's short description, detailedDescription=This is product's detail description, category=This is product's detail description, startingPrice=100, bidEndDate=2022-10-10, sellerId=42]
2022-05-07 06:59:06,101 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 07:04:06,112 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 07:09:06,119 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 07:14:06,133 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 07:19:06,135 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 08:35:43,740 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 08:35:43,749 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 08:35:43,772 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Error sending fetch request (sessionId=255245285, epoch=3010) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 08:35:43,772 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Error sending fetch request (sessionId=488864505, epoch=3010) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 08:35:43,793 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:35:43,795 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:35:43,850 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32-4, groupId=anonymous.929cd48d-9fcd-45c4-9a0f-ec1546852b32] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:35:49,571 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-2f24a846-121f-4c49-9931-a84640423419', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 08:35:49,572 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 08:35:49,573 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 08:35:49,573 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 08:35:49,573 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 08:35:49,581 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:35:49,583 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:35:49,584 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] (Re-)joining group
2022-05-07 08:35:49,599 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Attempt to heartbeat with stale Generation{generationId=1, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-2f24a846-121f-4c49-9931-a84640423419', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, ignoring the error
2022-05-07 08:35:50,124 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:35:50,125 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] (Re-)joining group
2022-05-07 08:35:50,289 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-dd690bd2-68f2-41fa-9e8e-97a51b4cd74e', protocol='range'}
2022-05-07 08:35:50,291 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Finished assignment for group at generation 3: {consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-dd690bd2-68f2-41fa-9e8e-97a51b4cd74e=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 08:35:50,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2-dd690bd2-68f2-41fa-9e8e-97a51b4cd74e', protocol='range'}
2022-05-07 08:35:50,717 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 08:35:50,720 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 08:35:50,756 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6-2, groupId=anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 08:35:50,757 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.63317c16-c330-4a91-86e9-c4efbfa8abd6: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:39:56,082 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 08:39:56,083 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 26692 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 08:39:56,083 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 08:39:56,124 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 08:39:56,124 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 08:39:56,125 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 08:39:56,125 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 08:39:56,685 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 08:39:56,809 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 120 ms. Found 3 MongoDB repository interfaces.
2022-05-07 08:39:56,980 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 08:39:56,992 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 08:39:57,081 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 08:39:57,146 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:39:57,222 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:39:57,673 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 08:39:57,682 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 08:39:57,682 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 08:39:57,683 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 08:39:57,777 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 08:39:57,777 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1651 ms
2022-05-07 08:39:57,897 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 08:39:57,951 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e3056f258933400a20f1', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:37}] to localhost:27017
2022-05-07 08:39:57,951 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275e3056f258933400a20f1', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:38}] to localhost:27017
2022-05-07 08:39:57,951 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e3056f258933400a20f1', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17735500}
2022-05-07 08:39:57,981 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:39:58,029 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 08:39:58,065 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:39:58,805 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 08:39:58,925 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 08:39:58,938 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 08:39:59,029 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 08:39:59,029 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 08:39:59,033 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 08:39:59,034 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 08:39:59,034 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 08:39:59,040 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 08:39:59,122 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 08:39:59,126 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 08:39:59,154 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 08:39:59,155 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 08:39:59,366 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 08:39:59,372 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 08:39:59,378 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 08:39:59,391 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651892999390 with initial instances count: 6
2022-05-07 08:39:59,392 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 08:39:59,393 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651892999393, current=UP, previous=STARTING]
2022-05-07 08:39:59,394 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 08:39:59,394 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 08:39:59,446 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 08:39:59,458 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 08:39:59,458 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:39:59,459 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 08:39:59,507 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 08:39:59,508 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:39:59,508 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 08:39:59,524 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 08:39:59,524 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:39:59,524 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 08:39:59,553 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 08:39:59,554 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:39:59,554 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:39:59,605 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:39:59,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:39:59,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:39:59,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651892999682
2022-05-07 08:40:00,057 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 08:40:00,061 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 08:40:00,061 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:40:00,061 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 08:40:00,071 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:40:00,107 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:40:00,108 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:40:00,108 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893000107
2022-05-07 08:40:00,114 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-1, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:40:00,115 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-1, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:40:00,115 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-1, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:40:00,115 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:40:00,115 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:40:00,115 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:40:00,116 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-1 unregistered
2022-05-07 08:40:00,138 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418.errors' has 1 subscriber(s).
2022-05-07 08:40:00,138 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418.errors' has 0 subscriber(s).
2022-05-07 08:40:00,138 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418.errors' has 1 subscriber(s).
2022-05-07 08:40:00,138 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418.errors' has 2 subscriber(s).
2022-05-07 08:40:00,158 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:40:00,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:40:00,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:40:00,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893000163
2022-05-07 08:40:00,164 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 08:40:00,170 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@50ae9132
2022-05-07 08:40:00,174 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:40:00,174 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:40:00,174 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:40:00,174 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:40:00,174 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:40:00,175 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:40:00,178 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:40:00,179 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:40:00,179 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 08:40:00,179 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893000178
2022-05-07 08:40:00,179 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:40:00,180 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:40:00,181 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] (Re-)joining group
2022-05-07 08:40:00,189 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 08:40:00,190 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 08:40:00,190 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:40:00,190 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 08:40:00,190 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:40:00,193 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:40:00,193 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] (Re-)joining group
2022-05-07 08:40:00,194 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:40:00,195 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:40:00,195 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893000194
2022-05-07 08:40:00,198 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-3, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:40:00,198 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-3, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:40:00,198 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-3, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:40:00,198 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:40:00,198 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:40:00,199 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:40:00,199 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-3 unregistered
2022-05-07 08:40:00,201 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6.errors' has 1 subscriber(s).
2022-05-07 08:40:00,202 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6.errors' has 0 subscriber(s).
2022-05-07 08:40:00,202 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6.errors' has 1 subscriber(s).
2022-05-07 08:40:00,203 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6.errors' has 2 subscriber(s).
2022-05-07 08:40:00,204 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:40:00,209 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:40:00,209 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:40:00,209 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893000208
2022-05-07 08:40:00,209 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 08:40:00,210 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@461b946c
2022-05-07 08:40:00,210 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 08:40:00,212 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2-d18c95c1-bd58-4e14-a4a3-adb1460c3df8', protocol='range'}
2022-05-07 08:40:00,214 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Finished assignment for group at generation 1: {consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2-d18c95c1-bd58-4e14-a4a3-adb1460c3df8=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 08:40:00,214 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 08:40:00,214 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:40:00,215 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:40:00,215 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] (Re-)joining group
2022-05-07 08:40:00,223 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 08:40:00,224 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 08:40:00,234 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:40:00,235 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] (Re-)joining group
2022-05-07 08:40:00,238 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2-d18c95c1-bd58-4e14-a4a3-adb1460c3df8', protocol='range'}
2022-05-07 08:40:00,238 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4-07e78196-4e4d-4a55-a0b0-6ed5f504703f', protocol='range'}
2022-05-07 08:40:00,238 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Finished assignment for group at generation 1: {consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4-07e78196-4e4d-4a55-a0b0-6ed5f504703f=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 08:40:00,238 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 08:40:00,243 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4-07e78196-4e4d-4a55-a0b0-6ed5f504703f', protocol='range'}
2022-05-07 08:40:00,243 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 08:40:00,243 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 08:40:00,243 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 08:40:00,248 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:40:00,248 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:40:00,254 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:40:00,254 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:40:00,270 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418-2, groupId=anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:40:00,270 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6-4, groupId=anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:40:00,278 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.e464ade0-82b3-47d0-8f2d-319642f8a418: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:40:00,278 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5778226e-abd5-402c-9dae-9fcdeb86c2a6: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 08:40:00,327 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.818 seconds (JVM running for 6.377)
2022-05-07 08:40:27,654 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 08:40:27,654 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Initializing Servlet 'dispatcherServlet'
2022-05-07 08:40:27,656 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Completed initialization in 2 ms
2022-05-07 08:42:47,853 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 08:42:47,853 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 21676 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 08:42:47,854 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 08:42:47,890 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 08:42:47,891 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 08:42:47,892 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 08:42:47,892 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 08:42:48,360 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 08:42:48,452 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 89 ms. Found 3 MongoDB repository interfaces.
2022-05-07 08:42:48,602 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 08:42:48,610 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 08:42:48,684 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 08:42:48,733 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:42:48,787 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:42:49,209 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 08:42:49,219 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 08:42:49,219 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 08:42:49,219 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 08:42:49,312 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 08:42:49,313 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1421 ms
2022-05-07 08:42:49,416 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 08:42:49,462 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e3b18a147e79c572cb57', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:39}] to localhost:27017
2022-05-07 08:42:49,462 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275e3b18a147e79c572cb57', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:40}] to localhost:27017
2022-05-07 08:42:49,462 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e3b18a147e79c572cb57', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16016200}
2022-05-07 08:42:49,492 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:42:49,533 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 08:42:49,564 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:42:50,126 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 08:42:50,242 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 08:42:50,253 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 08:42:50,336 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 08:42:50,337 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 08:42:50,340 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 08:42:50,340 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 08:42:50,340 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 08:42:50,345 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 08:42:50,432 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 08:42:50,436 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 08:42:50,462 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 08:42:50,462 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 08:42:50,462 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 08:42:50,462 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 08:42:50,462 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 08:42:50,463 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 08:42:50,463 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 08:42:50,635 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 08:42:50,640 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 08:42:50,646 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 08:42:50,660 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651893170659 with initial instances count: 6
2022-05-07 08:42:50,662 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 08:42:50,662 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651893170662, current=UP, previous=STARTING]
2022-05-07 08:42:50,663 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 08:42:50,664 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 08:42:50,699 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 08:42:50,729 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 08:42:50,730 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:42:50,730 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 08:42:50,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 08:42:50,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:42:50,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 08:42:50,784 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 08:42:50,784 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:42:50,784 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 08:42:50,804 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 08:42:50,804 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:42:50,804 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:42:50,852 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:42:50,912 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:50,913 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:50,913 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893170912
2022-05-07 08:42:51,273 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 08:42:51,276 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 08:42:51,276 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:42:51,276 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 08:42:51,288 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:42:51,319 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:51,320 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:51,320 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893171319
2022-05-07 08:42:51,327 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-1, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:42:51,327 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-1, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:42:51,327 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-1, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:42:51,328 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:42:51,328 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:42:51,328 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:42:51,329 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-1 unregistered
2022-05-07 08:42:51,348 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c.errors' has 1 subscriber(s).
2022-05-07 08:42:51,348 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c.errors' has 0 subscriber(s).
2022-05-07 08:42:51,348 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c.errors' has 1 subscriber(s).
2022-05-07 08:42:51,348 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c.errors' has 2 subscriber(s).
2022-05-07 08:42:51,364 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:42:51,368 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:51,368 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:51,368 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893171368
2022-05-07 08:42:51,369 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 08:42:51,372 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1130c5b0
2022-05-07 08:42:51,374 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:42:51,374 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:42:51,374 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:42:51,374 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:42:51,374 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:42:51,375 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:42:51,379 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:51,379 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 08:42:51,379 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:51,379 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893171379
2022-05-07 08:42:51,379 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:42:51,380 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:42:51,382 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] (Re-)joining group
2022-05-07 08:42:51,390 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 08:42:51,391 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 08:42:51,391 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:42:51,391 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 08:42:51,392 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:42:51,395 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:42:51,396 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] (Re-)joining group
2022-05-07 08:42:51,397 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:51,397 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:51,397 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893171397
2022-05-07 08:42:51,405 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-3, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:42:51,406 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-3, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:42:51,408 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-3, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:42:51,408 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:42:51,408 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:42:51,408 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:42:51,409 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2-a012c6b8-0ddd-4c61-9681-a927b5b9c43c', protocol='range'}
2022-05-07 08:42:51,409 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-3 unregistered
2022-05-07 08:42:51,411 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d.errors' has 1 subscriber(s).
2022-05-07 08:42:51,411 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Finished assignment for group at generation 1: {consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2-a012c6b8-0ddd-4c61-9681-a927b5b9c43c=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 08:42:51,411 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d.errors' has 0 subscriber(s).
2022-05-07 08:42:51,411 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d.errors' has 1 subscriber(s).
2022-05-07 08:42:51,411 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d.errors' has 2 subscriber(s).
2022-05-07 08:42:51,412 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:42:51,417 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:42:51,417 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:42:51,417 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893171417
2022-05-07 08:42:51,417 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 08:42:51,417 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2-a012c6b8-0ddd-4c61-9681-a927b5b9c43c', protocol='range'}
2022-05-07 08:42:51,418 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1008f4bb
2022-05-07 08:42:51,418 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 08:42:51,418 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 08:42:51,420 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 08:42:51,421 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 08:42:51,421 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:42:51,422 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:42:51,423 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] (Re-)joining group
2022-05-07 08:42:51,424 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:42:51,431 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:42:51,433 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 08:42:51,434 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 08:42:51,440 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:42:51,441 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] (Re-)joining group
2022-05-07 08:42:51,445 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4-0e13250e-37bd-4bef-9f52-6349de6b3309', protocol='range'}
2022-05-07 08:42:51,445 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c-2, groupId=anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:42:51,445 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Finished assignment for group at generation 1: {consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4-0e13250e-37bd-4bef-9f52-6349de6b3309=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 08:42:51,450 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4-0e13250e-37bd-4bef-9f52-6349de6b3309', protocol='range'}
2022-05-07 08:42:51,450 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 08:42:51,450 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.4590aa60-9f8f-490f-9b75-939e3a534f7c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:42:51,450 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 08:42:51,452 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:42:51,453 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:42:51,459 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d-4, groupId=anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:42:51,463 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5484b1a0-962f-4a64-beb1-377095b3e86d: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 08:42:51,536 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.622 seconds (JVM running for 5.103)
2022-05-07 08:42:57,059 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 08:42:57,060 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 08:42:57,061 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 08:42:57,071 WARN org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver [http-nio-8060-exec-2] Resolved [org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'GET' not supported]
2022-05-07 08:44:12,326 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 08:44:12,331 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 16260 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 08:44:12,331 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 08:44:12,364 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 08:44:12,364 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 08:44:12,365 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 08:44:12,366 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 08:44:12,849 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 08:44:12,943 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 90 ms. Found 3 MongoDB repository interfaces.
2022-05-07 08:44:13,097 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 08:44:13,105 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 08:44:13,180 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 08:44:13,226 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:44:13,267 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:44:13,661 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 08:44:13,669 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 08:44:13,669 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 08:44:13,669 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 08:44:13,761 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 08:44:13,761 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1395 ms
2022-05-07 08:44:13,861 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 08:44:13,905 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e405a31a452160014a63', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:42}] to localhost:27017
2022-05-07 08:44:13,905 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275e405a31a452160014a63', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:41}] to localhost:27017
2022-05-07 08:44:13,905 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e405a31a452160014a63', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15218400}
2022-05-07 08:44:13,939 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:44:13,986 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 08:44:14,016 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:44:14,622 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 08:44:14,746 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 08:44:14,762 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 08:44:14,850 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 08:44:14,850 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 08:44:14,854 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 08:44:14,854 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 08:44:14,854 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 08:44:14,859 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 08:44:14,928 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 08:44:14,934 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 08:44:14,961 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 08:44:15,122 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 08:44:15,128 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 08:44:15,137 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 08:44:15,151 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651893255150 with initial instances count: 6
2022-05-07 08:44:15,153 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 08:44:15,153 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651893255153, current=UP, previous=STARTING]
2022-05-07 08:44:15,154 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 08:44:15,154 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 08:44:15,182 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 08:44:15,205 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 08:44:15,206 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:44:15,206 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 08:44:15,248 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 08:44:15,249 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:44:15,249 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 08:44:15,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 08:44:15,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:44:15,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 08:44:15,285 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 08:44:15,285 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:44:15,285 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:44:15,332 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:44:15,384 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,384 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,384 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255383
2022-05-07 08:44:15,612 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 08:44:15,616 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 08:44:15,616 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:44:15,616 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 08:44:15,626 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:44:15,654 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,654 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,654 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255654
2022-05-07 08:44:15,662 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-1, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:44:15,662 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-1, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:44:15,662 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-1, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:44:15,663 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:44:15,663 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:44:15,663 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:44:15,664 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-1 unregistered
2022-05-07 08:44:15,679 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18.errors' has 1 subscriber(s).
2022-05-07 08:44:15,680 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18.errors' has 0 subscriber(s).
2022-05-07 08:44:15,680 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18.errors' has 1 subscriber(s).
2022-05-07 08:44:15,680 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18.errors' has 2 subscriber(s).
2022-05-07 08:44:15,695 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:44:15,699 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,700 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,700 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255699
2022-05-07 08:44:15,701 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 08:44:15,704 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@623e2ef3
2022-05-07 08:44:15,705 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:44:15,705 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:44:15,705 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:44:15,706 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:44:15,706 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:44:15,706 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:44:15,710 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,710 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,710 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255710
2022-05-07 08:44:15,711 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 08:44:15,711 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:44:15,711 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:44:15,713 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] (Re-)joining group
2022-05-07 08:44:15,721 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 08:44:15,722 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 08:44:15,723 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:44:15,723 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 08:44:15,724 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.3caa780e-5383-4759-8fb0-17479f7e5529
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:44:15,724 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:44:15,724 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] (Re-)joining group
2022-05-07 08:44:15,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255728
2022-05-07 08:44:15,732 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-3, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:44:15,733 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-3, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:44:15,733 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-3, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:44:15,733 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:44:15,733 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:44:15,734 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:44:15,736 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-3 unregistered
2022-05-07 08:44:15,739 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.3caa780e-5383-4759-8fb0-17479f7e5529.errors' has 1 subscriber(s).
2022-05-07 08:44:15,739 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.3caa780e-5383-4759-8fb0-17479f7e5529.errors' has 0 subscriber(s).
2022-05-07 08:44:15,739 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2-3ff76e1b-8ac3-4577-b3e4-78c712f6601a', protocol='range'}
2022-05-07 08:44:15,739 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.3caa780e-5383-4759-8fb0-17479f7e5529.errors' has 1 subscriber(s).
2022-05-07 08:44:15,739 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.3caa780e-5383-4759-8fb0-17479f7e5529.errors' has 2 subscriber(s).
2022-05-07 08:44:15,740 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.3caa780e-5383-4759-8fb0-17479f7e5529
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:44:15,741 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Finished assignment for group at generation 1: {consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2-3ff76e1b-8ac3-4577-b3e4-78c712f6601a=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 08:44:15,745 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:44:15,746 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:44:15,746 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893255745
2022-05-07 08:44:15,746 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 08:44:15,747 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@2978cead
2022-05-07 08:44:15,747 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 08:44:15,749 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2-3ff76e1b-8ac3-4577-b3e4-78c712f6601a', protocol='range'}
2022-05-07 08:44:15,750 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 08:44:15,752 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 08:44:15,753 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 08:44:15,753 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:44:15,753 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:44:15,756 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] (Re-)joining group
2022-05-07 08:44:15,760 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:44:15,762 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 08:44:15,763 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 08:44:15,764 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:44:15,764 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:44:15,765 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] (Re-)joining group
2022-05-07 08:44:15,768 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4-44764b8a-c15a-4736-9d26-4a9c11cf1450', protocol='range'}
2022-05-07 08:44:15,769 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Finished assignment for group at generation 1: {consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4-44764b8a-c15a-4736-9d26-4a9c11cf1450=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 08:44:15,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4-44764b8a-c15a-4736-9d26-4a9c11cf1450', protocol='range'}
2022-05-07 08:44:15,773 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 08:44:15,773 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 08:44:15,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:44:15,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:44:15,776 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18-2, groupId=anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:44:15,779 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.3caa780e-5383-4759-8fb0-17479f7e5529-4, groupId=anonymous.3caa780e-5383-4759-8fb0-17479f7e5529] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:44:15,781 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5a6a736c-48c7-476f-bb3c-8ab79d1ada18: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:44:15,783 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.3caa780e-5383-4759-8fb0-17479f7e5529: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 08:44:15,851 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.46 seconds (JVM running for 4.934)
2022-05-07 08:44:22,876 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 08:44:22,876 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 08:44:22,878 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 08:44:22,894 WARN org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver [http-nio-8060-exec-2] Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type '' not supported]
2022-05-07 08:45:44,603 WARN org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver [http-nio-8060-exec-4] Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type '' not supported]
2022-05-07 08:46:55,488 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 08:46:55,492 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 10952 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 08:46:55,493 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 08:46:55,527 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 08:46:55,528 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 08:46:55,529 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 08:46:55,529 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 08:46:55,987 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 08:46:56,077 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 85 ms. Found 3 MongoDB repository interfaces.
2022-05-07 08:46:56,237 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 08:46:56,245 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 08:46:56,321 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 08:46:56,381 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:46:56,424 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 08:46:56,811 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 08:46:56,817 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 08:46:56,818 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 08:46:56,818 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 08:46:56,908 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 08:46:56,908 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1378 ms
2022-05-07 08:46:56,998 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 08:46:57,044 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275e4a8d142c62c59b8bf93', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:43}] to localhost:27017
2022-05-07 08:46:57,044 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e4a8d142c62c59b8bf93', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:44}] to localhost:27017
2022-05-07 08:46:57,045 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275e4a8d142c62c59b8bf93', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16357700}
2022-05-07 08:46:57,071 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:46:57,120 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 08:46:57,151 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 08:46:57,724 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 08:46:57,849 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 08:46:57,862 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 08:46:57,949 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 08:46:57,950 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 08:46:57,952 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 08:46:57,953 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 08:46:57,953 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 08:46:57,958 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 08:46:58,031 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 08:46:58,036 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 08:46:58,061 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 08:46:58,062 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 08:46:58,230 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 08:46:58,237 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 08:46:58,245 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 08:46:58,261 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651893418261 with initial instances count: 6
2022-05-07 08:46:58,263 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 08:46:58,263 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651893418263, current=UP, previous=STARTING]
2022-05-07 08:46:58,264 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 08:46:58,265 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 08:46:58,298 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 08:46:58,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 08:46:58,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:46:58,332 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 08:46:58,371 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 08:46:58,371 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:46:58,371 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 08:46:58,389 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 08:46:58,389 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:46:58,389 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 08:46:58,426 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 08:46:58,426 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:46:58,427 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:46:58,473 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:46:58,527 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,527 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,528 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418527
2022-05-07 08:46:58,753 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 08:46:58,756 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 08:46:58,756 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:46:58,756 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 08:46:58,765 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:46:58,791 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,791 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,791 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418791
2022-05-07 08:46:58,799 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-1, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:46:58,799 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-1, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:46:58,799 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-1, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:46:58,800 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:46:58,800 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:46:58,800 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:46:58,802 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-1 unregistered
2022-05-07 08:46:58,819 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4.errors' has 1 subscriber(s).
2022-05-07 08:46:58,820 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4.errors' has 0 subscriber(s).
2022-05-07 08:46:58,820 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4.errors' has 1 subscriber(s).
2022-05-07 08:46:58,820 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4.errors' has 2 subscriber(s).
2022-05-07 08:46:58,833 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:46:58,838 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,838 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,838 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418838
2022-05-07 08:46:58,839 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 08:46:58,842 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@276719ad
2022-05-07 08:46:58,843 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 08:46:58,843 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:46:58,843 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 08:46:58,843 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 08:46:58,843 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 08:46:58,845 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 08:46:58,849 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,849 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,849 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418849
2022-05-07 08:46:58,851 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 08:46:58,851 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:46:58,851 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:46:58,853 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] (Re-)joining group
2022-05-07 08:46:58,860 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 08:46:58,862 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 08:46:58,862 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:46:58,862 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 08:46:58,863 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:46:58,863 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.56c96113-60d9-43b4-8136-d5249276344e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:46:58,864 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] (Re-)joining group
2022-05-07 08:46:58,869 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,869 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,869 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418869
2022-05-07 08:46:58,872 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-3, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:46:58,873 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-3, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 08:46:58,874 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-3, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 08:46:58,874 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 08:46:58,874 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 08:46:58,874 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 08:46:58,875 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-3 unregistered
2022-05-07 08:46:58,878 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-53fdb3d8-e84d-43af-a3c8-6d953faadd05', protocol='range'}
2022-05-07 08:46:58,878 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.56c96113-60d9-43b4-8136-d5249276344e.errors' has 1 subscriber(s).
2022-05-07 08:46:58,878 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.56c96113-60d9-43b4-8136-d5249276344e.errors' has 0 subscriber(s).
2022-05-07 08:46:58,879 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.56c96113-60d9-43b4-8136-d5249276344e.errors' has 1 subscriber(s).
2022-05-07 08:46:58,879 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.56c96113-60d9-43b4-8136-d5249276344e.errors' has 2 subscriber(s).
2022-05-07 08:46:58,880 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Finished assignment for group at generation 1: {consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-53fdb3d8-e84d-43af-a3c8-6d953faadd05=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 08:46:58,880 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.56c96113-60d9-43b4-8136-d5249276344e
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 08:46:58,885 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 08:46:58,885 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 08:46:58,886 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651893418885
2022-05-07 08:46:58,886 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 08:46:58,886 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@2ba58b12
2022-05-07 08:46:58,888 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 08:46:58,891 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 08:46:58,891 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-53fdb3d8-e84d-43af-a3c8-6d953faadd05', protocol='range'}
2022-05-07 08:46:58,891 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 08:46:58,892 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 08:46:58,892 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 08:46:58,893 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 08:46:58,910 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 08:46:58,915 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: need to re-join with the given member-id
2022-05-07 08:46:58,916 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 08:46:58,916 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:46:58,917 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 08:46:58,918 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 08:46:58,918 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-5777e28c-3d40-42ba-9594-d64410785147', protocol='range'}
2022-05-07 08:46:58,918 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Finished assignment for group at generation 1: {consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-5777e28c-3d40-42ba-9594-d64410785147=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 08:46:58,921 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 08:46:58,923 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-5777e28c-3d40-42ba-9594-d64410785147', protocol='range'}
2022-05-07 08:46:58,923 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 08:46:58,923 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 08:46:58,925 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:46:58,929 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 08:46:58,937 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:46:58,937 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 08:46:58,942 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 08:46:58,942 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 08:46:59,020 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.451 seconds (JVM running for 5.029)
2022-05-07 08:47:12,698 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 08:47:12,699 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Initializing Servlet 'dispatcherServlet'
2022-05-07 08:47:12,701 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Completed initialization in 2 ms
2022-05-07 08:47:12,937 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-1] Opened connection [connectionId{localValue:3, serverValue:45}] to localhost:27017
2022-05-07 08:47:12,980 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null] with root cause
java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null
	at com.cts.eauction.microservices.listing.repository.ListingProjection.handle(ListingProjection.java:29)
	at com.cts.eauction.microservices.listing.service.ListingService.listAllBidsByProductBySeller(ListingService.java:26)
	at com.cts.eauction.microservices.listing.controller.ListingController.listAllBidsForAProduct(ListingController.java:27)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 09:03:36,218 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Error sending fetch request (sessionId=1644471032, epoch=267) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 09:03:36,218 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Error sending fetch request (sessionId=1039788527, epoch=267) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 09:03:36,218 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.56c96113-60d9-43b4-8136-d5249276344e] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 09:03:36,218 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 09:03:36,222 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,223 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,222 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,223 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,223 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 09:03:36,225 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,225 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 09:03:36,333 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,401 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 09:03:36,967 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-5777e28c-3d40-42ba-9594-d64410785147', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 09:03:36,967 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 09:03:36,967 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 09:03:36,967 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 09:03:36,967 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-07 09:03:36,967 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions lost: [PRODUCT_TOPIC-0]
2022-05-07 09:03:36,968 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-07 09:03:36,969 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 09:03:36,973 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: need to re-join with the given member-id
2022-05-07 09:03:36,975 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 09:03:36,984 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-03976293-31b9-4237-92c7-5cea46242553', protocol='range'}
2022-05-07 09:03:36,987 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Finished assignment for group at generation 3: {consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-03976293-31b9-4237-92c7-5cea46242553=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 09:03:36,994 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-03976293-31b9-4237-92c7-5cea46242553', protocol='range'}
2022-05-07 09:03:36,994 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 09:03:36,994 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 09:03:37,001 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 09:03:37,002 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 10:34:23,242 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Error sending fetch request (sessionId=857207342, epoch=187) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 10:34:23,243 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 10:34:23,242 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Error sending fetch request (sessionId=1269763523, epoch=187) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 10:34:23,245 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 10:34:23,363 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:34:23,365 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:34:24,000 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-53fdb3d8-e84d-43af-a3c8-6d953faadd05', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 10:34:24,001 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 10:34:24,001 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 10:34:24,003 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 10:34:24,004 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 10:34:24,004 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 10:34:24,004 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 10:34:24,004 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] (Re-)joining group
2022-05-07 10:34:24,583 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:34:24,584 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] (Re-)joining group
2022-05-07 10:34:24,593 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-03976293-31b9-4237-92c7-5cea46242553', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 10:34:24,594 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 10:34:24,594 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 10:34:24,594 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 10:34:24,594 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-07 10:34:24,594 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions lost: [PRODUCT_TOPIC-0]
2022-05-07 10:34:24,595 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-07 10:34:24,595 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 10:34:25,932 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-a8ceb103-10a5-42c0-9de1-935aff3265d7', protocol='range'}
2022-05-07 10:34:25,933 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Finished assignment for group at generation 3: {consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-a8ceb103-10a5-42c0-9de1-935aff3265d7=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 10:34:26,524 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:34:26,525 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] (Re-)joining group
2022-05-07 10:34:26,762 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2-a8ceb103-10a5-42c0-9de1-935aff3265d7', protocol='range'}
2022-05-07 10:34:26,762 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 10:34:26,762 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 10:34:26,771 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4-2, groupId=anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 10:34:26,772 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.d4c9b7c9-7af4-4c5f-9216-e366d1ed95e4: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 10:34:26,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-f5c6518b-1172-46f6-829f-3c723730df83', protocol='range'}
2022-05-07 10:34:26,773 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Finished assignment for group at generation 5: {consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-f5c6518b-1172-46f6-829f-3c723730df83=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 10:34:26,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4-f5c6518b-1172-46f6-829f-3c723730df83', protocol='range'}
2022-05-07 10:34:26,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 10:34:26,796 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 10:34:26,801 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.56c96113-60d9-43b4-8136-d5249276344e-4, groupId=anonymous.56c96113-60d9-43b4-8136-d5249276344e] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 10:34:26,803 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.56c96113-60d9-43b4-8136-d5249276344e: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 10:35:28,693 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 10:40:28,706 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 10:42:53,765 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 25192 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 10:42:53,767 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 10:42:53,770 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 10:42:53,817 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 10:42:53,817 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 10:42:53,818 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 10:42:53,819 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 10:42:54,480 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 10:42:54,649 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 162 ms. Found 3 MongoDB repository interfaces.
2022-05-07 10:42:54,871 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 10:42:54,886 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 10:42:54,984 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 10:42:55,062 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 10:42:55,141 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 10:42:55,706 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 10:42:55,717 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 10:42:55,718 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 10:42:55,719 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 10:42:55,837 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 10:42:55,837 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 2017 ms
2022-05-07 10:42:55,991 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 10:42:56,061 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275ffd7e436054f7309a9f0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:50}] to localhost:27017
2022-05-07 10:42:56,061 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6275ffd7e436054f7309a9f0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:51}] to localhost:27017
2022-05-07 10:42:56,061 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6275ffd7e436054f7309a9f0', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=21264300}
2022-05-07 10:42:56,104 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 10:42:56,156 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 10:42:56,194 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 10:42:57,021 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 10:42:57,165 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 10:42:57,180 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 10:42:57,282 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 10:42:57,283 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 10:42:57,287 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 10:42:57,287 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 10:42:57,288 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 10:42:57,296 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 10:42:57,421 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 10:42:57,426 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 10:42:57,464 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 10:42:57,464 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 10:42:57,465 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 10:42:57,465 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 10:42:57,465 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 10:42:57,465 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 10:42:57,465 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 10:42:57,738 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 10:42:57,745 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 10:42:57,752 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 10:42:57,770 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651900377767 with initial instances count: 6
2022-05-07 10:42:57,771 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 10:42:57,772 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651900377772, current=UP, previous=STARTING]
2022-05-07 10:42:57,773 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 10:42:57,773 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 10:42:57,844 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 10:42:57,844 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 10:42:57,844 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 10:42:57,860 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 10:42:57,902 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 10:42:57,903 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:42:57,903 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 10:42:57,921 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 10:42:57,921 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 10:42:57,921 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 10:42:57,948 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 10:42:57,949 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 10:42:57,949 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:42:58,010 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 10:42:58,108 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,108 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,108 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378106
2022-05-07 10:42:58,622 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 10:42:58,626 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 10:42:58,626 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:42:58,626 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 10:42:58,642 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:42:58,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378694
2022-05-07 10:42:58,703 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-1, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:42:58,704 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-1, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 10:42:58,704 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-1, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 10:42:58,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 10:42:58,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:42:58,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 10:42:58,706 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-1 unregistered
2022-05-07 10:42:58,733 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7.errors' has 1 subscriber(s).
2022-05-07 10:42:58,733 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7.errors' has 0 subscriber(s).
2022-05-07 10:42:58,733 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7.errors' has 1 subscriber(s).
2022-05-07 10:42:58,733 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7.errors' has 2 subscriber(s).
2022-05-07 10:42:58,754 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:42:58,760 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,760 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,760 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378760
2022-05-07 10:42:58,761 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 10:42:58,767 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7dd6a43c
2022-05-07 10:42:58,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 10:42:58,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:42:58,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 10:42:58,770 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 10:42:58,771 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:42:58,772 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 10:42:58,775 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 10:42:58,775 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,775 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,775 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:42:58,775 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378775
2022-05-07 10:42:58,778 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:42:58,781 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] (Re-)joining group
2022-05-07 10:42:58,790 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 10:42:58,791 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 10:42:58,791 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:42:58,791 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 10:42:58,792 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:42:58,798 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,799 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,799 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378798
2022-05-07 10:42:58,804 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-3, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:42:58,805 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-3, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 10:42:58,805 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-3, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 10:42:58,805 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 10:42:58,805 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:42:58,805 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 10:42:58,806 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-3 unregistered
2022-05-07 10:42:58,807 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534.errors' has 1 subscriber(s).
2022-05-07 10:42:58,808 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534.errors' has 0 subscriber(s).
2022-05-07 10:42:58,808 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534.errors' has 1 subscriber(s).
2022-05-07 10:42:58,808 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534.errors' has 2 subscriber(s).
2022-05-07 10:42:58,810 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:42:58,812 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:42:58,813 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] (Re-)joining group
2022-05-07 10:42:58,816 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:42:58,816 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:42:58,816 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900378816
2022-05-07 10:42:58,816 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 10:42:58,818 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@503d472c
2022-05-07 10:42:58,818 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 10:42:58,821 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 10:42:58,822 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:42:58,822 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:42:58,823 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] (Re-)joining group
2022-05-07 10:42:58,831 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 10:42:58,832 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 10:42:58,861 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:42:58,861 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] (Re-)joining group
2022-05-07 10:42:58,863 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2-ed81f61c-ddfa-4241-b7c9-ed2700a2682a', protocol='range'}
2022-05-07 10:42:58,864 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4-72253a12-f349-448c-8640-7a12835bfef3', protocol='range'}
2022-05-07 10:42:58,865 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Finished assignment for group at generation 1: {consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4-72253a12-f349-448c-8640-7a12835bfef3=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 10:42:58,865 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Finished assignment for group at generation 1: {consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2-ed81f61c-ddfa-4241-b7c9-ed2700a2682a=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 10:42:58,888 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2-ed81f61c-ddfa-4241-b7c9-ed2700a2682a', protocol='range'}
2022-05-07 10:42:58,888 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4-72253a12-f349-448c-8640-7a12835bfef3', protocol='range'}
2022-05-07 10:42:58,888 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 10:42:58,888 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 10:42:58,890 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 10:42:58,890 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 10:42:58,897 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 10:42:58,897 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 10:42:58,906 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 10:42:58,907 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 10:42:58,919 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7-2, groupId=anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 10:42:58,919 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534-4, groupId=anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 10:42:58,928 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.cc19beca-0c05-46c9-89bd-b021eed966a7: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 10:42:58,928 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.dd42dfc6-f5a4-4a22-9d30-45730e54e534: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 10:42:58,935 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 6.822 seconds (JVM running for 7.449)
2022-05-07 10:43:07,286 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 10:43:07,286 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Initializing Servlet 'dispatcherServlet'
2022-05-07 10:43:07,288 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-1] Completed initialization in 2 ms
2022-05-07 10:43:07,311 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-1] productIdInQuery=39
2022-05-07 10:43:07,373 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-1] Opened connection [connectionId{localValue:3, serverValue:52}] to localhost:27017
2022-05-07 10:43:07,391 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null] with root cause
java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null
	at com.cts.eauction.microservices.listing.repository.ListingProjection.handle(ListingProjection.java:29)
	at com.cts.eauction.microservices.listing.service.ListingService.listAllBidsByProductBySeller(ListingService.java:26)
	at com.cts.eauction.microservices.listing.controller.ListingController.listAllBidsForAProduct(ListingController.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 10:48:00,522 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 23372 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 10:48:00,523 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 10:48:00,524 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 10:48:00,555 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 10:48:00,555 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 10:48:00,556 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 10:48:00,556 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 10:48:01,028 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 10:48:01,119 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 88 ms. Found 3 MongoDB repository interfaces.
2022-05-07 10:48:01,280 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 10:48:01,288 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 10:48:01,365 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 10:48:01,414 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 10:48:01,464 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 10:48:01,930 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 10:48:01,942 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 10:48:01,942 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 10:48:01,942 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 10:48:02,044 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 10:48:02,045 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1488 ms
2022-05-07 10:48:02,142 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 10:48:02,188 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276010a8cd8a16d51fb3ca2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:54}] to localhost:27017
2022-05-07 10:48:02,188 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276010a8cd8a16d51fb3ca2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:53}] to localhost:27017
2022-05-07 10:48:02,189 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276010a8cd8a16d51fb3ca2', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16250000}
2022-05-07 10:48:02,221 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 10:48:02,264 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 10:48:02,296 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 10:48:02,892 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 10:48:03,017 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 10:48:03,029 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 10:48:03,116 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 10:48:03,117 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 10:48:03,120 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 10:48:03,121 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 10:48:03,121 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 10:48:03,126 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 10:48:03,220 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 10:48:03,231 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 10:48:03,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 10:48:03,257 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 10:48:03,258 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 10:48:03,258 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 10:48:03,258 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 10:48:03,258 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 10:48:03,258 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 10:48:03,450 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 10:48:03,457 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 10:48:03,464 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 10:48:03,479 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651900683477 with initial instances count: 6
2022-05-07 10:48:03,480 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 10:48:03,480 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651900683480, current=UP, previous=STARTING]
2022-05-07 10:48:03,481 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 10:48:03,482 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 10:48:03,515 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 10:48:03,543 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 10:48:03,544 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 10:48:03,544 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 10:48:03,584 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 10:48:03,584 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:48:03,585 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 10:48:03,600 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 10:48:03,600 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 10:48:03,600 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 10:48:03,621 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 10:48:03,621 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 10:48:03,621 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:48:03,669 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 10:48:03,744 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:03,744 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:03,744 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900683743
2022-05-07 10:48:04,116 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 10:48:04,119 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 10:48:04,119 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:48:04,119 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 10:48:04,132 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:48:04,164 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:04,164 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:04,165 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900684164
2022-05-07 10:48:04,172 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-1, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:48:04,174 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-1, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 10:48:04,174 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-1, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 10:48:04,175 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 10:48:04,175 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:48:04,175 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 10:48:04,177 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-1 unregistered
2022-05-07 10:48:04,197 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30.errors' has 1 subscriber(s).
2022-05-07 10:48:04,197 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30.errors' has 0 subscriber(s).
2022-05-07 10:48:04,197 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30.errors' has 1 subscriber(s).
2022-05-07 10:48:04,197 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30.errors' has 2 subscriber(s).
2022-05-07 10:48:04,211 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:48:04,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:04,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:04,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900684215
2022-05-07 10:48:04,216 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 10:48:04,220 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@4f5e993f
2022-05-07 10:48:04,221 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 10:48:04,221 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:48:04,222 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 10:48:04,222 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 10:48:04,222 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 10:48:04,222 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 10:48:04,226 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:04,226 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:04,226 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900684226
2022-05-07 10:48:04,226 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 10:48:04,227 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:48:04,227 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:48:04,229 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] (Re-)joining group
2022-05-07 10:48:04,236 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 10:48:04,238 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 10:48:04,238 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:48:04,238 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 10:48:04,239 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.7170f935-f53e-4f58-b1ac-e288a167e206
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:48:04,242 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:48:04,243 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] (Re-)joining group
2022-05-07 10:48:04,244 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:04,244 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:04,244 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900684244
2022-05-07 10:48:04,247 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-3, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:48:04,248 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-3, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 10:48:04,248 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-3, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 10:48:04,248 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 10:48:04,248 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 10:48:04,248 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 10:48:04,249 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-3 unregistered
2022-05-07 10:48:04,251 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.7170f935-f53e-4f58-b1ac-e288a167e206.errors' has 1 subscriber(s).
2022-05-07 10:48:04,252 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.7170f935-f53e-4f58-b1ac-e288a167e206.errors' has 0 subscriber(s).
2022-05-07 10:48:04,252 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.7170f935-f53e-4f58-b1ac-e288a167e206.errors' has 1 subscriber(s).
2022-05-07 10:48:04,252 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.7170f935-f53e-4f58-b1ac-e288a167e206.errors' has 2 subscriber(s).
2022-05-07 10:48:04,254 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2-11cb4537-07dd-4e74-b491-a539bf89d4e2', protocol='range'}
2022-05-07 10:48:04,254 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.7170f935-f53e-4f58-b1ac-e288a167e206
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 10:48:04,256 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Finished assignment for group at generation 1: {consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2-11cb4537-07dd-4e74-b491-a539bf89d4e2=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 10:48:04,259 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 10:48:04,259 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 10:48:04,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651900684259
2022-05-07 10:48:04,260 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 10:48:04,260 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1aa48aa8
2022-05-07 10:48:04,261 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 10:48:04,263 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2-11cb4537-07dd-4e74-b491-a539bf89d4e2', protocol='range'}
2022-05-07 10:48:04,264 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 10:48:04,264 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 10:48:04,265 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 10:48:04,266 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 10:48:04,267 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] (Re-)joining group
2022-05-07 10:48:04,267 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 10:48:04,272 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 10:48:04,275 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 10:48:04,277 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 10:48:04,277 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Request joining group due to: need to re-join with the given member-id
2022-05-07 10:48:04,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] (Re-)joining group
2022-05-07 10:48:04,278 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 10:48:04,280 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4-3ba164ff-afe5-4b83-b46d-6f85f5f6a1cc', protocol='range'}
2022-05-07 10:48:04,280 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Finished assignment for group at generation 1: {consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4-3ba164ff-afe5-4b83-b46d-6f85f5f6a1cc=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 10:48:04,285 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4-3ba164ff-afe5-4b83-b46d-6f85f5f6a1cc', protocol='range'}
2022-05-07 10:48:04,285 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 10:48:04,285 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 10:48:04,287 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 10:48:04,288 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 10:48:04,290 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30-2, groupId=anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 10:48:04,292 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.7170f935-f53e-4f58-b1ac-e288a167e206-4, groupId=anonymous.7170f935-f53e-4f58-b1ac-e288a167e206] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 10:48:04,296 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.7170f935-f53e-4f58-b1ac-e288a167e206: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 10:48:04,296 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a00066f3-5bf6-4ca4-b237-cb914992fd30: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 10:48:04,363 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.878 seconds (JVM running for 5.362)
2022-05-07 10:48:11,232 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 10:48:11,232 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 10:48:11,233 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 10:48:11,255 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 10:48:11,316 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:55}] to localhost:27017
2022-05-07 10:48:11,329 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database null
2022-05-07 10:48:11,345 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null] with root cause
java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null
	at com.cts.eauction.microservices.listing.repository.ListingProjection.handle(ListingProjection.java:34)
	at com.cts.eauction.microservices.listing.service.ListingService.listAllBidsByProductBySeller(ListingService.java:26)
	at com.cts.eauction.microservices.listing.controller.ListingController.listAllBidsForAProduct(ListingController.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 10:53:03,268 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 10:58:03,279 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 11:01:02,676 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 11:01:02,680 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 7472 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 11:01:02,681 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 11:01:02,715 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 11:01:02,716 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 11:01:02,717 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 11:01:02,717 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 11:01:03,206 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 11:01:03,309 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 100 ms. Found 3 MongoDB repository interfaces.
2022-05-07 11:01:03,466 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 11:01:03,474 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 11:01:03,552 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 11:01:03,602 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 11:01:03,662 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 11:01:04,154 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 11:01:04,163 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 11:01:04,164 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 11:01:04,164 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 11:01:04,271 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 11:01:04,271 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1554 ms
2022-05-07 11:01:04,386 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 11:01:04,432 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627604184008f07d78e3dd51', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:56}] to localhost:27017
2022-05-07 11:01:04,432 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627604184008f07d78e3dd51', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:57}] to localhost:27017
2022-05-07 11:01:04,433 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627604184008f07d78e3dd51', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15957400}
2022-05-07 11:01:04,469 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 11:01:04,516 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 11:01:04,548 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 11:01:05,136 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 11:01:05,267 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 11:01:05,279 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 11:01:05,368 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 11:01:05,369 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 11:01:05,371 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 11:01:05,372 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 11:01:05,372 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 11:01:05,377 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 11:01:05,473 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 11:01:05,478 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 11:01:05,510 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 11:01:05,691 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 11:01:05,698 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 11:01:05,705 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 11:01:05,720 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651901465718 with initial instances count: 6
2022-05-07 11:01:05,721 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 11:01:05,721 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651901465721, current=UP, previous=STARTING]
2022-05-07 11:01:05,722 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 11:01:05,723 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 11:01:05,753 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 11:01:05,782 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 11:01:05,783 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 11:01:05,783 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 11:01:05,821 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 11:01:05,821 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 11:01:05,821 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 11:01:05,834 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 11:01:05,834 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 11:01:05,834 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 11:01:05,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 11:01:05,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 11:01:05,855 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 11:01:05,903 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 11:01:05,987 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:05,987 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:05,987 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901465986
2022-05-07 11:01:06,389 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 11:01:06,394 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 11:01:06,394 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 11:01:06,394 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 11:01:06,405 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 11:01:06,436 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:06,436 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:06,436 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901466436
2022-05-07 11:01:06,446 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-1, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 11:01:06,448 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-1, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 11:01:06,448 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-1, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 11:01:06,448 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 11:01:06,449 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 11:01:06,449 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 11:01:06,450 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-1 unregistered
2022-05-07 11:01:06,471 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1.errors' has 1 subscriber(s).
2022-05-07 11:01:06,472 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1.errors' has 0 subscriber(s).
2022-05-07 11:01:06,472 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1.errors' has 1 subscriber(s).
2022-05-07 11:01:06,472 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1.errors' has 2 subscriber(s).
2022-05-07 11:01:06,487 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 11:01:06,492 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:06,492 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:06,492 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901466492
2022-05-07 11:01:06,493 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 11:01:06,496 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@28a7fe08
2022-05-07 11:01:06,497 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 11:01:06,497 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 11:01:06,497 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 11:01:06,497 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 11:01:06,497 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 11:01:06,500 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 11:01:06,502 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:06,502 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:06,502 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901466502
2022-05-07 11:01:06,507 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 11:01:06,508 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 11:01:06,508 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 11:01:06,510 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] (Re-)joining group
2022-05-07 11:01:06,513 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 11:01:06,514 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 11:01:06,514 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 11:01:06,514 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 11:01:06,515 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 11:01:06,520 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:06,520 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:06,521 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901466520
2022-05-07 11:01:06,526 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-3, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 11:01:06,527 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-3, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 11:01:06,527 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-3, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 11:01:06,527 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 11:01:06,527 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 11:01:06,527 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 11:01:06,528 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-3 unregistered
2022-05-07 11:01:06,529 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96.errors' has 1 subscriber(s).
2022-05-07 11:01:06,530 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96.errors' has 0 subscriber(s).
2022-05-07 11:01:06,530 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96.errors' has 1 subscriber(s).
2022-05-07 11:01:06,530 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96.errors' has 2 subscriber(s).
2022-05-07 11:01:06,531 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 11:01:06,536 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 11:01:06,537 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 11:01:06,537 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651901466536
2022-05-07 11:01:06,537 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 11:01:06,538 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1a70b489
2022-05-07 11:01:06,539 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 11:01:06,542 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 11:01:06,543 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 11:01:06,543 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 11:01:06,545 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] (Re-)joining group
2022-05-07 11:01:06,548 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Request joining group due to: need to re-join with the given member-id
2022-05-07 11:01:06,548 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] (Re-)joining group
2022-05-07 11:01:06,549 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Request joining group due to: need to re-join with the given member-id
2022-05-07 11:01:06,550 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] (Re-)joining group
2022-05-07 11:01:06,551 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 11:01:06,552 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 11:01:06,553 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2-a3f84dd5-872f-4da5-b692-6fde00896f5b', protocol='range'}
2022-05-07 11:01:06,553 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4-5f4c47c1-a52b-49ce-86c1-efecb4f89c4a', protocol='range'}
2022-05-07 11:01:06,554 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Finished assignment for group at generation 1: {consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4-5f4c47c1-a52b-49ce-86c1-efecb4f89c4a=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 11:01:06,554 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Finished assignment for group at generation 1: {consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2-a3f84dd5-872f-4da5-b692-6fde00896f5b=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 11:01:06,566 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4-5f4c47c1-a52b-49ce-86c1-efecb4f89c4a', protocol='range'}
2022-05-07 11:01:06,567 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 11:01:06,567 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2-a3f84dd5-872f-4da5-b692-6fde00896f5b', protocol='range'}
2022-05-07 11:01:06,568 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 11:01:06,570 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 11:01:06,570 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 11:01:06,577 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 11:01:06,577 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 11:01:06,583 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 11:01:06,583 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 11:01:06,593 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1-2, groupId=anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 11:01:06,593 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96-4, groupId=anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 11:01:06,601 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.25ea6e80-5d2c-4cc2-9876-44f23d5c93a1: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 11:01:06,601 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a9bcca84-87f7-448f-af9a-25ff9b963d96: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 11:01:06,649 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.013 seconds (JVM running for 5.522)
2022-05-07 11:01:13,524 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 11:01:13,524 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 11:01:13,525 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 11:01:13,546 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 11:01:13,596 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:58}] to localhost:27017
2022-05-07 11:01:13,610 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database null
2022-05-07 11:01:13,625 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null] with root cause
java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null
	at com.cts.eauction.microservices.listing.repository.ListingProjection.handle(ListingProjection.java:34)
	at com.cts.eauction.microservices.listing.service.ListingService.listAllBidsByProductBySeller(ListingService.java:26)
	at com.cts.eauction.microservices.listing.controller.ListingController.listAllBidsForAProduct(ListingController.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 11:06:05,527 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 11:09:11,238 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 11:09:11,242 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 19248 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 11:09:11,243 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 11:09:11,275 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 11:09:11,275 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 11:09:11,276 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 11:09:11,277 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 11:09:11,762 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 11:09:11,863 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 97 ms. Found 3 MongoDB repository interfaces.
2022-05-07 11:09:12,018 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 11:09:12,026 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 11:09:12,107 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 11:09:12,159 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 11:09:12,217 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 11:09:12,685 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 11:09:12,695 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 11:09:12,695 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 11:09:12,695 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 11:09:12,796 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 11:09:12,797 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1520 ms
2022-05-07 11:09:12,900 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 11:09:12,945 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276060071e2d33afa5e9920', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:60}] to localhost:27017
2022-05-07 11:09:12,945 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276060071e2d33afa5e9920', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:59}] to localhost:27017
2022-05-07 11:09:12,945 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276060071e2d33afa5e9920', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14619500}
2022-05-07 11:09:12,983 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 11:09:13,028 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 11:09:13,056 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 11:09:13,166 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingController': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'repository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'listingReadRepository' defined in com.cts.eauction.microservices.listing.repository.ListingReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
2022-05-07 11:09:13,169 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-07 11:09:13,182 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-07 11:09:13,205 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingController': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'repository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'listingReadRepository' defined in com.cts.eauction.microservices.listing.repository.ListingReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:953)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:740)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:415)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'repository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'listingReadRepository' defined in com.cts.eauction.microservices.listing.repository.ListingReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'repository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'listingReadRepository' defined in com.cts.eauction.microservices.listing.repository.ListingReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'listingReadRepository' defined in com.cts.eauction.microservices.listing.repository.ListingReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 53 common frames omitted
Caused by: org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.ListingReadRepository.getAllBidsByProductId(com.cts.eauction.microservices.listing.model.BidsReceivedOnProductQuery)! Reason: No property 'productId' found for type 'ProductDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.data.repository.query.QueryCreationException.create(QueryCreationException.java:101)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lookupQuery(QueryExecutorMethodInterceptor.java:106)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lambda$mapMethodsToQuery$1(QueryExecutorMethodInterceptor.java:94)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Collections$UnmodifiableCollection$1.forEachRemaining(Collections.java:1056)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.mapMethodsToQuery(QueryExecutorMethodInterceptor.java:96)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lambda$new$0(QueryExecutorMethodInterceptor.java:86)
	at java.base/java.util.Optional.map(Optional.java:258)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.<init>(QueryExecutorMethodInterceptor.java:86)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:364)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:322)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:230)
	at org.springframework.data.util.Lazy.get(Lazy.java:114)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:328)
	at org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean.afterPropertiesSet(MongoRepositoryFactoryBean.java:119)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 63 common frames omitted
Caused by: org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'ProductDetails'!
	at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:90)
	at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:437)
	at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:413)
	at org.springframework.data.mapping.PropertyPath.lambda$from$0(PropertyPath.java:366)
	at java.base/java.util.concurrent.ConcurrentMap.computeIfAbsent(ConcurrentMap.java:330)
	at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:348)
	at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:331)
	at org.springframework.data.repository.query.parser.Part.<init>(Part.java:81)
	at org.springframework.data.repository.query.parser.PartTree$OrPart.lambda$new$0(PartTree.java:249)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:250)
	at org.springframework.data.repository.query.parser.PartTree$Predicate.lambda$new$0(PartTree.java:383)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:384)
	at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:95)
	at org.springframework.data.mongodb.repository.query.PartTreeMongoQuery.<init>(PartTreeMongoQuery.java:67)
	at org.springframework.data.mongodb.repository.support.MongoRepositoryFactory$MongoQueryLookupStrategy.resolveQuery(MongoRepositoryFactory.java:207)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lookupQuery(QueryExecutorMethodInterceptor.java:102)
	... 85 common frames omitted
2022-05-07 13:44:04,739 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 26484 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 13:44:04,741 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 13:44:04,744 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 13:44:04,786 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 13:44:04,786 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 13:44:04,788 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 13:44:04,788 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 13:44:05,390 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 13:44:05,550 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 156 ms. Found 3 MongoDB repository interfaces.
2022-05-07 13:44:05,745 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 13:44:05,760 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 13:44:05,852 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 13:44:05,918 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 13:44:05,990 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 13:44:06,505 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 13:44:06,517 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 13:44:06,517 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 13:44:06,517 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 13:44:06,629 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 13:44:06,629 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1841 ms
2022-05-07 13:44:06,779 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 13:44:06,857 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62762a4e7e402e6b9d7a0157', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:66}] to localhost:27017
2022-05-07 13:44:06,857 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62762a4e7e402e6b9d7a0157', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:65}] to localhost:27017
2022-05-07 13:44:06,857 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62762a4e7e402e6b9d7a0157', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=22807200}
2022-05-07 13:44:06,897 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 13:44:06,951 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 13:44:06,989 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 13:44:07,647 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 13:44:07,787 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 13:44:07,801 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 13:44:07,905 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 13:44:07,906 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 13:44:07,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 13:44:07,909 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 13:44:07,909 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 13:44:07,917 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 13:44:08,029 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 13:44:08,034 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 13:44:08,067 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 13:44:08,068 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 13:44:08,313 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 13:44:08,319 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 13:44:08,328 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 13:44:08,344 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651911248344 with initial instances count: 5
2022-05-07 13:44:08,346 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 13:44:08,346 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651911248346, current=UP, previous=STARTING]
2022-05-07 13:44:08,347 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 13:44:08,348 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 13:44:08,432 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 13:44:08,433 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 13:44:08,433 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 13:44:08,433 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 13:44:08,483 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 13:44:08,484 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:44:08,484 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 13:44:08,501 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 13:44:08,502 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 13:44:08,502 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 13:44:08,519 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 13:44:08,520 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 13:44:08,520 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:44:08,567 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 13:44:08,661 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:08,661 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:08,661 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911248660
2022-05-07 13:44:09,097 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 13:44:09,101 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 13:44:09,102 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:44:09,102 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 13:44:09,117 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:44:09,154 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:09,154 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:09,154 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911249154
2022-05-07 13:44:09,165 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-1, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:44:09,166 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-1, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 13:44:09,167 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-1, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 13:44:09,167 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 13:44:09,167 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:44:09,167 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 13:44:09,168 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-1 unregistered
2022-05-07 13:44:09,193 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea.errors' has 1 subscriber(s).
2022-05-07 13:44:09,193 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea.errors' has 0 subscriber(s).
2022-05-07 13:44:09,193 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea.errors' has 1 subscriber(s).
2022-05-07 13:44:09,193 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea.errors' has 2 subscriber(s).
2022-05-07 13:44:09,210 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:44:09,216 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:09,217 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:09,217 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911249216
2022-05-07 13:44:09,218 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 13:44:09,222 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@5fd47b8f
2022-05-07 13:44:09,223 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 13:44:09,223 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:44:09,223 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 13:44:09,224 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 13:44:09,224 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:44:09,225 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 13:44:09,228 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:09,228 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:09,228 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911249228
2022-05-07 13:44:09,230 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 13:44:09,230 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:44:09,241 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 13:44:09,243 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 13:44:09,243 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:44:09,243 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 13:44:09,243 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 13:44:09,244 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:44:09,246 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] (Re-)joining group
2022-05-07 13:44:09,249 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:09,250 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:09,250 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911249249
2022-05-07 13:44:09,254 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-3, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:44:09,255 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-3, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 13:44:09,255 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-3, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 13:44:09,255 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 13:44:09,255 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:44:09,255 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 13:44:09,257 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-3 unregistered
2022-05-07 13:44:09,258 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f.errors' has 1 subscriber(s).
2022-05-07 13:44:09,258 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f.errors' has 0 subscriber(s).
2022-05-07 13:44:09,258 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f.errors' has 1 subscriber(s).
2022-05-07 13:44:09,258 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f.errors' has 2 subscriber(s).
2022-05-07 13:44:09,259 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:44:09,264 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:44:09,264 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:44:09,264 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911249264
2022-05-07 13:44:09,264 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 13:44:09,265 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@ac7dddf
2022-05-07 13:44:09,266 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 13:44:09,269 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 13:44:09,270 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:44:09,270 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 13:44:09,271 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] (Re-)joining group
2022-05-07 13:44:09,284 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 13:44:09,285 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 13:44:09,287 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Request joining group due to: need to re-join with the given member-id
2022-05-07 13:44:09,288 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] (Re-)joining group
2022-05-07 13:44:09,295 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Request joining group due to: need to re-join with the given member-id
2022-05-07 13:44:09,296 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] (Re-)joining group
2022-05-07 13:44:09,307 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2-617143df-ef89-4478-9c15-19bd189950cd', protocol='range'}
2022-05-07 13:44:09,309 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4-9fc5816e-2d9d-4964-8228-1fbc871ddefe', protocol='range'}
2022-05-07 13:44:09,309 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Finished assignment for group at generation 1: {consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2-617143df-ef89-4478-9c15-19bd189950cd=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 13:44:09,309 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Finished assignment for group at generation 1: {consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4-9fc5816e-2d9d-4964-8228-1fbc871ddefe=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 13:44:09,356 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2-617143df-ef89-4478-9c15-19bd189950cd', protocol='range'}
2022-05-07 13:44:09,356 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4-9fc5816e-2d9d-4964-8228-1fbc871ddefe', protocol='range'}
2022-05-07 13:44:09,357 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 13:44:09,357 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 13:44:09,360 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 13:44:09,360 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 13:44:09,371 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 13:44:09,371 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 13:44:09,375 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 13:44:09,375 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 13:44:09,386 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 6.167 seconds (JVM running for 6.744)
2022-05-07 13:44:09,390 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f-4, groupId=anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 13:44:09,390 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea-2, groupId=anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 13:44:09,400 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.8050cd4c-83ad-4c36-9fb4-a92c8a65f76f: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 13:44:09,400 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.e92890e6-40a3-4ae3-8dc2-075f9d55a5ea: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 13:44:17,222 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 13:44:17,223 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 13:44:17,225 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 2 ms
2022-05-07 13:44:17,247 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 13:44:17,307 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:67}] to localhost:27017
2022-05-07 13:44:17,321 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database null
2022-05-07 13:44:17,345 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null] with root cause
java.lang.NullPointerException: Cannot invoke "com.cts.eauction.microservices.listing.model.ProductDetails.getShortDescription()" because "productDetails" is null
	at com.cts.eauction.microservices.listing.repository.ListingProjection.handle(ListingProjection.java:34)
	at com.cts.eauction.microservices.listing.service.ListingService.listAllBidsByProductBySeller(ListingService.java:26)
	at com.cts.eauction.microservices.listing.controller.ListingController.listAllBidsForAProduct(ListingController.java:32)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1067)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1743)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:832)
2022-05-07 13:48:15,157 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 13:48:15,162 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 11532 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 13:48:15,163 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 13:48:15,197 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 13:48:15,198 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 13:48:15,199 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 13:48:15,199 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 13:48:15,660 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 13:48:15,757 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 93 ms. Found 3 MongoDB repository interfaces.
2022-05-07 13:48:15,902 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 13:48:15,910 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 13:48:15,985 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=66df5acc-4ab4-30a1-89d8-002b23745199
2022-05-07 13:48:16,034 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 13:48:16,093 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 13:48:16,539 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 13:48:16,549 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 13:48:16,549 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 13:48:16,549 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 13:48:16,646 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 13:48:16,646 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1446 ms
2022-05-07 13:48:16,745 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 13:48:16,791 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62762b48cf10725e14c52ad6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:69}] to localhost:27017
2022-05-07 13:48:16,791 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62762b48cf10725e14c52ad6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:68}] to localhost:27017
2022-05-07 13:48:16,792 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62762b48cf10725e14c52ad6', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17626000}
2022-05-07 13:48:16,821 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 13:48:16,861 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 13:48:16,892 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 13:48:17,461 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 13:48:17,584 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 13:48:17,597 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 13:48:17,681 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 13:48:17,681 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 13:48:17,685 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 13:48:17,686 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 13:48:17,687 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 13:48:17,692 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 13:48:17,788 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 13:48:17,795 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 13:48:17,822 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 13:48:17,822 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 13:48:17,822 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 13:48:17,822 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 13:48:17,822 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 13:48:17,823 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 13:48:17,823 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 13:48:17,999 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 13:48:18,005 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 13:48:18,012 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 13:48:18,027 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651911498025 with initial instances count: 6
2022-05-07 13:48:18,028 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 13:48:18,028 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651911498028, current=UP, previous=STARTING]
2022-05-07 13:48:18,029 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 13:48:18,030 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 13:48:18,062 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 13:48:18,091 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 13:48:18,091 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 13:48:18,092 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 13:48:18,137 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 13:48:18,137 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:48:18,137 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 13:48:18,153 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 13:48:18,153 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 13:48:18,154 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 13:48:18,171 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 13:48:18,171 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 13:48:18,172 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:48:18,224 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 13:48:18,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498292
2022-05-07 13:48:18,659 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 13:48:18,662 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 13:48:18,662 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:48:18,662 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 13:48:18,674 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:48:18,716 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,716 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,716 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498716
2022-05-07 13:48:18,723 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-1, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:48:18,724 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-1, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 13:48:18,724 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-1, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 13:48:18,724 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 13:48:18,724 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:48:18,724 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 13:48:18,725 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-1 unregistered
2022-05-07 13:48:18,744 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724.errors' has 1 subscriber(s).
2022-05-07 13:48:18,744 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724.errors' has 0 subscriber(s).
2022-05-07 13:48:18,744 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724.errors' has 1 subscriber(s).
2022-05-07 13:48:18,744 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724.errors' has 2 subscriber(s).
2022-05-07 13:48:18,758 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:48:18,762 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,762 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,762 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498762
2022-05-07 13:48:18,763 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 13:48:18,766 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@365fb870
2022-05-07 13:48:18,767 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 13:48:18,767 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:48:18,767 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 13:48:18,767 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 13:48:18,767 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 13:48:18,768 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 13:48:18,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498772
2022-05-07 13:48:18,772 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 13:48:18,773 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:48:18,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 13:48:18,776 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] (Re-)joining group
2022-05-07 13:48:18,782 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 13:48:18,784 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 13:48:18,784 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:48:18,785 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 13:48:18,785 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:48:18,788 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Request joining group due to: need to re-join with the given member-id
2022-05-07 13:48:18,789 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] (Re-)joining group
2022-05-07 13:48:18,792 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,793 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,793 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498792
2022-05-07 13:48:18,797 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-3, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:48:18,798 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-3, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 13:48:18,799 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-3, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 13:48:18,799 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 13:48:18,799 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 13:48:18,800 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 13:48:18,802 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-3 unregistered
2022-05-07 13:48:18,802 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2-39da7254-6d7e-44f9-aea2-5f057baf398d', protocol='range'}
2022-05-07 13:48:18,803 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398.errors' has 1 subscriber(s).
2022-05-07 13:48:18,804 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398.errors' has 0 subscriber(s).
2022-05-07 13:48:18,804 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Finished assignment for group at generation 1: {consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2-39da7254-6d7e-44f9-aea2-5f057baf398d=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 13:48:18,804 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398.errors' has 1 subscriber(s).
2022-05-07 13:48:18,804 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398.errors' has 2 subscriber(s).
2022-05-07 13:48:18,806 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 13:48:18,810 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 13:48:18,811 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 13:48:18,811 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651911498810
2022-05-07 13:48:18,811 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 13:48:18,812 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1c20576
2022-05-07 13:48:18,812 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 13:48:18,813 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2-39da7254-6d7e-44f9-aea2-5f057baf398d', protocol='range'}
2022-05-07 13:48:18,813 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 13:48:18,815 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 13:48:18,816 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 13:48:18,816 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 13:48:18,816 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 13:48:18,817 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] (Re-)joining group
2022-05-07 13:48:18,820 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 13:48:18,825 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 13:48:18,826 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 13:48:18,827 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 13:48:18,834 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Request joining group due to: need to re-join with the given member-id
2022-05-07 13:48:18,835 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] (Re-)joining group
2022-05-07 13:48:18,836 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724-2, groupId=anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 13:48:18,838 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4-de2f6f0b-6776-4fc7-9296-8ca8d80e4a3f', protocol='range'}
2022-05-07 13:48:18,839 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Finished assignment for group at generation 1: {consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4-de2f6f0b-6776-4fc7-9296-8ca8d80e4a3f=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 13:48:18,842 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.b3601c36-deb1-41f3-a1be-c723a05ca724: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 13:48:18,843 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4-de2f6f0b-6776-4fc7-9296-8ca8d80e4a3f', protocol='range'}
2022-05-07 13:48:18,844 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 13:48:18,844 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 13:48:18,845 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 13:48:18,846 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 13:48:18,849 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398-4, groupId=anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 13:48:18,852 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.05c329e2-c0be-45ad-b5e5-6e0fa762b398: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 13:48:18,902 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.787 seconds (JVM running for 5.286)
2022-05-07 13:48:26,302 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 13:48:26,302 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 13:48:26,303 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 13:48:26,326 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 13:48:26,393 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:70}] to localhost:27017
2022-05-07 13:48:26,436 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database com.cts.eauction.microservices.listing.model.ProductDetails@3e2b9364
2022-05-07 13:53:17,831 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 13:58:17,835 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:03:17,839 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:08:17,852 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:13:20,815 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 14:13:20,816 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 12396 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 14:13:20,817 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 14:13:20,851 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 14:13:20,851 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 14:13:20,852 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 14:13:20,852 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 14:13:21,333 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 14:13:21,436 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 99 ms. Found 5 MongoDB repository interfaces.
2022-05-07 14:13:21,586 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 14:13:21,594 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 14:13:21,676 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 14:13:21,731 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:13:21,782 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:13:22,254 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 14:13:22,264 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 14:13:22,264 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 14:13:22,264 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 14:13:22,366 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 14:13:22,366 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1513 ms
2022-05-07 14:13:22,472 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 14:13:22,524 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276312a2ab92a0f581da292', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:75}] to localhost:27017
2022-05-07 14:13:22,524 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276312a2ab92a0f581da292', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:76}] to localhost:27017
2022-05-07 14:13:22,525 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276312a2ab92a0f581da292', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19175400}
2022-05-07 14:13:22,570 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:13:22,621 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 14:13:22,656 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:13:23,264 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 14:13:23,386 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 14:13:23,400 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 14:13:23,492 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 14:13:23,493 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 14:13:23,496 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 14:13:23,496 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 14:13:23,496 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 14:13:23,502 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 14:13:23,601 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 14:13:23,606 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 14:13:23,639 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 14:13:23,831 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 14:13:23,838 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 14:13:23,844 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 14:13:23,859 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651913003857 with initial instances count: 6
2022-05-07 14:13:23,860 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 14:13:23,860 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651913003860, current=UP, previous=STARTING]
2022-05-07 14:13:23,861 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 14:13:23,862 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 14:13:23,900 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 14:13:23,919 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 14:13:23,919 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 14:13:23,920 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 14:13:23,959 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 14:13:23,959 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:13:23,959 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 14:13:23,974 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 14:13:23,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 14:13:23,975 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 14:13:23,994 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 14:13:23,995 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 14:13:23,995 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:13:24,050 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 14:13:24,135 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,135 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,135 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004134
2022-05-07 14:13:24,510 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 14:13:24,513 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 14:13:24,513 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:13:24,513 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 14:13:24,524 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.85f68452-2cf9-4807-b264-537898ba8cff
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:13:24,558 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,558 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,558 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004558
2022-05-07 14:13:24,565 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-1, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:13:24,566 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-1, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 14:13:24,566 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-1, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 14:13:24,567 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 14:13:24,567 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:13:24,567 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 14:13:24,568 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-1 unregistered
2022-05-07 14:13:24,589 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.85f68452-2cf9-4807-b264-537898ba8cff.errors' has 1 subscriber(s).
2022-05-07 14:13:24,589 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.85f68452-2cf9-4807-b264-537898ba8cff.errors' has 0 subscriber(s).
2022-05-07 14:13:24,590 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.85f68452-2cf9-4807-b264-537898ba8cff.errors' has 1 subscriber(s).
2022-05-07 14:13:24,590 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.85f68452-2cf9-4807-b264-537898ba8cff.errors' has 2 subscriber(s).
2022-05-07 14:13:24,606 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.85f68452-2cf9-4807-b264-537898ba8cff
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:13:24,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004611
2022-05-07 14:13:24,612 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 14:13:24,615 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@500ca189
2022-05-07 14:13:24,617 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 14:13:24,617 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:13:24,617 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 14:13:24,618 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 14:13:24,618 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:13:24,619 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 14:13:24,624 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,624 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 14:13:24,624 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,624 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004624
2022-05-07 14:13:24,625 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:13:24,626 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:13:24,628 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] (Re-)joining group
2022-05-07 14:13:24,635 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 14:13:24,637 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 14:13:24,637 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:13:24,637 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 14:13:24,638 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:13:24,643 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,644 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,644 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004643
2022-05-07 14:13:24,648 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-3, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:13:24,650 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-3, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 14:13:24,651 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-3, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 14:13:24,651 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 14:13:24,652 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:13:24,652 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 14:13:24,653 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-3 unregistered
2022-05-07 14:13:24,654 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9.errors' has 1 subscriber(s).
2022-05-07 14:13:24,654 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9.errors' has 0 subscriber(s).
2022-05-07 14:13:24,654 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9.errors' has 1 subscriber(s).
2022-05-07 14:13:24,654 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9.errors' has 2 subscriber(s).
2022-05-07 14:13:24,655 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:13:24,658 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:13:24,658 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:13:24,659 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651913004658
2022-05-07 14:13:24,659 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 14:13:24,660 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@57a062b3
2022-05-07 14:13:24,660 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 14:13:24,665 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Request joining group due to: need to re-join with the given member-id
2022-05-07 14:13:24,665 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 14:13:24,665 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:13:24,666 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] (Re-)joining group
2022-05-07 14:13:24,666 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:13:24,667 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] (Re-)joining group
2022-05-07 14:13:24,671 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Request joining group due to: need to re-join with the given member-id
2022-05-07 14:13:24,671 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] (Re-)joining group
2022-05-07 14:13:24,672 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2-83939c54-2ec7-4615-8053-2105c80e698e', protocol='range'}
2022-05-07 14:13:24,673 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 14:13:24,674 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Finished assignment for group at generation 1: {consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2-83939c54-2ec7-4615-8053-2105c80e698e=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 14:13:24,674 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4-2709eb5d-3a65-43ca-a634-6ee61e01a114', protocol='range'}
2022-05-07 14:13:24,674 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 14:13:24,674 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Finished assignment for group at generation 1: {consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4-2709eb5d-3a65-43ca-a634-6ee61e01a114=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 14:13:24,689 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2-83939c54-2ec7-4615-8053-2105c80e698e', protocol='range'}
2022-05-07 14:13:24,689 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4-2709eb5d-3a65-43ca-a634-6ee61e01a114', protocol='range'}
2022-05-07 14:13:24,689 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 14:13:24,689 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 14:13:24,691 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 14:13:24,691 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 14:13:24,697 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 14:13:24,697 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 14:13:24,701 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 14:13:24,701 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 14:13:24,713 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 14:13:24,714 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 14:13:24,719 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.85f68452-2cf9-4807-b264-537898ba8cff: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 14:13:24,719 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 14:13:24,763 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.083 seconds (JVM running for 5.571)
2022-05-07 14:13:34,406 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 14:13:34,407 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 14:13:34,409 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 2 ms
2022-05-07 14:13:34,435 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 14:13:34,514 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:77}] to localhost:27017
2022-05-07 14:13:34,556 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database com.cts.eauction.microservices.listing.model.ProductDetails@76f55e29
2022-05-07 14:28:09,559 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.85f68452-2cf9-4807-b264-537898ba8cff] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 14:28:09,558 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 14:28:09,561 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Error sending fetch request (sessionId=830074792, epoch=73) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 14:28:09,561 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Error sending fetch request (sessionId=1776700873, epoch=73) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 14:28:09,650 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9-4, groupId=anonymous.c24daaa5-39a3-426e-83aa-377d38afa1f9] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:28:09,650 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.85f68452-2cf9-4807-b264-537898ba8cff-2, groupId=anonymous.85f68452-2cf9-4807-b264-537898ba8cff] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:31:52,123 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 20400 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 14:31:52,126 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 14:31:52,126 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 14:31:52,164 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 14:31:52,165 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 14:31:52,166 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 14:31:52,166 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 14:31:52,617 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 14:31:52,715 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 95 ms. Found 4 MongoDB repository interfaces.
2022-05-07 14:31:52,866 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 14:31:52,874 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 14:31:52,947 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=25fe816b-8828-36ee-9d23-928762de3455
2022-05-07 14:31:52,996 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:31:53,051 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:31:53,503 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 14:31:53,513 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 14:31:53,513 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 14:31:53,514 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 14:31:53,609 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 14:31:53,609 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1442 ms
2022-05-07 14:31:53,712 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 14:31:53,758 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627635818be3c503a5ee5372', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:80}] to localhost:27017
2022-05-07 14:31:53,758 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635818be3c503a5ee5372', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:81}] to localhost:27017
2022-05-07 14:31:53,758 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635818be3c503a5ee5372', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15529600}
2022-05-07 14:31:53,789 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:31:53,836 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 14:31:53,870 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:31:53,983 WARN org.springframework.context.support.AbstractApplicationContext [restartedMain] Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingController': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'bidRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bidReadRepository' defined in com.cts.eauction.microservices.listing.repository.BidReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
2022-05-07 14:31:53,986 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Stopping service [Tomcat]
2022-05-07 14:31:53,999 INFO org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener [restartedMain] 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2022-05-07 14:31:54,025 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingController': Unsatisfied dependency expressed through field 'service'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'bidRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bidReadRepository' defined in com.cts.eauction.microservices.listing.repository.BidReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:953)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:145)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:740)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:415)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:303)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1312)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1301)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.main(EauctionHouseListingServiceApplication.java:33)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingService': Unsatisfied dependency expressed through field 'projection'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'bidRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bidReadRepository' defined in com.cts.eauction.microservices.listing.repository.BidReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'listingProjection': Unsatisfied dependency expressed through field 'bidRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bidReadRepository' defined in com.cts.eauction.microservices.listing.repository.BidReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'bidReadRepository' defined in com.cts.eauction.microservices.listing.repository.BidReadRepository defined in @EnableMongoRepositories declared on MongoRepositoriesRegistrar.EnableMongoRepositoriesConfiguration: Invocation of init method failed; nested exception is org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1389)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1309)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 53 common frames omitted
Caused by: org.springframework.data.repository.query.QueryCreationException: Could not create query for public abstract java.util.List com.cts.eauction.microservices.listing.repository.BidReadRepository.findByProductId(java.lang.Integer)! Reason: No property 'productId' found for type 'BidDetails'!; nested exception is org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.data.repository.query.QueryCreationException.create(QueryCreationException.java:101)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lookupQuery(QueryExecutorMethodInterceptor.java:106)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lambda$mapMethodsToQuery$1(QueryExecutorMethodInterceptor.java:94)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Collections$UnmodifiableCollection$1.forEachRemaining(Collections.java:1056)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.mapMethodsToQuery(QueryExecutorMethodInterceptor.java:96)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lambda$new$0(QueryExecutorMethodInterceptor.java:86)
	at java.base/java.util.Optional.map(Optional.java:258)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.<init>(QueryExecutorMethodInterceptor.java:86)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:364)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:322)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:230)
	at org.springframework.data.util.Lazy.get(Lazy.java:114)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:328)
	at org.springframework.data.mongodb.repository.support.MongoRepositoryFactoryBean.afterPropertiesSet(MongoRepositoryFactoryBean.java:119)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 63 common frames omitted
Caused by: org.springframework.data.mapping.PropertyReferenceException: No property 'productId' found for type 'BidDetails'!
	at org.springframework.data.mapping.PropertyPath.<init>(PropertyPath.java:90)
	at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:437)
	at org.springframework.data.mapping.PropertyPath.create(PropertyPath.java:413)
	at org.springframework.data.mapping.PropertyPath.lambda$from$0(PropertyPath.java:366)
	at java.base/java.util.concurrent.ConcurrentMap.computeIfAbsent(ConcurrentMap.java:330)
	at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:348)
	at org.springframework.data.mapping.PropertyPath.from(PropertyPath.java:331)
	at org.springframework.data.repository.query.parser.Part.<init>(Part.java:81)
	at org.springframework.data.repository.query.parser.PartTree$OrPart.lambda$new$0(PartTree.java:249)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.query.parser.PartTree$OrPart.<init>(PartTree.java:250)
	at org.springframework.data.repository.query.parser.PartTree$Predicate.lambda$new$0(PartTree.java:383)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177)
	at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578)
	at org.springframework.data.repository.query.parser.PartTree$Predicate.<init>(PartTree.java:384)
	at org.springframework.data.repository.query.parser.PartTree.<init>(PartTree.java:95)
	at org.springframework.data.mongodb.repository.query.PartTreeMongoQuery.<init>(PartTreeMongoQuery.java:67)
	at org.springframework.data.mongodb.repository.support.MongoRepositoryFactory$MongoQueryLookupStrategy.resolveQuery(MongoRepositoryFactory.java:207)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.lookupQuery(QueryExecutorMethodInterceptor.java:102)
	... 85 common frames omitted
2022-05-07 14:33:01,068 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 14:33:01,075 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 13076 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 14:33:01,075 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 14:33:01,108 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 14:33:01,108 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 14:33:01,109 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 14:33:01,109 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 14:33:01,575 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 14:33:01,668 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 90 ms. Found 5 MongoDB repository interfaces.
2022-05-07 14:33:01,823 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 14:33:01,833 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 14:33:01,907 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 14:33:01,960 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:33:02,006 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 14:33:02,393 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 14:33:02,400 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 14:33:02,400 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 14:33:02,400 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 14:33:02,493 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 14:33:02,493 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1383 ms
2022-05-07 14:33:02,583 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 14:33:02,631 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:83}] to localhost:27017
2022-05-07 14:33:02,631 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:82}] to localhost:27017
2022-05-07 14:33:02,631 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=14862200}
2022-05-07 14:33:02,661 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:33:02,705 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 14:33:02,742 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 14:33:03,336 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 14:33:03,458 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 14:33:03,471 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 14:33:03,560 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 14:33:03,560 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 14:33:03,564 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 14:33:03,565 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 14:33:03,565 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 14:33:03,570 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 14:33:03,666 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 14:33:03,672 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 14:33:03,699 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 14:33:03,700 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 14:33:03,701 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 14:33:03,701 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 14:33:03,701 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 14:33:03,701 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 14:33:03,701 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 14:33:03,898 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 14:33:03,904 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 14:33:03,910 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 14:33:03,923 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651914183922 with initial instances count: 6
2022-05-07 14:33:03,924 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 14:33:03,924 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651914183924, current=UP, previous=STARTING]
2022-05-07 14:33:03,925 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 14:33:03,926 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 14:33:03,960 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 14:33:03,982 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 14:33:03,982 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 14:33:03,983 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 14:33:04,023 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 14:33:04,023 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:33:04,023 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 14:33:04,039 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 14:33:04,039 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 14:33:04,040 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 14:33:04,070 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 14:33:04,070 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 14:33:04,070 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:33:04,116 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 14:33:04,185 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,185 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,185 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184183
2022-05-07 14:33:04,573 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 14:33:04,576 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 14:33:04,576 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:33:04,576 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 14:33:04,588 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:33:04,621 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,621 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,621 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184621
2022-05-07 14:33:04,628 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-1, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:33:04,629 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-1, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 14:33:04,629 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-1, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 14:33:04,630 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 14:33:04,630 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:33:04,630 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 14:33:04,631 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-1 unregistered
2022-05-07 14:33:04,647 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a.errors' has 1 subscriber(s).
2022-05-07 14:33:04,648 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a.errors' has 0 subscriber(s).
2022-05-07 14:33:04,649 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a.errors' has 1 subscriber(s).
2022-05-07 14:33:04,649 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a.errors' has 2 subscriber(s).
2022-05-07 14:33:04,665 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:33:04,670 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,670 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,670 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184669
2022-05-07 14:33:04,671 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 14:33:04,675 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@2cb76063
2022-05-07 14:33:04,676 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 14:33:04,676 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:33:04,676 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 14:33:04,676 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 14:33:04,676 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 14:33:04,677 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 14:33:04,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,683 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184683
2022-05-07 14:33:04,684 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 14:33:04,684 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:33:04,685 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:33:04,687 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] (Re-)joining group
2022-05-07 14:33:04,693 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 14:33:04,694 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 14:33:04,694 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:33:04,694 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 14:33:04,695 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:33:04,697 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Request joining group due to: need to re-join with the given member-id
2022-05-07 14:33:04,697 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] (Re-)joining group
2022-05-07 14:33:04,700 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,701 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,701 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184700
2022-05-07 14:33:04,704 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-3, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:33:04,705 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-3, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 14:33:04,705 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-3, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 14:33:04,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 14:33:04,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 14:33:04,705 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 14:33:04,706 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-3 unregistered
2022-05-07 14:33:04,708 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde.errors' has 1 subscriber(s).
2022-05-07 14:33:04,709 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde.errors' has 0 subscriber(s).
2022-05-07 14:33:04,709 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde.errors' has 1 subscriber(s).
2022-05-07 14:33:04,709 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde.errors' has 2 subscriber(s).
2022-05-07 14:33:04,709 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-79139582-ae6b-4898-8ee3-af3d4bb8ab97', protocol='range'}
2022-05-07 14:33:04,710 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 14:33:04,712 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Finished assignment for group at generation 1: {consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-79139582-ae6b-4898-8ee3-af3d4bb8ab97=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 14:33:04,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 14:33:04,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 14:33:04,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651914184715
2022-05-07 14:33:04,716 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 14:33:04,716 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@e045819
2022-05-07 14:33:04,717 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 14:33:04,719 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-79139582-ae6b-4898-8ee3-af3d4bb8ab97', protocol='range'}
2022-05-07 14:33:04,719 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 14:33:04,720 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 14:33:04,720 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 14:33:04,721 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 14:33:04,721 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 14:33:04,722 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] (Re-)joining group
2022-05-07 14:33:04,725 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Request joining group due to: need to re-join with the given member-id
2022-05-07 14:33:04,725 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] (Re-)joining group
2022-05-07 14:33:04,726 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 14:33:04,728 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 14:33:04,729 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 14:33:04,730 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 14:33:04,741 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 14:33:04,741 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4-f2b04969-5e02-4423-b98b-11f88f27c673', protocol='range'}
2022-05-07 14:33:04,741 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Finished assignment for group at generation 1: {consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4-f2b04969-5e02-4423-b98b-11f88f27c673=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 14:33:04,747 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4-f2b04969-5e02-4423-b98b-11f88f27c673', protocol='range'}
2022-05-07 14:33:04,747 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 14:33:04,747 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 14:33:04,747 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 14:33:04,749 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 14:33:04,750 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 14:33:04,754 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 14:33:04,756 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 14:33:04,821 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.717 seconds (JVM running for 5.197)
2022-05-07 14:33:10,815 INFO org.apache.juli.logging.DirectJDKLog [http-nio-8060-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2022-05-07 14:33:10,816 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Initializing Servlet 'dispatcherServlet'
2022-05-07 14:33:10,817 INFO org.springframework.web.servlet.FrameworkServlet [http-nio-8060-exec-2] Completed initialization in 1 ms
2022-05-07 14:33:10,844 INFO com.cts.eauction.microservices.listing.controller.ListingController [http-nio-8060-exec-2] productIdInQuery=39
2022-05-07 14:33:10,894 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-8060-exec-2] Opened connection [connectionId{localValue:3, serverValue:84}] to localhost:27017
2022-05-07 14:33:10,931 INFO com.cts.eauction.microservices.listing.repository.ListingProjection [http-nio-8060-exec-2] Products obtained from database com.cts.eauction.microservices.listing.model.ProductDetails@6b84f5be
2022-05-07 14:38:03,706 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:43:03,722 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:48:03,737 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:53:03,743 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 14:58:03,751 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:03:03,760 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:12:53,956 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Error sending fetch request (sessionId=116017643, epoch=3721) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 15:12:53,943 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 15:12:53,957 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:701)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:579)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:415)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:374)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:216)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:152)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:283)
	at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:309)
	at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:350)
	at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:803)
	at java.base/java.net.Socket$SocketInputStream.read(Socket.java:981)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:109)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:131)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:718)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:576)
	... 5 common frames omitted
2022-05-07 15:12:54,004 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Error sending fetch request (sessionId=1738696096, epoch=3721) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 15:12:54,007 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 15:12:54,022 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:4, serverValue:85}] to localhost:27017
2022-05-07 15:12:54,022 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627635c69dec3c2852bc914c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=40982700}
2022-05-07 15:12:54,031 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:12:54,033 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:12:54,034 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 15:12:54,039 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:12:54,043 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:12:54,153 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde-4, groupId=anonymous.ed2a0a05-c29b-45f6-98d3-70e8bc6bccde] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:12:54,887 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-79139582-ae6b-4898-8ee3-af3d4bb8ab97', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 15:12:54,887 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 15:12:54,888 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 15:12:54,888 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 15:12:54,888 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 15:12:54,890 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 15:12:54,891 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 15:12:54,892 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] (Re-)joining group
2022-05-07 15:12:54,905 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Request joining group due to: need to re-join with the given member-id
2022-05-07 15:12:54,906 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] (Re-)joining group
2022-05-07 15:12:54,919 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-de5da4f3-a766-450a-827f-946f5774cef9', protocol='range'}
2022-05-07 15:12:54,920 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Finished assignment for group at generation 3: {consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-de5da4f3-a766-450a-827f-946f5774cef9=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 15:12:54,928 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2-de5da4f3-a766-450a-827f-946f5774cef9', protocol='range'}
2022-05-07 15:12:54,929 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 15:12:54,929 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 15:12:54,938 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a-2, groupId=anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 15:12:54,939 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a34a0c3a-1802-4768-8ee6-cfac7622e56a: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 15:16:03,322 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:21:03,324 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:24:11,371 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 15:24:11,375 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 23364 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 15:24:11,375 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 15:24:11,406 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 15:24:11,406 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 15:24:11,407 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 15:24:11,407 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 15:24:11,886 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 15:24:11,986 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 97 ms. Found 5 MongoDB repository interfaces.
2022-05-07 15:24:12,140 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 15:24:12,149 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 15:24:12,227 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 15:24:12,275 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 15:24:12,323 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 15:24:12,792 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 15:24:12,805 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 15:24:12,805 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 15:24:12,805 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 15:24:12,913 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 15:24:12,913 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1505 ms
2022-05-07 15:24:13,043 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 15:24:13,105 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627641c5c8c904230b2ff07c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:88}] to localhost:27017
2022-05-07 15:24:13,105 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627641c5c8c904230b2ff07c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:89}] to localhost:27017
2022-05-07 15:24:13,105 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627641c5c8c904230b2ff07c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=18196201}
2022-05-07 15:24:13,145 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 15:24:13,195 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 15:24:13,232 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 15:24:13,889 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 15:24:14,011 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 15:24:14,028 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 15:24:14,115 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 15:24:14,116 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 15:24:14,118 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 15:24:14,118 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 15:24:14,118 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 15:24:14,123 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 15:24:14,223 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 15:24:14,227 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 15:24:14,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 15:24:14,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 15:24:14,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 15:24:14,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 15:24:14,256 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 15:24:14,257 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 15:24:14,257 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 15:24:14,450 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 15:24:14,459 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 15:24:14,466 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 15:24:14,481 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651917254480 with initial instances count: 6
2022-05-07 15:24:14,483 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 15:24:14,483 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651917254483, current=UP, previous=STARTING]
2022-05-07 15:24:14,485 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 15:24:14,486 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 15:24:14,515 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 15:24:14,544 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 15:24:14,545 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 15:24:14,546 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 15:24:14,584 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 15:24:14,585 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:24:14,585 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 15:24:14,599 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 15:24:14,600 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 15:24:14,600 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 15:24:14,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 15:24:14,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 15:24:14,622 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:24:14,670 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 15:24:14,769 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:14,769 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:14,769 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917254768
2022-05-07 15:24:15,157 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 15:24:15,160 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 15:24:15,161 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:24:15,161 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 15:24:15,172 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:24:15,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:15,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:15,215 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917255215
2022-05-07 15:24:15,225 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-1, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:24:15,227 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-1, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 15:24:15,227 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-1, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 15:24:15,227 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 15:24:15,228 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:24:15,228 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 15:24:15,229 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-1 unregistered
2022-05-07 15:24:15,255 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22.errors' has 1 subscriber(s).
2022-05-07 15:24:15,256 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22.errors' has 0 subscriber(s).
2022-05-07 15:24:15,256 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22.errors' has 1 subscriber(s).
2022-05-07 15:24:15,256 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22.errors' has 2 subscriber(s).
2022-05-07 15:24:15,275 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:24:15,279 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:15,279 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:15,279 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917255279
2022-05-07 15:24:15,280 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 15:24:15,284 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@44f3aee8
2022-05-07 15:24:15,286 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 15:24:15,286 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:24:15,286 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 15:24:15,287 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 15:24:15,287 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:24:15,289 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 15:24:15,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:15,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:15,293 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917255293
2022-05-07 15:24:15,299 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 15:24:15,300 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:24:15,312 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 15:24:15,313 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 15:24:15,315 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:24:15,315 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 15:24:15,315 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:24:15,321 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:15,322 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:15,322 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917255321
2022-05-07 15:24:15,329 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-3, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:24:15,331 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-3, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 15:24:15,331 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-3, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 15:24:15,331 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 15:24:15,332 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:24:15,332 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 15:24:15,333 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-3 unregistered
2022-05-07 15:24:15,333 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:24:15,334 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5.errors' has 1 subscriber(s).
2022-05-07 15:24:15,335 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5.errors' has 0 subscriber(s).
2022-05-07 15:24:15,335 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5.errors' has 1 subscriber(s).
2022-05-07 15:24:15,335 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5.errors' has 2 subscriber(s).
2022-05-07 15:24:15,335 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] (Re-)joining group
2022-05-07 15:24:15,336 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:24:15,342 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:24:15,342 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:24:15,343 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651917255342
2022-05-07 15:24:15,343 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 15:24:15,344 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@175c04d7
2022-05-07 15:24:15,344 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 15:24:15,350 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 15:24:15,350 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:24:15,350 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:24:15,352 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] (Re-)joining group
2022-05-07 15:24:15,358 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 15:24:15,360 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 15:24:15,384 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Request joining group due to: need to re-join with the given member-id
2022-05-07 15:24:15,386 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] (Re-)joining group
2022-05-07 15:24:15,395 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Request joining group due to: need to re-join with the given member-id
2022-05-07 15:24:15,396 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] (Re-)joining group
2022-05-07 15:24:15,426 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2-a2aaf1cc-e1e6-4b6e-8f3a-4a4ba20096a0', protocol='range'}
2022-05-07 15:24:15,428 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Finished assignment for group at generation 1: {consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2-a2aaf1cc-e1e6-4b6e-8f3a-4a4ba20096a0=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 15:24:15,428 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4-9aacc948-128f-444e-80e8-9ac2dff0bf65', protocol='range'}
2022-05-07 15:24:15,428 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Finished assignment for group at generation 1: {consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4-9aacc948-128f-444e-80e8-9ac2dff0bf65=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 15:24:15,444 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.058 seconds (JVM running for 5.562)
2022-05-07 15:24:15,497 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4-9aacc948-128f-444e-80e8-9ac2dff0bf65', protocol='range'}
2022-05-07 15:24:15,497 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2-a2aaf1cc-e1e6-4b6e-8f3a-4a4ba20096a0', protocol='range'}
2022-05-07 15:24:15,498 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 15:24:15,498 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 15:24:15,499 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 15:24:15,499 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 15:24:15,513 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 15:24:15,513 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 15:24:15,516 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 15:24:15,516 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 15:24:15,531 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5-4, groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=25, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 15:24:15,531 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22-2, groupId=anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 15:24:15,551 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 15:24:15,551 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.fe7eac69-3da1-4c70-ab85-1b3e2d485b22: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 15:29:14,265 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:29:50,063 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:29:51,105 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:29:53,118 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:29:53,122 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=25, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@5b45f822, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651917589848, kafka_groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:61)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 15:29:53,129 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@25
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=25, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@5b45f822, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651917589848, kafka_groupId=anonymous.a7c07d8e-aab7-4c99-96c9-5de1560d29e5}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:61)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 15:34:14,272 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:39:14,277 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 15:42:49,142 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 5520 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 15:42:49,144 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 15:42:49,144 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 15:42:49,189 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 15:42:49,189 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 15:42:49,191 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 15:42:49,191 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 15:42:49,683 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 15:42:49,803 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 116 ms. Found 5 MongoDB repository interfaces.
2022-05-07 15:42:50,032 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 15:42:50,043 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 15:42:50,122 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 15:42:50,178 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 15:42:50,234 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 15:42:50,732 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 15:42:50,744 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 15:42:50,744 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 15:42:50,744 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 15:42:50,854 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 15:42:50,854 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1662 ms
2022-05-07 15:42:50,981 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 15:42:51,059 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62764622cc27021342739e47', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:94}] to localhost:27017
2022-05-07 15:42:51,059 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764622cc27021342739e47', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:95}] to localhost:27017
2022-05-07 15:42:51,059 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764622cc27021342739e47', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=21910800}
2022-05-07 15:42:51,090 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 15:42:51,139 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 15:42:51,180 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 15:42:51,774 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 15:42:51,913 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 15:42:51,930 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 15:42:52,057 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 15:42:52,057 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 15:42:52,062 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 15:42:52,062 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 15:42:52,063 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 15:42:52,072 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 15:42:52,175 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 15:42:52,180 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 15:42:52,209 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 15:42:52,394 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 15:42:52,401 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 15:42:52,409 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 15:42:52,425 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651918372423 with initial instances count: 6
2022-05-07 15:42:52,426 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 15:42:52,426 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651918372426, current=UP, previous=STARTING]
2022-05-07 15:42:52,427 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 15:42:52,428 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 15:42:52,464 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 15:42:52,495 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 15:42:52,495 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 15:42:52,495 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 15:42:52,537 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 15:42:52,537 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:42:52,537 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 15:42:52,553 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 15:42:52,553 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 15:42:52,553 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 15:42:52,571 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 15:42:52,572 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 15:42:52,572 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:42:52,617 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 15:42:52,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:52,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:52,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918372692
2022-05-07 15:42:53,058 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 15:42:53,060 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 15:42:53,061 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:42:53,061 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 15:42:53,074 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:42:53,109 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:53,109 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:53,109 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918373109
2022-05-07 15:42:53,117 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-1, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:42:53,118 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-1, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 15:42:53,118 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-1, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 15:42:53,118 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 15:42:53,118 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:42:53,120 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 15:42:53,122 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-1 unregistered
2022-05-07 15:42:53,148 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa.errors' has 1 subscriber(s).
2022-05-07 15:42:53,149 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa.errors' has 0 subscriber(s).
2022-05-07 15:42:53,149 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa.errors' has 1 subscriber(s).
2022-05-07 15:42:53,149 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa.errors' has 2 subscriber(s).
2022-05-07 15:42:53,170 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:42:53,174 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:53,174 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:53,174 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918373174
2022-05-07 15:42:53,175 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 15:42:53,179 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@61f017ac
2022-05-07 15:42:53,181 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 15:42:53,181 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:42:53,181 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 15:42:53,181 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 15:42:53,181 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 15:42:53,182 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 15:42:53,186 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:53,186 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:53,186 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918373186
2022-05-07 15:42:53,187 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 15:42:53,187 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:42:53,195 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 15:42:53,197 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 15:42:53,197 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:42:53,197 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 15:42:53,198 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:42:53,203 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:42:53,203 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:53,203 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:53,204 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918373203
2022-05-07 15:42:53,206 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] (Re-)joining group
2022-05-07 15:42:53,208 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-3, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:42:53,208 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-3, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 15:42:53,208 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-3, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 15:42:53,208 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 15:42:53,208 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 15:42:53,208 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 15:42:53,210 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-3 unregistered
2022-05-07 15:42:53,211 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56.errors' has 1 subscriber(s).
2022-05-07 15:42:53,211 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56.errors' has 0 subscriber(s).
2022-05-07 15:42:53,212 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56.errors' has 1 subscriber(s).
2022-05-07 15:42:53,212 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56.errors' has 2 subscriber(s).
2022-05-07 15:42:53,213 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 15:42:53,219 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 15:42:53,219 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 15:42:53,219 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651918373219
2022-05-07 15:42:53,219 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 15:42:53,221 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@3fcc7fdd
2022-05-07 15:42:53,221 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 15:42:53,225 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 15:42:53,226 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 15:42:53,226 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 15:42:53,227 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] (Re-)joining group
2022-05-07 15:42:53,234 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 15:42:53,235 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 15:42:53,236 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Request joining group due to: need to re-join with the given member-id
2022-05-07 15:42:53,236 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] (Re-)joining group
2022-05-07 15:42:53,246 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Request joining group due to: need to re-join with the given member-id
2022-05-07 15:42:53,247 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] (Re-)joining group
2022-05-07 15:42:53,254 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-7c9255ab-b8b4-4c64-80e4-06692510cdd6', protocol='range'}
2022-05-07 15:42:53,256 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-6f1ec437-0335-4787-a0c3-bbb9a3dfd5fe', protocol='range'}
2022-05-07 15:42:53,258 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Finished assignment for group at generation 1: {consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-6f1ec437-0335-4787-a0c3-bbb9a3dfd5fe=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 15:42:53,258 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Finished assignment for group at generation 1: {consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-7c9255ab-b8b4-4c64-80e4-06692510cdd6=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 15:42:53,351 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.294 seconds (JVM running for 6.05)
2022-05-07 15:42:53,357 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-6f1ec437-0335-4787-a0c3-bbb9a3dfd5fe', protocol='range'}
2022-05-07 15:42:53,358 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 15:42:53,360 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-7c9255ab-b8b4-4c64-80e4-06692510cdd6', protocol='range'}
2022-05-07 15:42:53,360 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 15:42:53,362 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 15:42:53,362 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 15:42:53,422 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 15:42:53,422 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 15:42:53,427 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 15:42:53,427 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 15:42:53,470 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 15:42:53,470 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=26, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 15:42:53,480 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 15:42:53,480 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 15:43:04,922 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:43:05,945 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:43:07,955 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 15:43:07,959 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=26, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@799e244b, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651918384525, kafka_groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:61)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 15:43:07,971 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@26
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=26, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@799e244b, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651918384525, kafka_groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:61)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 16:03:20,182 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Error sending fetch request (sessionId=2022052080, epoch=98) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 16:03:20,183 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 16:03:20,184 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Error sending fetch request (sessionId=1933208251, epoch=92) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 16:03:20,184 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 16:03:20,303 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:03:21,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-6f1ec437-0335-4787-a0c3-bbb9a3dfd5fe', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 16:03:21,487 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 16:03:21,488 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 16:03:21,488 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 16:03:21,488 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-07 16:03:21,489 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56: partitions lost: [PRODUCT_TOPIC-0]
2022-05-07 16:03:21,490 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-07 16:03:21,491 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] (Re-)joining group
2022-05-07 16:03:21,494 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:03:21,741 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:03:21,742 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] (Re-)joining group
2022-05-07 16:03:21,752 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-7499a61d-7106-411f-817a-a654ea983940', protocol='range'}
2022-05-07 16:03:21,752 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Finished assignment for group at generation 3: {consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-7499a61d-7106-411f-817a-a654ea983940=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 16:03:21,752 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-7c9255ab-b8b4-4c64-80e4-06692510cdd6', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 16:03:21,752 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 16:03:21,752 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 16:03:21,753 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 16:03:21,753 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 16:03:21,753 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:03:21,753 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:03:21,753 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] (Re-)joining group
2022-05-07 16:03:21,763 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:03:21,763 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] (Re-)joining group
2022-05-07 16:03:21,768 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4-7499a61d-7106-411f-817a-a654ea983940', protocol='range'}
2022-05-07 16:03:21,769 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 16:03:21,769 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 16:03:21,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56-4, groupId=anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=27, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 16:03:21,772 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.0eca8f84-7583-4f76-b676-6eaa3d9e2c56: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 16:03:21,870 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-dc0b0d8b-6db1-4a50-a01e-c395886b4a9b', protocol='range'}
2022-05-07 16:03:21,871 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Finished assignment for group at generation 3: {consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-dc0b0d8b-6db1-4a50-a01e-c395886b4a9b=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 16:03:21,878 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2-dc0b0d8b-6db1-4a50-a01e-c395886b4a9b', protocol='range'}
2022-05-07 16:03:21,878 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 16:03:21,878 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 16:03:21,886 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa-2, groupId=anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 16:03:21,886 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.2f2d7485-18eb-40cf-b495-aa72d69415fa: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:07:28,525 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 16:09:04,196 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 16:09:04,199 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 1916 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 16:09:04,200 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 16:09:04,237 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 16:09:04,237 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 16:09:04,238 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 16:09:04,239 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 16:09:04,781 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 16:09:04,883 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 97 ms. Found 5 MongoDB repository interfaces.
2022-05-07 16:09:05,043 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 16:09:05,053 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 16:09:05,132 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 16:09:05,186 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:09:05,267 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:09:05,786 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 16:09:05,797 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 16:09:05,797 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 16:09:05,798 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 16:09:05,902 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 16:09:05,903 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1664 ms
2022-05-07 16:09:06,005 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 16:09:06,063 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764c4a329367633a5b309b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:99}] to localhost:27017
2022-05-07 16:09:06,063 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62764c4a329367633a5b309b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:98}] to localhost:27017
2022-05-07 16:09:06,064 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764c4a329367633a5b309b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17709400}
2022-05-07 16:09:06,103 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:09:06,153 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 16:09:06,193 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:09:06,831 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 16:09:06,980 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 16:09:06,993 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 16:09:07,120 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 16:09:07,120 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 16:09:07,124 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 16:09:07,124 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 16:09:07,124 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 16:09:07,131 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 16:09:07,220 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 16:09:07,223 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 16:09:07,250 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 16:09:07,250 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 16:09:07,250 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 16:09:07,251 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 16:09:07,251 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 16:09:07,251 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 16:09:07,251 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 16:09:07,451 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 16:09:07,457 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 16:09:07,464 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 16:09:07,480 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651919947478 with initial instances count: 6
2022-05-07 16:09:07,482 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 16:09:07,482 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651919947482, current=UP, previous=STARTING]
2022-05-07 16:09:07,483 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 16:09:07,484 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 16:09:07,524 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 16:09:07,544 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 16:09:07,544 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:09:07,545 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 16:09:07,590 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 16:09:07,590 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:09:07,590 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 16:09:07,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 16:09:07,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:09:07,609 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 16:09:07,634 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 16:09:07,634 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:09:07,634 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:09:07,686 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:09:07,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:07,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:07,772 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919947771
2022-05-07 16:09:08,195 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 16:09:08,199 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 16:09:08,200 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:09:08,200 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 16:09:08,216 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:09:08,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:08,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:08,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919948260
2022-05-07 16:09:08,270 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-1, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:09:08,271 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-1, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:09:08,271 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-1, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:09:08,271 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:09:08,271 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:09:08,271 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:09:08,273 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-1 unregistered
2022-05-07 16:09:08,299 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb.errors' has 1 subscriber(s).
2022-05-07 16:09:08,299 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb.errors' has 0 subscriber(s).
2022-05-07 16:09:08,300 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb.errors' has 1 subscriber(s).
2022-05-07 16:09:08,300 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb.errors' has 2 subscriber(s).
2022-05-07 16:09:08,319 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:09:08,325 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:08,325 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:08,325 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919948325
2022-05-07 16:09:08,326 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 16:09:08,329 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@603b1083
2022-05-07 16:09:08,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:09:08,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:09:08,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:09:08,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:09:08,331 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:09:08,332 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:09:08,338 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:08,338 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:08,338 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919948338
2022-05-07 16:09:08,338 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 16:09:08,339 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:09:08,346 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:09:08,349 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] (Re-)joining group
2022-05-07 16:09:08,350 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 16:09:08,352 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 16:09:08,352 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:09:08,352 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 16:09:08,353 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:09:08,359 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:08,359 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:08,359 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919948359
2022-05-07 16:09:08,362 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-3, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:09:08,362 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-3, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:09:08,362 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-3, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:09:08,364 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:09:08,364 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:09:08,364 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:09:08,364 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:09:08,365 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] (Re-)joining group
2022-05-07 16:09:08,365 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-3 unregistered
2022-05-07 16:09:08,367 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3.errors' has 1 subscriber(s).
2022-05-07 16:09:08,368 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3.errors' has 0 subscriber(s).
2022-05-07 16:09:08,368 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3.errors' has 1 subscriber(s).
2022-05-07 16:09:08,369 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3.errors' has 2 subscriber(s).
2022-05-07 16:09:08,370 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:09:08,374 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:09:08,374 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:09:08,374 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651919948374
2022-05-07 16:09:08,375 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 16:09:08,375 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7f99b58c
2022-05-07 16:09:08,376 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 16:09:08,381 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2-3b66502a-0f18-4ab9-83a3-9eaede6157dc', protocol='range'}
2022-05-07 16:09:08,381 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 16:09:08,382 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:09:08,383 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:09:08,383 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] (Re-)joining group
2022-05-07 16:09:08,386 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Finished assignment for group at generation 1: {consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2-3b66502a-0f18-4ab9-83a3-9eaede6157dc=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 16:09:08,389 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:09:08,389 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] (Re-)joining group
2022-05-07 16:09:08,390 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 16:09:08,391 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 16:09:08,391 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4-da196225-7572-47ca-875e-b5260cfc76b2', protocol='range'}
2022-05-07 16:09:08,392 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Finished assignment for group at generation 1: {consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4-da196225-7572-47ca-875e-b5260cfc76b2=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 16:09:08,393 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2-3b66502a-0f18-4ab9-83a3-9eaede6157dc', protocol='range'}
2022-05-07 16:09:08,394 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 16:09:08,396 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4-da196225-7572-47ca-875e-b5260cfc76b2', protocol='range'}
2022-05-07 16:09:08,396 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 16:09:08,397 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 16:09:08,397 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 16:09:08,403 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:09:08,403 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:09:08,409 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:09:08,409 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:09:08,421 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb-2, groupId=anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:09:08,421 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3-4, groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=27, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:09:08,426 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 16:09:08,426 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.9eb9c584-f1ed-401f-ba5e-e668516842eb: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:09:08,494 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.447 seconds (JVM running for 5.974)
2022-05-07 16:09:26,033 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:09:26,049 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:09:27,086 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:09:27,087 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:09:29,090 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:09:29,092 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:09:29,095 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=27, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@77b7a312, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651919965972, kafka_groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 16:09:29,103 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@27
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=27, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@77b7a312, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651919965972, kafka_groupId=anonymous.824c44e9-785c-4343-bf69-50de3c2a6da3}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 16:14:07,267 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 16:15:10,563 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 24872 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 16:15:10,562 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 16:15:10,564 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 16:15:10,595 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 16:15:10,595 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 16:15:10,596 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 16:15:10,596 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 16:15:11,061 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 16:15:11,157 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 93 ms. Found 5 MongoDB repository interfaces.
2022-05-07 16:15:11,330 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 16:15:11,338 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 16:15:11,425 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 16:15:11,481 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:15:11,531 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:15:11,929 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 16:15:11,936 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 16:15:11,936 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 16:15:11,937 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 16:15:12,036 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 16:15:12,036 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1439 ms
2022-05-07 16:15:12,173 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 16:15:12,228 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764db87ba5fc1372a4511c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:100}] to localhost:27017
2022-05-07 16:15:12,228 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62764db87ba5fc1372a4511c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:101}] to localhost:27017
2022-05-07 16:15:12,229 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764db87ba5fc1372a4511c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=16386900}
2022-05-07 16:15:12,254 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:15:12,304 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 16:15:12,337 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:15:12,950 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 16:15:13,067 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 16:15:13,079 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 16:15:13,178 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 16:15:13,179 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 16:15:13,182 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 16:15:13,183 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 16:15:13,183 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 16:15:13,192 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 16:15:13,270 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 16:15:13,276 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 16:15:13,307 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 16:15:13,308 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 16:15:13,459 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 16:15:13,467 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 16:15:13,474 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 16:15:13,489 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651920313489 with initial instances count: 6
2022-05-07 16:15:13,492 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 16:15:13,492 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651920313492, current=UP, previous=STARTING]
2022-05-07 16:15:13,493 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 16:15:13,493 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 16:15:13,522 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 16:15:13,559 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 16:15:13,559 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:15:13,559 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 16:15:13,606 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 16:15:13,606 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:15:13,607 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 16:15:13,623 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 16:15:13,623 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:15:13,623 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 16:15:13,641 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 16:15:13,641 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:15:13,641 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:15:13,692 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:15:13,741 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:13,741 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:13,741 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920313740
2022-05-07 16:15:13,966 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 16:15:13,969 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 16:15:13,969 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:15:13,969 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 16:15:13,977 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.187dde79-54d0-4461-a6c7-78a37ad73218
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:15:14,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:14,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:14,004 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920314004
2022-05-07 16:15:14,009 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-1, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:15:14,010 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-1, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:15:14,010 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-1, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:15:14,010 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:15:14,010 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:15:14,010 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:15:14,011 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-1 unregistered
2022-05-07 16:15:14,028 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.187dde79-54d0-4461-a6c7-78a37ad73218.errors' has 1 subscriber(s).
2022-05-07 16:15:14,029 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.187dde79-54d0-4461-a6c7-78a37ad73218.errors' has 0 subscriber(s).
2022-05-07 16:15:14,029 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.187dde79-54d0-4461-a6c7-78a37ad73218.errors' has 1 subscriber(s).
2022-05-07 16:15:14,029 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.187dde79-54d0-4461-a6c7-78a37ad73218.errors' has 2 subscriber(s).
2022-05-07 16:15:14,041 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.187dde79-54d0-4461-a6c7-78a37ad73218
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:15:14,045 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:14,046 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:14,046 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920314045
2022-05-07 16:15:14,047 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 16:15:14,051 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@5b4d60d5
2022-05-07 16:15:14,052 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:15:14,052 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:15:14,052 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:15:14,052 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:15:14,053 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:15:14,054 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:15:14,057 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:14,057 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:14,057 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 16:15:14,057 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920314057
2022-05-07 16:15:14,058 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:15:14,058 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:15:14,059 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] (Re-)joining group
2022-05-07 16:15:14,073 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 16:15:14,074 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 16:15:14,074 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:15:14,075 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 16:15:14,076 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:15:14,077 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:15:14,078 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] (Re-)joining group
2022-05-07 16:15:14,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:14,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:14,084 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920314084
2022-05-07 16:15:14,088 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-3, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:15:14,089 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-3, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:15:14,089 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-3, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:15:14,089 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:15:14,089 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:15:14,089 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:15:14,091 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-3 unregistered
2022-05-07 16:15:14,094 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86.errors' has 1 subscriber(s).
2022-05-07 16:15:14,095 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86.errors' has 0 subscriber(s).
2022-05-07 16:15:14,095 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86.errors' has 1 subscriber(s).
2022-05-07 16:15:14,095 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86.errors' has 2 subscriber(s).
2022-05-07 16:15:14,097 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:15:14,102 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:15:14,103 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:15:14,103 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920314102
2022-05-07 16:15:14,103 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 16:15:14,103 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2-84657d7a-df30-4858-9ab5-2587cefbd699', protocol='range'}
2022-05-07 16:15:14,105 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1996f1b6
2022-05-07 16:15:14,106 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 16:15:14,107 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Finished assignment for group at generation 1: {consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2-84657d7a-df30-4858-9ab5-2587cefbd699=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 16:15:14,116 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 16:15:14,116 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:15:14,116 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:15:14,117 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] (Re-)joining group
2022-05-07 16:15:14,128 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:15:14,129 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2-84657d7a-df30-4858-9ab5-2587cefbd699', protocol='range'}
2022-05-07 16:15:14,129 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] (Re-)joining group
2022-05-07 16:15:14,129 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 16:15:14,130 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 16:15:14,131 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 16:15:14,132 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4-e817bf47-4ab3-4ab3-a4bb-ef56b6c36d31', protocol='range'}
2022-05-07 16:15:14,132 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Finished assignment for group at generation 1: {consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4-e817bf47-4ab3-4ab3-a4bb-ef56b6c36d31=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 16:15:14,135 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 16:15:14,136 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4-e817bf47-4ab3-4ab3-a4bb-ef56b6c36d31', protocol='range'}
2022-05-07 16:15:14,136 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 16:15:14,137 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 16:15:14,145 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:15:14,145 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:15:14,150 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:15:14,150 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:15:14,161 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86-4, groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=28, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:15:14,161 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.187dde79-54d0-4461-a6c7-78a37ad73218-2, groupId=anonymous.187dde79-54d0-4461-a6c7-78a37ad73218] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:15:14,168 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.187dde79-54d0-4461-a6c7-78a37ad73218: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:15:14,168 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 16:15:14,241 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.673 seconds (JVM running for 5.179)
2022-05-07 16:16:24,831 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:16:24,845 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:16:25,869 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:16:25,869 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:16:27,886 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:16:27,886 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:16:27,889 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=28, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@3534136, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651920384718, kafka_groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 16:16:27,896 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@28
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=28, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@3534136, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651920384718, kafka_groupId=anonymous.15e1c424-0f9a-4af2-9494-c46ee211ee86}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 16:18:54,380 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 16:18:54,382 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 22608 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 16:18:54,383 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 16:18:54,414 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 16:18:54,415 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 16:18:54,415 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 16:18:54,416 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 16:18:54,878 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 16:18:54,982 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 100 ms. Found 5 MongoDB repository interfaces.
2022-05-07 16:18:55,135 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 16:18:55,144 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 16:18:55,219 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 16:18:55,268 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:18:55,308 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 16:18:55,701 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 16:18:55,708 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 16:18:55,708 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 16:18:55,708 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 16:18:55,797 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 16:18:55,798 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1382 ms
2022-05-07 16:18:55,902 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 16:18:55,951 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62764e97ab43cc419d692ee5', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:102}] to localhost:27017
2022-05-07 16:18:55,951 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764e97ab43cc419d692ee5', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:103}] to localhost:27017
2022-05-07 16:18:55,952 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62764e97ab43cc419d692ee5', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=15675100}
2022-05-07 16:18:55,989 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:18:56,035 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 16:18:56,067 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 16:18:56,650 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 16:18:56,771 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 16:18:56,785 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 16:18:56,870 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 16:18:56,871 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 16:18:56,873 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 16:18:56,873 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 16:18:56,874 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 16:18:56,878 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 16:18:56,949 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 16:18:56,953 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 16:18:56,978 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 16:18:56,979 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 16:18:57,145 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 16:18:57,152 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 16:18:57,158 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 16:18:57,175 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651920537174 with initial instances count: 6
2022-05-07 16:18:57,176 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 16:18:57,176 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651920537176, current=UP, previous=STARTING]
2022-05-07 16:18:57,177 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 16:18:57,178 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 16:18:57,213 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 16:18:57,232 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 16:18:57,232 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:18:57,232 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 16:18:57,271 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 16:18:57,271 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:18:57,271 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 16:18:57,288 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 16:18:57,288 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:18:57,288 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 16:18:57,309 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 16:18:57,309 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:18:57,309 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:18:57,361 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:18:57,416 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,416 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,416 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537415
2022-05-07 16:18:57,640 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 16:18:57,643 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 16:18:57,644 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:18:57,644 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 16:18:57,656 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8760d60c-4732-4591-ac45-10306e190685
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:18:57,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,694 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537694
2022-05-07 16:18:57,702 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-1, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:18:57,703 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-1, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:18:57,703 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-1, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:18:57,703 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:18:57,703 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:18:57,703 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:18:57,705 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-1 unregistered
2022-05-07 16:18:57,728 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.8760d60c-4732-4591-ac45-10306e190685.errors' has 1 subscriber(s).
2022-05-07 16:18:57,728 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.8760d60c-4732-4591-ac45-10306e190685.errors' has 0 subscriber(s).
2022-05-07 16:18:57,728 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.8760d60c-4732-4591-ac45-10306e190685.errors' has 1 subscriber(s).
2022-05-07 16:18:57,729 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.8760d60c-4732-4591-ac45-10306e190685.errors' has 2 subscriber(s).
2022-05-07 16:18:57,743 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.8760d60c-4732-4591-ac45-10306e190685
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:18:57,746 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,747 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,747 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537746
2022-05-07 16:18:57,747 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 16:18:57,750 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@456a4be0
2022-05-07 16:18:57,751 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 16:18:57,751 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:18:57,751 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 16:18:57,752 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 16:18:57,752 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 16:18:57,753 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 16:18:57,756 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 16:18:57,756 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:18:57,758 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:18:57,758 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,758 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,758 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537758
2022-05-07 16:18:57,759 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] (Re-)joining group
2022-05-07 16:18:57,767 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 16:18:57,768 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 16:18:57,768 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:18:57,768 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 16:18:57,769 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:18:57,770 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:18:57,770 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] (Re-)joining group
2022-05-07 16:18:57,774 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,774 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,775 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537774
2022-05-07 16:18:57,779 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-3, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:18:57,779 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-3, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 16:18:57,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-3, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 16:18:57,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 16:18:57,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 16:18:57,780 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 16:18:57,782 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-3 unregistered
2022-05-07 16:18:57,784 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-14e2c266-91c1-41a2-8dc9-8e3ff0138181', protocol='range'}
2022-05-07 16:18:57,784 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165.errors' has 1 subscriber(s).
2022-05-07 16:18:57,785 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165.errors' has 0 subscriber(s).
2022-05-07 16:18:57,785 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165.errors' has 1 subscriber(s).
2022-05-07 16:18:57,785 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165.errors' has 2 subscriber(s).
2022-05-07 16:18:57,786 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 16:18:57,786 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Finished assignment for group at generation 1: {consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-14e2c266-91c1-41a2-8dc9-8e3ff0138181=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 16:18:57,790 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 16:18:57,790 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 16:18:57,790 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651920537790
2022-05-07 16:18:57,791 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 16:18:57,791 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7674e469
2022-05-07 16:18:57,792 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 16:18:57,794 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-14e2c266-91c1-41a2-8dc9-8e3ff0138181', protocol='range'}
2022-05-07 16:18:57,794 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 16:18:57,795 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 16:18:57,795 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 16:18:57,795 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 16:18:57,797 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 16:18:57,797 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] (Re-)joining group
2022-05-07 16:18:57,801 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Request joining group due to: need to re-join with the given member-id
2022-05-07 16:18:57,802 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] (Re-)joining group
2022-05-07 16:18:57,803 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:18:57,807 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 16:18:57,808 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 16:18:57,808 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 16:18:57,814 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-5bd90ba0-1f46-4ca1-9977-0554e665139b', protocol='range'}
2022-05-07 16:18:57,815 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Finished assignment for group at generation 1: {consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-5bd90ba0-1f46-4ca1-9977-0554e665139b=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 16:18:57,818 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-5bd90ba0-1f46-4ca1-9977-0554e665139b', protocol='range'}
2022-05-07 16:18:57,818 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 16:18:57,818 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 16:18:57,820 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:18:57,821 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:18:57,821 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 16:18:57,825 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.8760d60c-4732-4591-ac45-10306e190685: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 16:18:57,828 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=29, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 16:18:57,830 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 16:18:57,902 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.442 seconds (JVM running for 4.914)
2022-05-07 16:19:07,570 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:19:07,587 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:19:08,612 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:19:08,614 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:19:10,616 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 16:19:10,617 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 16:19:10,621 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=29, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4a84b8a8, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651920547466, kafka_groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 16:19:10,628 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@29
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=29, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@4a84b8a8, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651920547466, kafka_groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 19:54:25,248 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.8760d60c-4732-4591-ac45-10306e190685] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 19:54:25,248 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=882698229, epoch=459) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:54:25,249 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=1384311844, epoch=454) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:54:25,249 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 19:54:28,103 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 19:54:28,105 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 19:54:28,107 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-5bd90ba0-1f46-4ca1-9977-0554e665139b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-14e2c266-91c1-41a2-8dc9-8e3ff0138181', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 19:54:28,109 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 19:54:28,110 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 19:54:28,110 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 19:54:28,110 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-07 19:54:28,110 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 19:54:28,111 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165: partitions lost: [PRODUCT_TOPIC-0]
2022-05-07 19:54:28,111 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.8760d60c-4732-4591-ac45-10306e190685: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 19:54:28,112 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-07 19:54:28,112 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.8760d60c-4732-4591-ac45-10306e190685: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 19:54:28,112 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] (Re-)joining group
2022-05-07 19:54:28,113 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] (Re-)joining group
2022-05-07 19:54:28,423 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Request joining group due to: need to re-join with the given member-id
2022-05-07 19:54:28,425 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] (Re-)joining group
2022-05-07 19:54:28,747 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Request joining group due to: need to re-join with the given member-id
2022-05-07 19:54:28,748 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] (Re-)joining group
2022-05-07 19:54:28,764 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-e3c197e2-ba6c-426a-bf39-f1e456ba17ef', protocol='range'}
2022-05-07 19:54:28,764 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Finished assignment for group at generation 3: {consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-e3c197e2-ba6c-426a-bf39-f1e456ba17ef=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 19:54:28,766 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-223fa9ab-d8bd-4ce1-8fdc-6a257444173c', protocol='range'}
2022-05-07 19:54:28,766 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Finished assignment for group at generation 3: {consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-223fa9ab-d8bd-4ce1-8fdc-6a257444173c=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 19:54:28,771 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2-e3c197e2-ba6c-426a-bf39-f1e456ba17ef', protocol='range'}
2022-05-07 19:54:28,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 19:54:28,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 19:54:28,777 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 19:54:28,777 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.8760d60c-4732-4591-ac45-10306e190685: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 19:54:28,790 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4-223fa9ab-d8bd-4ce1-8fdc-6a257444173c', protocol='range'}
2022-05-07 19:54:28,791 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 19:54:28,792 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 19:54:28,794 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 19:54:28,795 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 19:55:28,477 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 19:58:22,309 INFO org.apache.kafka.clients.FetchSessionHandler [kafka-coordinator-heartbeat-thread | anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=454) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:22,309 INFO org.apache.kafka.clients.FetchSessionHandler [kafka-coordinator-heartbeat-thread | anonymous.8760d60c-4732-4591-ac45-10306e190685] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=454) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:22,312 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 19:58:22,312 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.8760d60c-4732-4591-ac45-10306e190685] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 19:58:24,482 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:24,482 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:26,695 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:26,695 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:26,696 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:26,696 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:28,980 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:28,980 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:31,503 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:31,503 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:31,504 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:31,504 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:34,280 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:34,530 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:37,375 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:37,376 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:37,438 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:37,439 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:40,275 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:40,663 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:43,292 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:43,760 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:46,445 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:46,446 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:46,864 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:46,865 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:49,353 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:49,958 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:52,441 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:52,452 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:53,096 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:58:59,571 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:58:59,571 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:01,726 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:01,727 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:01,727 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:01,727 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:03,877 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:03,877 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:06,157 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:06,157 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:06,158 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:06,158 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:08,571 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:08,694 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:11,548 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:11,549 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:11,734 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:11,735 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:14,632 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:15,006 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:17,534 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:17,534 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:18,078 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:20,692 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:21,048 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:21,049 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:23,709 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:24,082 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:26,802 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:26,803 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:27,113 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:27,114 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:30,013 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:30,013 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:32,953 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:33,282 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:36,043 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:36,044 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:36,421 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:36,422 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:39,320 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:39,679 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:42,605 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:42,605 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:42,715 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:42,715 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:45,751 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:45,797 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:48,770 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:49,080 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:51,799 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:51,800 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:52,112 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:52,113 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 19:59:54,947 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:55,385 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:57,968 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 19:59:58,311 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:00,879 WARN org.apache.kafka.clients.NetworkClient [kafka-coordinator-heartbeat-thread | anonymous.8760d60c-4732-4591-ac45-10306e190685] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:00,880 INFO org.apache.kafka.clients.FetchSessionHandler [kafka-coordinator-heartbeat-thread | anonymous.8760d60c-4732-4591-ac45-10306e190685] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:01,390 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:01,390 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:03,978 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:04,555 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:06,950 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:06,950 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:07,652 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:07,652 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:10,221 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:10,596 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:13,421 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:13,857 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:16,646 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:16,646 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:17,006 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:17,006 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:19,743 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:19,915 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:22,767 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:22,768 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:22,952 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:25,991 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:25,992 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:26,176 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:26,177 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:28,502 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:00:29,187 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:29,187 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:32,147 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:32,147 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:32,334 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:32,335 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:35,248 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:35,560 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:38,423 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:38,657 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:41,521 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:41,522 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:41,814 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:41,814 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:44,617 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:44,726 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:47,685 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:47,686 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:47,839 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:47,840 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:50,693 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:50,724 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:53,681 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:53,853 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:56,593 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:56,593 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:56,763 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:56,764 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:00:59,672 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:00:59,875 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:02,955 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:02,955 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:01:03,155 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:06,034 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:06,034 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Error sending fetch request (sessionId=5038548, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:01:06,173 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:06,173 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Error sending fetch request (sessionId=1438995811, epoch=INITIAL) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:01:09,057 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165-4, groupId=anonymous.593d58ed-1d64-4857-b68b-c83ddbbb9165] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:01:09,384 WARN org.apache.kafka.clients.NetworkClient [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.8760d60c-4732-4591-ac45-10306e190685-2, groupId=anonymous.8760d60c-4732-4591-ac45-10306e190685] Connection to node 0 (DESKTOP-UP4G20T/192.168.1.3:9092) could not be established. Broker may not be available.
2022-05-07 20:15:37,736 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 1928 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 20:15:37,738 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 20:15:37,739 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 20:15:37,770 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 20:15:37,770 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 20:15:37,771 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 20:15:37,771 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 20:15:38,304 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 20:15:38,411 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 102 ms. Found 5 MongoDB repository interfaces.
2022-05-07 20:15:38,571 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 20:15:38,581 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 20:15:38,655 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 20:15:38,708 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 20:15:38,767 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 20:15:39,220 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 20:15:39,230 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 20:15:39,231 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 20:15:39,231 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 20:15:39,349 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 20:15:39,349 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1577 ms
2022-05-07 20:15:39,452 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 20:15:39,538 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276861300d1644b5858913e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:2}] to localhost:27017
2022-05-07 20:15:39,538 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276861300d1644b5858913e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:1}] to localhost:27017
2022-05-07 20:15:39,539 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276861300d1644b5858913e', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=51060700}
2022-05-07 20:15:39,546 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 20:15:39,594 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 20:15:39,633 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 20:15:40,226 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 20:15:40,356 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 20:15:40,372 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 20:15:40,463 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 20:15:40,464 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 20:15:40,466 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 20:15:40,466 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 20:15:40,467 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 20:15:40,475 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 20:15:40,561 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 20:15:40,568 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 20:15:40,606 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 20:15:40,780 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 20:15:40,788 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 20:15:40,796 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 20:15:40,814 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651934740813 with initial instances count: 5
2022-05-07 20:15:40,815 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 20:15:40,815 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651934740815, current=UP, previous=STARTING]
2022-05-07 20:15:40,817 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 20:15:40,817 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 20:15:40,853 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 20:15:40,879 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 20:15:40,880 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 20:15:40,880 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 20:15:40,923 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 20:15:40,923 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 20:15:40,923 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 20:15:40,938 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 20:15:40,938 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 20:15:40,938 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 20:15:40,962 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 20:15:40,963 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 20:15:40,963 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 20:15:41,019 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 20:15:41,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,116 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741115
2022-05-07 20:15:41,556 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 20:15:41,559 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 20:15:41,559 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 20:15:41,559 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 20:15:41,572 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 20:15:41,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,611 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741611
2022-05-07 20:15:41,620 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-1, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 20:15:41,621 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-1, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 20:15:41,621 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-1, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 20:15:41,622 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 20:15:41,622 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 20:15:41,622 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 20:15:41,623 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-1 unregistered
2022-05-07 20:15:41,650 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c.errors' has 1 subscriber(s).
2022-05-07 20:15:41,650 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c.errors' has 0 subscriber(s).
2022-05-07 20:15:41,651 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c.errors' has 1 subscriber(s).
2022-05-07 20:15:41,651 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c.errors' has 2 subscriber(s).
2022-05-07 20:15:41,674 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 20:15:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741680
2022-05-07 20:15:41,681 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 20:15:41,685 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@196f6957
2022-05-07 20:15:41,686 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 20:15:41,687 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 20:15:41,688 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 20:15:41,688 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 20:15:41,688 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 20:15:41,691 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 20:15:41,696 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,696 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,696 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741696
2022-05-07 20:15:41,699 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 20:15:41,699 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 20:15:41,717 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 20:15:41,718 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 20:15:41,719 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 20:15:41,719 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 20:15:41,721 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 20:15:41,726 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,727 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,727 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741726
2022-05-07 20:15:41,732 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-3, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 20:15:41,734 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-3, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 20:15:41,734 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-3, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 20:15:41,734 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 20:15:41,734 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 20:15:41,734 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 20:15:41,736 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-3 unregistered
2022-05-07 20:15:41,737 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b.errors' has 1 subscriber(s).
2022-05-07 20:15:41,737 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b.errors' has 0 subscriber(s).
2022-05-07 20:15:41,737 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b.errors' has 1 subscriber(s).
2022-05-07 20:15:41,737 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b.errors' has 2 subscriber(s).
2022-05-07 20:15:41,738 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 20:15:41,743 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 20:15:41,743 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 20:15:41,743 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651934741743
2022-05-07 20:15:41,743 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 20:15:41,744 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1b1bede4
2022-05-07 20:15:41,745 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 20:15:41,752 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 20:15:41,753 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 20:15:41,757 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 20:15:41,758 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 20:15:41,766 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:15:41,766 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:15:41,768 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 20:15:41,768 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] (Re-)joining group
2022-05-07 20:15:41,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Request joining group due to: need to re-join with the given member-id
2022-05-07 20:15:41,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: need to re-join with the given member-id
2022-05-07 20:15:41,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 20:15:41,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] (Re-)joining group
2022-05-07 20:15:41,851 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.09 seconds (JVM running for 5.611)
2022-05-07 20:15:41,861 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-01ef4c88-ba7b-4924-80dd-b43b7a2fb027', protocol='range'}
2022-05-07 20:15:41,862 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Finished assignment for group at generation 1: {consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-01ef4c88-ba7b-4924-80dd-b43b7a2fb027=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 20:15:41,867 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-d6de97ce-c22a-4d22-b5de-22e7ef286aab', protocol='range'}
2022-05-07 20:15:41,867 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Finished assignment for group at generation 1: {consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-d6de97ce-c22a-4d22-b5de-22e7ef286aab=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 20:15:41,969 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-d6de97ce-c22a-4d22-b5de-22e7ef286aab', protocol='range'}
2022-05-07 20:15:41,969 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-01ef4c88-ba7b-4924-80dd-b43b7a2fb027', protocol='range'}
2022-05-07 20:15:41,970 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 20:15:41,970 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 20:15:41,974 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 20:15:41,974 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 20:15:42,001 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 20:15:42,001 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 20:15:42,007 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 20:15:42,007 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 20:15:42,069 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 20:15:42,069 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 20:15:42,120 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 20:15:42,120 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 20:18:34,556 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 20:18:34,585 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 20:18:35,647 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 20:18:35,648 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 20:18:37,652 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 20:18:37,652 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 20:18:37,661 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=30, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@76f8daa1, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651934914223, kafka_groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 20:18:37,680 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@30
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=30, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@76f8daa1, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651934914223, kafka_groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 20:20:40,626 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:25:40,630 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:27:23,731 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 20:27:23,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 20:27:23,975 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Error sending fetch request (sessionId=116998206, epoch=1244) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:27:23,922 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Error sending fetch request (sessionId=986658591, epoch=1239) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 20:27:25,439 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:27:25,448 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:27:25,449 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:27:25,459 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:27:25,485 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 20:27:25,628 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-01ef4c88-ba7b-4924-80dd-b43b7a2fb027', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 20:27:25,630 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 20:27:25,630 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 20:27:25,631 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 20:27:25,631 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 20:27:25,643 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 20:27:25,648 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 20:27:25,652 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 20:27:25,755 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: need to re-join with the given member-id
2022-05-07 20:27:25,756 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 20:27:25,767 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-508f0a43-b7e2-49c3-91c9-e35753afa38f', protocol='range'}
2022-05-07 20:27:25,770 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Finished assignment for group at generation 3: {consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-508f0a43-b7e2-49c3-91c9-e35753afa38f=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 20:27:25,912 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-508f0a43-b7e2-49c3-91c9-e35753afa38f', protocol='range'}
2022-05-07 20:27:25,913 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 20:27:25,914 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 20:27:25,922 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 20:27:25,924 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 20:31:44,474 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:36:44,490 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:41:44,493 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 20:46:44,503 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 21:09:03,637 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Error sending fetch request (sessionId=984483802, epoch=2449) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 21:09:03,639 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 21:09:03,636 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Error sending fetch request (sessionId=459153550, epoch=2449) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 21:09:03,674 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 21:09:03,755 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:09:03,766 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-508f0a43-b7e2-49c3-91c9-e35753afa38f', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 21:09:03,767 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:09:03,767 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:09:03,767 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 21:09:03,767 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 21:09:03,767 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:09:03,768 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:09:03,768 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 21:09:03,778 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:09:03,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:09:03,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-d6de97ce-c22a-4d22-b5de-22e7ef286aab', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 21:09:03,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 21:09:03,781 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:09:03,781 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:09:03,781 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 21:09:03,781 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Lost previously assigned partitions PRODUCT_TOPIC-0
2022-05-07 21:09:03,781 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b: partitions lost: [PRODUCT_TOPIC-0]
2022-05-07 21:09:03,781 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b: partitions revoked: [PRODUCT_TOPIC-0]
2022-05-07 21:09:03,781 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] (Re-)joining group
2022-05-07 21:09:03,784 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:09:03,784 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-e9941e6a-7dab-4ecc-8a10-6dbb4120c766', protocol='range'}
2022-05-07 21:09:03,784 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] (Re-)joining group
2022-05-07 21:09:03,784 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Finished assignment for group at generation 5: {consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-e9941e6a-7dab-4ecc-8a10-6dbb4120c766=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:09:03,787 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-0e6bf50b-6b79-4b46-aec9-bb8c4c55882d', protocol='range'}
2022-05-07 21:09:03,787 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-e9941e6a-7dab-4ecc-8a10-6dbb4120c766', protocol='range'}
2022-05-07 21:09:03,787 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Finished assignment for group at generation 3: {consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-0e6bf50b-6b79-4b46-aec9-bb8c4c55882d=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 21:09:03,787 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:09:03,788 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:09:03,790 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4-0e6bf50b-6b79-4b46-aec9-bb8c4c55882d', protocol='range'}
2022-05-07 21:09:03,790 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 21:09:03,790 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 21:09:03,791 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 21:09:03,800 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:09:03,802 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Setting offset for partition PRODUCT_TOPIC-0 to the committed offset FetchPosition{offset=31, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 21:09:03,802 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 21:10:55,096 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:10:55,096 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:10:55,101 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,101 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 21:10:55,102 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,103 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,104 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:10:55,113 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 21:10:55,114 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,114 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:10:55,208 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,224 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b-4, groupId=anonymous.db5a5d67-a4ad-4030-b4d8-e43f8db6c02b] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:10:55,909 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Attempt to heartbeat with Generation{generationId=5, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-e9941e6a-7dab-4ecc-8a10-6dbb4120c766', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 21:10:55,910 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:10:55,910 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:10:55,910 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 21:10:55,910 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 21:10:55,911 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:10:55,911 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:10:55,911 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 21:10:55,915 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:10:55,917 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] (Re-)joining group
2022-05-07 21:10:55,919 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully joined group with generation Generation{generationId=7, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-aef38adb-d102-4498-8395-375e237792ef', protocol='range'}
2022-05-07 21:10:55,919 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Finished assignment for group at generation 7: {consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-aef38adb-d102-4498-8395-375e237792ef=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:10:55,922 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Successfully synced group in generation Generation{generationId=7, memberId='consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2-aef38adb-d102-4498-8395-375e237792ef', protocol='range'}
2022-05-07 21:10:55,922 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:10:55,923 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:10:55,925 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c-2, groupId=anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 21:10:55,925 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.17b9adc8-7ff7-49aa-9a8f-e217f442554c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:14:17,870 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 21:14:17,876 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 24636 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 21:14:17,877 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 21:14:17,910 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 21:14:17,910 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 21:14:17,911 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 21:14:17,912 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 21:14:18,410 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 21:14:18,520 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 107 ms. Found 5 MongoDB repository interfaces.
2022-05-07 21:14:18,677 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 21:14:18,687 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 21:14:18,766 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 21:14:18,830 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:14:18,879 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:14:19,366 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 21:14:19,377 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 21:14:19,377 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 21:14:19,377 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 21:14:19,485 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 21:14:19,486 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1574 ms
2022-05-07 21:14:19,606 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 21:14:19,683 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627693d365b47c0d51dc05ef', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:19}] to localhost:27017
2022-05-07 21:14:19,683 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627693d365b47c0d51dc05ef', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:20}] to localhost:27017
2022-05-07 21:14:19,683 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627693d365b47c0d51dc05ef', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=25637600}
2022-05-07 21:14:19,775 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:14:19,853 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 21:14:19,913 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:14:20,538 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 21:14:20,664 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 21:14:20,678 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 21:14:20,774 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 21:14:20,774 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 21:14:20,778 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 21:14:20,778 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 21:14:20,778 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 21:14:20,784 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 21:14:20,883 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 21:14:20,889 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 21:14:20,919 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 21:14:20,920 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 21:14:21,122 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 21:14:21,130 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 21:14:21,136 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 21:14:21,151 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651938261150 with initial instances count: 6
2022-05-07 21:14:21,153 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 21:14:21,154 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651938261154, current=UP, previous=STARTING]
2022-05-07 21:14:21,155 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 21:14:21,156 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 21:14:21,185 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 21:14:21,217 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 21:14:21,217 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:14:21,218 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 21:14:21,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 21:14:21,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:14:21,263 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 21:14:21,278 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 21:14:21,278 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:14:21,278 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 21:14:21,299 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 21:14:21,299 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:14:21,299 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:14:21,348 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:14:21,434 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,434 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,434 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261433
2022-05-07 21:14:21,819 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 21:14:21,821 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 21:14:21,822 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:14:21,822 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 21:14:21,836 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:14:21,868 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,868 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,868 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261868
2022-05-07 21:14:21,875 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-1, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:14:21,877 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-1, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:14:21,877 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-1, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:14:21,878 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:14:21,878 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:14:21,878 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:14:21,879 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-1 unregistered
2022-05-07 21:14:21,900 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103.errors' has 1 subscriber(s).
2022-05-07 21:14:21,901 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103.errors' has 0 subscriber(s).
2022-05-07 21:14:21,901 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103.errors' has 1 subscriber(s).
2022-05-07 21:14:21,901 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103.errors' has 2 subscriber(s).
2022-05-07 21:14:21,922 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:14:21,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261927
2022-05-07 21:14:21,928 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 21:14:21,931 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@42156fe6
2022-05-07 21:14:21,933 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:14:21,933 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:14:21,933 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:14:21,933 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:14:21,933 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:14:21,934 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:14:21,937 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,937 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,937 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261937
2022-05-07 21:14:21,940 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 21:14:21,941 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:14:21,952 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 21:14:21,953 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:14:21,953 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 21:14:21,953 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:14:21,953 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 21:14:21,955 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:14:21,955 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] (Re-)joining group
2022-05-07 21:14:21,959 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,959 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,960 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261959
2022-05-07 21:14:21,963 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-3, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:14:21,964 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-3, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:14:21,964 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-3, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:14:21,964 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:14:21,964 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:14:21,964 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:14:21,965 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-3 unregistered
2022-05-07 21:14:21,967 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f.errors' has 1 subscriber(s).
2022-05-07 21:14:21,967 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f.errors' has 0 subscriber(s).
2022-05-07 21:14:21,967 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f.errors' has 1 subscriber(s).
2022-05-07 21:14:21,967 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f.errors' has 2 subscriber(s).
2022-05-07 21:14:21,968 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:14:21,974 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:14:21,974 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:14:21,974 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938261973
2022-05-07 21:14:21,974 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 21:14:21,975 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@7ed73321
2022-05-07 21:14:21,975 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 21:14:21,979 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 21:14:21,979 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:14:21,980 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:14:21,981 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] (Re-)joining group
2022-05-07 21:14:21,987 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 21:14:21,989 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 21:14:22,001 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:14:22,001 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:14:22,002 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] (Re-)joining group
2022-05-07 21:14:22,002 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] (Re-)joining group
2022-05-07 21:14:22,017 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2-2360c4f9-128e-4b07-8db2-72ca0ff84a9e', protocol='range'}
2022-05-07 21:14:22,018 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4-286d2cf1-305c-45eb-96a2-1ed4482be1b4', protocol='range'}
2022-05-07 21:14:22,020 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Finished assignment for group at generation 1: {consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4-286d2cf1-305c-45eb-96a2-1ed4482be1b4=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 21:14:22,020 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Finished assignment for group at generation 1: {consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2-2360c4f9-128e-4b07-8db2-72ca0ff84a9e=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:14:22,071 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4-286d2cf1-305c-45eb-96a2-1ed4482be1b4', protocol='range'}
2022-05-07 21:14:22,071 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2-2360c4f9-128e-4b07-8db2-72ca0ff84a9e', protocol='range'}
2022-05-07 21:14:22,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:14:22,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 21:14:22,075 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 21:14:22,075 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:14:22,080 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.252 seconds (JVM running for 5.792)
2022-05-07 21:14:22,085 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:14:22,085 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 21:14:22,089 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:14:22,089 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 21:14:22,109 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f-4, groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=31, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:14:22,109 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103-2, groupId=anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:14:22,125 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.44be23ed-a191-40c5-bef3-82c24e1a4103: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:14:22,125 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 21:14:32,936 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:14:32,943 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:14:33,971 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:14:33,972 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:14:35,980 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:14:35,980 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:14:35,985 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=31, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@2820ba13, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651938272818, kafka_groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 21:14:35,992 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@31
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=31, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@2820ba13, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651938272818, kafka_groupId=anonymous.5a93e55f-0c3e-4047-a076-bf1c98f2a24f}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 21:19:20,926 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 21:21:10,629 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 21:21:10,631 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 24280 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 21:21:10,631 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 21:21:10,664 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 21:21:10,665 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 21:21:10,666 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 21:21:10,666 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 21:21:11,134 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 21:21:11,237 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 98 ms. Found 5 MongoDB repository interfaces.
2022-05-07 21:21:11,392 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 21:21:11,400 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 21:21:11,476 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 21:21:11,525 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:21:11,570 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:21:11,977 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 21:21:11,985 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 21:21:11,986 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 21:21:11,986 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 21:21:12,075 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 21:21:12,077 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1410 ms
2022-05-07 21:21:12,177 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 21:21:12,227 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62769570102bde69948d9ac1', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:22}] to localhost:27017
2022-05-07 21:21:12,227 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='62769570102bde69948d9ac1', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:21}] to localhost:27017
2022-05-07 21:21:12,228 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62769570102bde69948d9ac1', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19745800}
2022-05-07 21:21:12,259 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:21:12,303 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 21:21:12,343 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:21:13,012 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 21:21:13,170 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 21:21:13,184 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 21:21:13,329 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 21:21:13,329 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 21:21:13,332 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 21:21:13,332 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 21:21:13,332 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 21:21:13,337 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 21:21:13,409 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 21:21:13,416 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 21:21:13,441 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 21:21:13,605 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 21:21:13,612 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 21:21:13,619 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 21:21:13,633 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651938673632 with initial instances count: 6
2022-05-07 21:21:13,634 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 21:21:13,634 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651938673634, current=UP, previous=STARTING]
2022-05-07 21:21:13,636 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 21:21:13,636 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 21:21:13,663 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 21:21:13,698 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 21:21:13,698 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:21:13,699 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 21:21:13,739 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 21:21:13,739 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:21:13,739 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 21:21:13,753 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 21:21:13,753 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:21:13,753 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 21:21:13,773 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 21:21:13,773 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:21:13,773 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:21:13,826 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:21:13,875 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:13,875 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:13,875 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938673873
2022-05-07 21:21:14,106 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 21:21:14,109 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 21:21:14,109 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:21:14,109 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 21:21:14,120 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:21:14,154 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:14,155 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:14,155 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938674154
2022-05-07 21:21:14,164 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-1, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:21:14,165 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-1, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:21:14,165 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-1, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:21:14,165 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:21:14,165 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:21:14,165 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:21:14,167 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-1 unregistered
2022-05-07 21:21:14,183 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c.errors' has 1 subscriber(s).
2022-05-07 21:21:14,184 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c.errors' has 0 subscriber(s).
2022-05-07 21:21:14,184 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c.errors' has 1 subscriber(s).
2022-05-07 21:21:14,184 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c.errors' has 2 subscriber(s).
2022-05-07 21:21:14,200 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:21:14,206 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:14,206 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:14,206 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938674206
2022-05-07 21:21:14,207 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 21:21:14,210 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@537d6593
2022-05-07 21:21:14,212 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:21:14,212 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:21:14,212 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:21:14,213 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:21:14,213 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:21:14,214 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:21:14,217 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:14,218 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:14,219 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938674217
2022-05-07 21:21:14,219 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 21:21:14,220 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:21:14,220 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:21:14,222 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] (Re-)joining group
2022-05-07 21:21:14,233 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 21:21:14,235 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 21:21:14,235 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:21:14,235 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 21:21:14,236 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:21:14,239 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:21:14,240 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] (Re-)joining group
2022-05-07 21:21:14,242 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:14,243 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:14,243 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938674242
2022-05-07 21:21:14,246 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2-eca4bcc4-76be-44bd-b1f4-dcf7fbb49e8a', protocol='range'}
2022-05-07 21:21:14,248 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-3, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:21:14,248 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Finished assignment for group at generation 1: {consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2-eca4bcc4-76be-44bd-b1f4-dcf7fbb49e8a=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:21:14,249 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-3, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:21:14,250 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-3, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:21:14,250 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:21:14,250 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:21:14,250 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:21:14,251 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-3 unregistered
2022-05-07 21:21:14,253 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c.errors' has 1 subscriber(s).
2022-05-07 21:21:14,254 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c.errors' has 0 subscriber(s).
2022-05-07 21:21:14,254 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c.errors' has 1 subscriber(s).
2022-05-07 21:21:14,254 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCT_TOPIC.anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c.errors' has 2 subscriber(s).
2022-05-07 21:21:14,255 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:21:14,259 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2-eca4bcc4-76be-44bd-b1f4-dcf7fbb49e8a', protocol='range'}
2022-05-07 21:21:14,259 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:21:14,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:21:14,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:21:14,260 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651938674260
2022-05-07 21:21:14,260 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Subscribed to topic(s): PRODUCT_TOPIC
2022-05-07 21:21:14,261 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@2e748b09
2022-05-07 21:21:14,261 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 21:21:14,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:21:14,264 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Resetting the last seen epoch of partition PRODUCT_TOPIC-0 to 0 since the associated topicId changed from null to 8pJDXN2yT12qC7Hxtze1RQ
2022-05-07 21:21:14,265 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:21:14,265 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:21:14,265 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] (Re-)joining group
2022-05-07 21:21:14,267 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:21:14,270 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:21:14,270 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] (Re-)joining group
2022-05-07 21:21:14,270 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:21:14,273 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4-b8071c31-ceaa-4e8f-a8d2-56fd74cbf0a5', protocol='range'}
2022-05-07 21:21:14,273 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Finished assignment for group at generation 1: {consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4-b8071c31-ceaa-4e8f-a8d2-56fd74cbf0a5=Assignment(partitions=[PRODUCT_TOPIC-0])}
2022-05-07 21:21:14,274 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 21:21:14,275 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 21:21:14,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4-b8071c31-ceaa-4e8f-a8d2-56fd74cbf0a5', protocol='range'}
2022-05-07 21:21:14,278 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Notifying assignor about the new Assignment(partitions=[PRODUCT_TOPIC-0])
2022-05-07 21:21:14,279 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Adding newly assigned partitions: PRODUCT_TOPIC-0
2022-05-07 21:21:14,280 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 21:21:14,281 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Found no committed offset for partition PRODUCT_TOPIC-0
2022-05-07 21:21:14,284 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c-2, groupId=anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:21:14,286 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c-4, groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c] Resetting offset for partition PRODUCT_TOPIC-0 to position FetchPosition{offset=32, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:21:14,290 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c: partitions assigned: [PRODUCT_TOPIC-0]
2022-05-07 21:21:14,290 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.bed39cf2-c72b-4f85-920d-e2d9ab67a86c: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:21:14,361 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.748 seconds (JVM running for 5.271)
2022-05-07 21:21:29,840 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:21:29,851 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:21:30,873 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:21:30,874 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:21:32,879 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:21:32,880 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:21:32,885 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=32, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@23719727, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651938689741, kafka_groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 21:21:32,894 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCT_TOPIC', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCT_TOPIC-0@32
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=32, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@23719727, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCT_TOPIC, kafka_receivedTimestamp=1651938689741, kafka_groupId=anonymous.e2794f5c-fafb-4e16-9b6c-660929a9df0c}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 21:26:13,455 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 21:28:04,372 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 21:28:04,376 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 11708 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 21:28:04,376 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 21:28:04,409 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 21:28:04,409 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 21:28:04,410 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 21:28:04,411 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 21:28:04,884 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 21:28:04,979 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 90 ms. Found 5 MongoDB repository interfaces.
2022-05-07 21:28:05,141 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 21:28:05,148 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 21:28:05,224 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 21:28:05,274 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:28:05,312 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:28:05,695 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 21:28:05,702 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 21:28:05,703 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 21:28:05,703 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 21:28:05,788 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 21:28:05,788 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1377 ms
2022-05-07 21:28:05,891 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 21:28:05,938 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276970dcaba55106ebbca1a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:24}] to localhost:27017
2022-05-07 21:28:05,938 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276970dcaba55106ebbca1a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:23}] to localhost:27017
2022-05-07 21:28:05,938 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276970dcaba55106ebbca1a', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17233600}
2022-05-07 21:28:05,966 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:28:06,020 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 21:28:06,061 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:28:06,636 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 21:28:06,765 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 21:28:06,778 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 21:28:06,867 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 21:28:06,868 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 21:28:06,871 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 21:28:06,871 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 21:28:06,871 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 21:28:06,879 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 21:28:06,951 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 21:28:06,955 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 21:28:06,981 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 21:28:06,982 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 21:28:06,983 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 21:28:06,983 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 21:28:06,983 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 21:28:06,983 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 21:28:06,983 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 21:28:07,144 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 21:28:07,151 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 21:28:07,158 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 21:28:07,172 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651939087171 with initial instances count: 6
2022-05-07 21:28:07,181 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 21:28:07,181 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651939087181, current=UP, previous=STARTING]
2022-05-07 21:28:07,182 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 21:28:07,183 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 21:28:07,214 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 21:28:07,235 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 21:28:07,237 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:28:07,237 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 21:28:07,282 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 21:28:07,282 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:28:07,282 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 21:28:07,298 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 21:28:07,298 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:28:07,299 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 21:28:07,319 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 21:28:07,320 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:28:07,320 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:28:07,368 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:28:07,423 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,423 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,424 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087422
2022-05-07 21:28:07,663 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 21:28:07,667 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 21:28:07,667 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:28:07,667 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 21:28:07,678 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.0f48de49-a065-4dfb-90fa-090622256c12
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:28:07,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087715
2022-05-07 21:28:07,723 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-1, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:28:07,724 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-1, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:28:07,725 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-1, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:28:07,725 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:28:07,725 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:28:07,725 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:28:07,726 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-1 unregistered
2022-05-07 21:28:07,745 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.0f48de49-a065-4dfb-90fa-090622256c12.errors' has 1 subscriber(s).
2022-05-07 21:28:07,746 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.0f48de49-a065-4dfb-90fa-090622256c12.errors' has 0 subscriber(s).
2022-05-07 21:28:07,746 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.0f48de49-a065-4dfb-90fa-090622256c12.errors' has 1 subscriber(s).
2022-05-07 21:28:07,746 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.0f48de49-a065-4dfb-90fa-090622256c12.errors' has 2 subscriber(s).
2022-05-07 21:28:07,761 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.0f48de49-a065-4dfb-90fa-090622256c12
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:28:07,765 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,766 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,766 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087765
2022-05-07 21:28:07,767 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 21:28:07,770 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@561266c3
2022-05-07 21:28:07,771 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:28:07,771 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:28:07,771 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:28:07,772 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:28:07,772 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:28:07,773 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:28:07,777 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 21:28:07,777 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,777 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,777 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:28:07,778 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087777
2022-05-07 21:28:07,779 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:28:07,781 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] (Re-)joining group
2022-05-07 21:28:07,791 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 21:28:07,792 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 21:28:07,793 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:28:07,793 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 21:28:07,794 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:28:07,796 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:28:07,796 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] (Re-)joining group
2022-05-07 21:28:07,798 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,798 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,798 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087798
2022-05-07 21:28:07,801 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-3, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:28:07,802 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2-9d12a877-7c12-41f4-ba5b-bdca7891f1d3', protocol='range'}
2022-05-07 21:28:07,803 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-3, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:28:07,803 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-3, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:28:07,803 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:28:07,803 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:28:07,803 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:28:07,804 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Finished assignment for group at generation 1: {consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2-9d12a877-7c12-41f4-ba5b-bdca7891f1d3=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:28:07,804 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-3 unregistered
2022-05-07 21:28:07,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d.errors' has 1 subscriber(s).
2022-05-07 21:28:07,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d.errors' has 0 subscriber(s).
2022-05-07 21:28:07,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d.errors' has 1 subscriber(s).
2022-05-07 21:28:07,805 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d.errors' has 2 subscriber(s).
2022-05-07 21:28:07,806 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:28:07,811 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:28:07,811 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:28:07,811 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939087811
2022-05-07 21:28:07,812 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Subscribed to topic(s): PRODUCTS_ON_AUCTION
2022-05-07 21:28:07,814 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@41da829b
2022-05-07 21:28:07,814 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 21:28:07,814 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2-9d12a877-7c12-41f4-ba5b-bdca7891f1d3', protocol='range'}
2022-05-07 21:28:07,815 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:28:07,817 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Resetting the last seen epoch of partition PRODUCTS_ON_AUCTION-0 to 0 since the associated topicId changed from null to dpooxllMSyGxqYtu52bpZg
2022-05-07 21:28:07,817 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:28:07,818 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:28:07,818 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:28:07,819 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] (Re-)joining group
2022-05-07 21:28:07,823 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:28:07,823 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:28:07,824 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] (Re-)joining group
2022-05-07 21:28:07,825 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4-5a45be6b-cc25-4a52-ac0b-43445e080213', protocol='range'}
2022-05-07 21:28:07,825 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Finished assignment for group at generation 1: {consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4-5a45be6b-cc25-4a52-ac0b-43445e080213=Assignment(partitions=[PRODUCTS_ON_AUCTION-0])}
2022-05-07 21:28:07,827 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 21:28:07,828 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 21:28:07,828 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:28:07,829 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4-5a45be6b-cc25-4a52-ac0b-43445e080213', protocol='range'}
2022-05-07 21:28:07,829 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Notifying assignor about the new Assignment(partitions=[PRODUCTS_ON_AUCTION-0])
2022-05-07 21:28:07,829 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Adding newly assigned partitions: PRODUCTS_ON_AUCTION-0
2022-05-07 21:28:07,831 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:28:07,832 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:28:07,838 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.0f48de49-a065-4dfb-90fa-090622256c12-2, groupId=anonymous.0f48de49-a065-4dfb-90fa-090622256c12] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:28:07,838 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d-4, groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d] Resetting offset for partition PRODUCTS_ON_AUCTION-0 to position FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:28:07,845 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d: partitions assigned: [PRODUCTS_ON_AUCTION-0]
2022-05-07 21:28:07,845 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.0f48de49-a065-4dfb-90fa-090622256c12: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:28:07,914 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.445 seconds (JVM running for 4.901)
2022-05-07 21:28:21,000 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:28:21,005 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:28:22,019 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:28:22,020 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:28:24,029 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:28:24,031 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommandForListing [productId=null, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:28:24,034 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=12, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@7c04f24c, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCTS_ON_AUCTION, kafka_receivedTimestamp=1651939100909, kafka_groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 21:28:24,040 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCTS_ON_AUCTION-0@12
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=12, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@7c04f24c, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCTS_ON_AUCTION, kafka_receivedTimestamp=1651939100909, kafka_groupId=anonymous.5bb29616-c3b8-421c-a0a3-9343600f691d}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 21:33:06,998 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 21:35:37,846 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 21:35:37,849 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 10880 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 21:35:37,849 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 21:35:37,882 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 21:35:37,882 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 21:35:37,883 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 21:35:37,883 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 21:35:38,356 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 21:35:38,461 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 101 ms. Found 5 MongoDB repository interfaces.
2022-05-07 21:35:38,615 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 21:35:38,623 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 21:35:38,697 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 21:35:38,750 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:35:38,798 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:35:39,266 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 21:35:39,277 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 21:35:39,277 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 21:35:39,277 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 21:35:39,383 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 21:35:39,383 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1499 ms
2022-05-07 21:35:39,491 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 21:35:39,553 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627698d31d2bc94813ad9417', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:25}] to localhost:27017
2022-05-07 21:35:39,553 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627698d31d2bc94813ad9417', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:26}] to localhost:27017
2022-05-07 21:35:39,555 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627698d31d2bc94813ad9417', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19203700}
2022-05-07 21:35:39,589 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:35:39,634 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 21:35:39,672 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:35:40,266 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 21:35:40,391 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 21:35:40,406 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 21:35:40,492 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 21:35:40,493 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 21:35:40,495 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 21:35:40,495 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 21:35:40,496 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 21:35:40,500 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 21:35:40,593 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 21:35:40,598 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 21:35:40,630 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 21:35:40,856 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 21:35:40,863 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 21:35:40,870 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 21:35:40,885 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651939540884 with initial instances count: 6
2022-05-07 21:35:40,886 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 21:35:40,886 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651939540886, current=UP, previous=STARTING]
2022-05-07 21:35:40,887 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 21:35:40,888 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 21:35:40,917 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 21:35:40,954 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 21:35:40,954 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:35:40,954 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 21:35:40,993 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 21:35:40,993 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:35:40,994 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 21:35:41,007 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 21:35:41,008 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:35:41,008 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 21:35:41,026 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 21:35:41,027 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:35:41,027 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:35:41,074 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:35:41,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,163 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541162
2022-05-07 21:35:41,569 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 21:35:41,573 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 21:35:41,573 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:35:41,573 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 21:35:41,585 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:35:41,620 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,620 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,620 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541620
2022-05-07 21:35:41,628 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-1, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:35:41,629 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-1, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:35:41,629 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-1, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:35:41,629 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:35:41,629 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:35:41,629 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:35:41,631 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-1 unregistered
2022-05-07 21:35:41,656 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea.errors' has 1 subscriber(s).
2022-05-07 21:35:41,656 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea.errors' has 0 subscriber(s).
2022-05-07 21:35:41,656 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea.errors' has 1 subscriber(s).
2022-05-07 21:35:41,656 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea.errors' has 2 subscriber(s).
2022-05-07 21:35:41,674 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:35:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,680 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541680
2022-05-07 21:35:41,681 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 21:35:41,687 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@9ceebf3
2022-05-07 21:35:41,688 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:35:41,689 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:35:41,689 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:35:41,689 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:35:41,689 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:35:41,690 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:35:41,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,693 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541693
2022-05-07 21:35:41,695 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 21:35:41,695 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:35:41,695 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:35:41,697 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] (Re-)joining group
2022-05-07 21:35:41,707 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 21:35:41,708 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 21:35:41,708 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:35:41,708 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 21:35:41,709 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:35:41,711 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:35:41,711 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] (Re-)joining group
2022-05-07 21:35:41,714 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2-c856f82b-b6f6-4326-bad7-1cf3e3a6fe57', protocol='range'}
2022-05-07 21:35:41,714 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,715 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541714
2022-05-07 21:35:41,716 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Finished assignment for group at generation 1: {consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2-c856f82b-b6f6-4326-bad7-1cf3e3a6fe57=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:35:41,719 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-3, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:35:41,719 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-3, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:35:41,720 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-3, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:35:41,720 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:35:41,720 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:35:41,720 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:35:41,721 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-3 unregistered
2022-05-07 21:35:41,722 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8.errors' has 1 subscriber(s).
2022-05-07 21:35:41,723 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8.errors' has 0 subscriber(s).
2022-05-07 21:35:41,723 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8.errors' has 1 subscriber(s).
2022-05-07 21:35:41,723 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8.errors' has 2 subscriber(s).
2022-05-07 21:35:41,723 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2-c856f82b-b6f6-4326-bad7-1cf3e3a6fe57', protocol='range'}
2022-05-07 21:35:41,723 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:35:41,724 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:35:41,725 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:35:41,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:35:41,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:35:41,728 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939541728
2022-05-07 21:35:41,728 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Subscribed to topic(s): PRODUCTS_ON_AUCTION
2022-05-07 21:35:41,729 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@678ed550
2022-05-07 21:35:41,729 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 21:35:41,729 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:35:41,733 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Resetting the last seen epoch of partition PRODUCTS_ON_AUCTION-0 to 0 since the associated topicId changed from null to dpooxllMSyGxqYtu52bpZg
2022-05-07 21:35:41,734 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:35:41,734 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:35:41,735 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:35:41,735 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] (Re-)joining group
2022-05-07 21:35:41,739 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:35:41,739 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] (Re-)joining group
2022-05-07 21:35:41,742 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4-7f0196d4-addd-4076-bef0-781408273bdf', protocol='range'}
2022-05-07 21:35:41,742 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Finished assignment for group at generation 1: {consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4-7f0196d4-addd-4076-bef0-781408273bdf=Assignment(partitions=[PRODUCTS_ON_AUCTION-0])}
2022-05-07 21:35:41,743 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 21:35:41,744 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea-2, groupId=anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:35:41,745 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 21:35:41,745 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4-7f0196d4-addd-4076-bef0-781408273bdf', protocol='range'}
2022-05-07 21:35:41,745 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Notifying assignor about the new Assignment(partitions=[PRODUCTS_ON_AUCTION-0])
2022-05-07 21:35:41,745 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Adding newly assigned partitions: PRODUCTS_ON_AUCTION-0
2022-05-07 21:35:41,746 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:35:41,748 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:35:41,749 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.cc9a49f2-babc-4684-aad8-9fcbec738aea: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:35:41,752 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8-4, groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8] Resetting offset for partition PRODUCTS_ON_AUCTION-0 to position FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:35:41,756 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8: partitions assigned: [PRODUCTS_ON_AUCTION-0]
2022-05-07 21:35:41,824 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.988 seconds (JVM running for 5.481)
2022-05-07 21:35:50,053 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:35:50,061 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommand [productId=41, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:35:51,075 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:35:51,075 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommand [productId=41, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:35:53,080 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:35:53,081 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommand [productId=41, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:35:53,084 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=13, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@dd7d392, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCTS_ON_AUCTION, kafka_receivedTimestamp=1651939550017, kafka_groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8}]
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 more

2022-05-07 21:35:53,090 ERROR org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Backoff none exhausted for PRODUCTS_ON_AUCTION-0@13
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener failed; nested exception is org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!, failedMessage=GenericMessage [payload=byte[264], headers={kafka_offset=13, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@dd7d392, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=PRODUCTS_ON_AUCTION, kafka_receivedTimestamp=1651939550017, kafka_groupId=anonymous.5e0d6be7-77d9-4e42-aa27-fa121218b6c8}]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2691)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2657)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2617)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2544)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2429)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2307)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1981)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1365)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1356)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1251)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:832)
Caused by: org.springframework.messaging.MessagingException: Exception thrown while invoking EauctionHouseListingServiceApplication#consumeProductEvents[1 args]; nested exception is org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:64)
	at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:136)
	at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:56)
	at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:115)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:133)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:106)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:72)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:317)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:272)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:216)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:397)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:83)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:454)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:428)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:125)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:329)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:255)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:119)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:42)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2637)
	... 11 common frames omitted
Caused by: org.springframework.data.mapping.MappingException: No id property found for object of type class com.cts.eauction.microservices.listing.product.model.ProductCommand!
	at org.springframework.data.mongodb.core.EntityOperations$MappedEntity.getByIdQuery(EntityOperations.java:558)
	at org.springframework.data.mongodb.core.EntityOperations$Entity.getRemoveByQuery(EntityOperations.java:268)
	at org.springframework.data.mongodb.core.MongoTemplate.remove(MongoTemplate.java:1714)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.delete(SimpleMongoRepository.java:199)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:639)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy97.delete(Unknown Source)
	at com.cts.eauction.microservices.listing.product.repository.ProductAggregate.handleProductRemoval(ProductAggregate.java:30)
	at com.cts.eauction.microservices.listing.product.service.ProductService.handleProductRemoval(ProductService.java:33)
	at com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication.consumeProductEvents(EauctionHouseListingServiceApplication.java:63)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:64)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119)
	at org.springframework.cloud.stream.binding.StreamListenerMessageHandler.handleRequestMessage(StreamListenerMessageHandler.java:55)
	... 34 common frames omitted
2022-05-07 21:39:10,675 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 21:39:10,679 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 13948 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 21:39:10,679 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 21:39:10,710 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 21:39:10,711 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 21:39:10,712 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 21:39:10,712 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 21:39:11,168 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 21:39:11,258 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 87 ms. Found 5 MongoDB repository interfaces.
2022-05-07 21:39:11,413 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 21:39:11,421 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 21:39:11,497 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 21:39:11,543 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:39:11,582 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 21:39:11,946 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 21:39:11,953 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 21:39:11,954 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 21:39:11,954 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 21:39:12,049 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 21:39:12,049 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1337 ms
2022-05-07 21:39:12,144 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 21:39:12,198 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627699a8f8d1432b5a5faaed', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:27}] to localhost:27017
2022-05-07 21:39:12,198 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='627699a8f8d1432b5a5faaed', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:28}] to localhost:27017
2022-05-07 21:39:12,198 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='627699a8f8d1432b5a5faaed', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19205900}
2022-05-07 21:39:12,222 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:39:12,267 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 21:39:12,307 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 21:39:12,852 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 21:39:12,969 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 21:39:12,985 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 21:39:13,067 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 21:39:13,068 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 21:39:13,070 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 21:39:13,070 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 21:39:13,070 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 21:39:13,076 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 21:39:13,143 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 21:39:13,147 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 21:39:13,180 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 21:39:13,182 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 21:39:13,333 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 21:39:13,341 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 21:39:13,346 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 21:39:13,361 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651939753360 with initial instances count: 6
2022-05-07 21:39:13,362 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 21:39:13,362 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651939753362, current=UP, previous=STARTING]
2022-05-07 21:39:13,363 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 21:39:13,364 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 21:39:13,396 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 21:39:13,417 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 21:39:13,417 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:39:13,417 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 21:39:13,453 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 21:39:13,453 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:39:13,453 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 21:39:13,469 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 21:39:13,469 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:39:13,469 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 21:39:13,500 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 21:39:13,500 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:39:13,500 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:39:13,545 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:39:13,598 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,598 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,598 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753597
2022-05-07 21:39:13,824 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 21:39:13,827 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 21:39:13,827 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:39:13,828 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 21:39:13,836 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.def5526b-974d-4baf-8300-0c7e07959681
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:39:13,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,866 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753866
2022-05-07 21:39:13,873 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-1, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:39:13,873 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-1, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:39:13,875 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-1, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:39:13,875 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:39:13,875 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:39:13,875 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:39:13,876 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-1 unregistered
2022-05-07 21:39:13,897 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.def5526b-974d-4baf-8300-0c7e07959681.errors' has 1 subscriber(s).
2022-05-07 21:39:13,897 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.def5526b-974d-4baf-8300-0c7e07959681.errors' has 0 subscriber(s).
2022-05-07 21:39:13,897 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.def5526b-974d-4baf-8300-0c7e07959681.errors' has 1 subscriber(s).
2022-05-07 21:39:13,897 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.def5526b-974d-4baf-8300-0c7e07959681.errors' has 2 subscriber(s).
2022-05-07 21:39:13,912 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.def5526b-974d-4baf-8300-0c7e07959681
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:39:13,916 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,917 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,917 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753916
2022-05-07 21:39:13,917 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 21:39:13,920 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@767ea0a6
2022-05-07 21:39:13,922 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 21:39:13,922 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:39:13,922 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 21:39:13,922 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 21:39:13,922 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 21:39:13,923 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 21:39:13,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,927 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753927
2022-05-07 21:39:13,927 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 21:39:13,928 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:39:13,928 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:39:13,930 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 21:39:13,938 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 21:39:13,939 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 21:39:13,939 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:39:13,939 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 21:39:13,939 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:39:13,939 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 21:39:13,940 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:39:13,942 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-72b2d765-6c0d-4803-a12f-178ce943a5c8', protocol='range'}
2022-05-07 21:39:13,944 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Finished assignment for group at generation 1: {consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-72b2d765-6c0d-4803-a12f-178ce943a5c8=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:39:13,945 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,945 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,945 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753945
2022-05-07 21:39:13,949 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-3, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:39:13,950 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-3, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 21:39:13,950 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-3, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 21:39:13,950 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 21:39:13,950 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 21:39:13,950 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 21:39:13,951 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-72b2d765-6c0d-4803-a12f-178ce943a5c8', protocol='range'}
2022-05-07 21:39:13,951 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-3 unregistered
2022-05-07 21:39:13,951 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:39:13,953 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000.errors' has 1 subscriber(s).
2022-05-07 21:39:13,953 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:39:13,953 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000.errors' has 0 subscriber(s).
2022-05-07 21:39:13,953 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000.errors' has 1 subscriber(s).
2022-05-07 21:39:13,953 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000.errors' has 2 subscriber(s).
2022-05-07 21:39:13,955 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 21:39:13,957 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:39:13,959 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 21:39:13,959 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 21:39:13,960 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651939753959
2022-05-07 21:39:13,960 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Subscribed to topic(s): PRODUCTS_ON_AUCTION
2022-05-07 21:39:13,961 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 21:39:13,961 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@44677bd
2022-05-07 21:39:13,961 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 21:39:13,964 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Resetting the last seen epoch of partition PRODUCTS_ON_AUCTION-0 to 0 since the associated topicId changed from null to dpooxllMSyGxqYtu52bpZg
2022-05-07 21:39:13,964 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 21:39:13,964 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:39:13,966 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] (Re-)joining group
2022-05-07 21:39:13,969 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:39:13,969 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:39:13,969 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] (Re-)joining group
2022-05-07 21:39:13,972 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-e8737e65-4ddc-4f20-849b-de2df6637291', protocol='range'}
2022-05-07 21:39:13,972 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Finished assignment for group at generation 1: {consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-e8737e65-4ddc-4f20-849b-de2df6637291=Assignment(partitions=[PRODUCTS_ON_AUCTION-0])}
2022-05-07 21:39:13,973 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 21:39:13,974 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 21:39:13,975 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-e8737e65-4ddc-4f20-849b-de2df6637291', protocol='range'}
2022-05-07 21:39:13,975 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:39:13,975 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Notifying assignor about the new Assignment(partitions=[PRODUCTS_ON_AUCTION-0])
2022-05-07 21:39:13,975 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Adding newly assigned partitions: PRODUCTS_ON_AUCTION-0
2022-05-07 21:39:13,976 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:39:13,978 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 21:39:13,982 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Resetting offset for partition PRODUCTS_ON_AUCTION-0 to position FetchPosition{offset=14, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 21:39:13,985 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000: partitions assigned: [PRODUCTS_ON_AUCTION-0]
2022-05-07 21:39:14,062 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 4.279 seconds (JVM running for 4.72)
2022-05-07 21:39:20,570 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 21:39:20,582 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommand [productId=41, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 21:39:20,670 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:29}] to localhost:27017
2022-05-07 21:46:05,793 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.def5526b-974d-4baf-8300-0c7e07959681] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:46:05,799 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Error sending fetch request (sessionId=540911305, epoch=176) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 21:46:05,799 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Error sending fetch request (sessionId=145723548, epoch=176) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 21:46:05,793 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 21:46:06,027 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:46:07,118 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 21:46:07,123 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-72b2d765-6c0d-4803-a12f-178ce943a5c8', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 21:46:07,123 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:46:07,124 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 21:46:07,124 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 21:46:07,125 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 21:46:07,125 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:46:07,126 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 21:46:07,127 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 21:46:07,426 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: need to re-join with the given member-id
2022-05-07 21:46:07,428 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 21:46:07,442 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-b06e4019-3313-4ccf-9f6e-9eb82a442182', protocol='range'}
2022-05-07 21:46:07,442 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Finished assignment for group at generation 3: {consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-b06e4019-3313-4ccf-9f6e-9eb82a442182=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 21:46:07,695 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-b06e4019-3313-4ccf-9f6e-9eb82a442182', protocol='range'}
2022-05-07 21:46:07,695 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 21:46:07,696 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 21:46:07,704 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 21:46:07,704 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 22:44:53,213 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Error sending fetch request (sessionId=527403191, epoch=11) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 22:44:53,333 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Error sending fetch request (sessionId=978367583, epoch=9) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 22:44:53,338 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 22:44:53,352 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.def5526b-974d-4baf-8300-0c7e07959681] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 22:44:53,861 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:44:53,862 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:44:53,865 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:44:53,865 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:44:55,224 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Attempt to heartbeat with Generation{generationId=1, memberId='consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-e8737e65-4ddc-4f20-849b-de2df6637291', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 22:44:55,224 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 22:44:55,225 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 22:44:55,225 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 22:44:55,225 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Lost previously assigned partitions PRODUCTS_ON_AUCTION-0
2022-05-07 22:44:55,225 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000: partitions lost: [PRODUCTS_ON_AUCTION-0]
2022-05-07 22:44:55,225 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000: partitions revoked: [PRODUCTS_ON_AUCTION-0]
2022-05-07 22:44:55,226 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] (Re-)joining group
2022-05-07 22:44:55,230 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Request joining group due to: need to re-join with the given member-id
2022-05-07 22:44:55,231 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] (Re-)joining group
2022-05-07 22:44:55,246 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Successfully joined group with generation Generation{generationId=3, memberId='consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-4c6858d0-ae4d-4702-8c96-8e306b1e2942', protocol='range'}
2022-05-07 22:44:55,246 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Finished assignment for group at generation 3: {consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-4c6858d0-ae4d-4702-8c96-8e306b1e2942=Assignment(partitions=[PRODUCTS_ON_AUCTION-0])}
2022-05-07 22:44:55,256 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Successfully synced group in generation Generation{generationId=3, memberId='consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4-4c6858d0-ae4d-4702-8c96-8e306b1e2942', protocol='range'}
2022-05-07 22:44:55,257 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Notifying assignor about the new Assignment(partitions=[PRODUCTS_ON_AUCTION-0])
2022-05-07 22:44:55,257 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Adding newly assigned partitions: PRODUCTS_ON_AUCTION-0
2022-05-07 22:44:55,260 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Setting offset for partition PRODUCTS_ON_AUCTION-0 to the committed offset FetchPosition{offset=15, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 22:44:55,261 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000: partitions assigned: [PRODUCTS_ON_AUCTION-0]
2022-05-07 22:45:53,818 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Error sending fetch request (sessionId=158403759, epoch=7) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 22:45:53,819 INFO org.apache.kafka.clients.FetchSessionHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Error sending fetch request (sessionId=1841259133, epoch=6) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-05-07 22:45:53,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
2022-05-07 22:45:53,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | anonymous.def5526b-974d-4baf-8300-0c7e07959681] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-05-07 22:45:53,936 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:45:54,003 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000-4, groupId=anonymous.a1c15ed8-2b9a-469e-9bb9-2361dce18000] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:45:54,335 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Attempt to heartbeat with Generation{generationId=3, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-b06e4019-3313-4ccf-9f6e-9eb82a442182', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-05-07 22:45:54,335 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 22:45:54,336 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-05-07 22:45:54,336 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-05-07 22:45:54,336 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Lost previously assigned partitions BIDS_PLACED_BY_BUYER-0
2022-05-07 22:45:54,336 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions lost: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 22:45:54,337 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions revoked: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 22:45:54,337 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 22:45:54,347 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Request joining group due to: need to re-join with the given member-id
2022-05-07 22:45:54,348 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] (Re-)joining group
2022-05-07 22:45:54,352 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully joined group with generation Generation{generationId=5, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-7c843dc9-8ff3-4eda-8bed-066aa5bd56dc', protocol='range'}
2022-05-07 22:45:54,353 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Finished assignment for group at generation 5: {consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-7c843dc9-8ff3-4eda-8bed-066aa5bd56dc=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 22:45:54,387 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Successfully synced group in generation Generation{generationId=5, memberId='consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2-7c843dc9-8ff3-4eda-8bed-066aa5bd56dc', protocol='range'}
2022-05-07 22:45:54,388 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 22:45:54,388 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 22:45:54,391 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.def5526b-974d-4baf-8300-0c7e07959681-2, groupId=anonymous.def5526b-974d-4baf-8300-0c7e07959681] Setting offset for partition BIDS_PLACED_BY_BUYER-0 to the committed offset FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}
2022-05-07 22:45:54,392 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.def5526b-974d-4baf-8300-0c7e07959681: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 22:49:11,162 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-05-07 22:54:48,084 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Starting EauctionHouseListingServiceApplication using Java 15.0.1 on DESKTOP-UP4G20T with PID 12456 (D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service\build\classes\java\main started by supra in D:\Work\HackFSE-2022-v1\project-repo\eauction-house\eauction-house-listing-service)
2022-05-07 22:54:48,085 INFO org.hibernate.validator.internal.util.Version [background-preinit] HV000001: Hibernate Validator 6.2.3.Final
2022-05-07 22:54:48,086 INFO org.springframework.boot.SpringApplication [restartedMain] The following 1 profile is active: "dev"
2022-05-07 22:54:48,127 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Fetching config from server at : http://localhost:8888
2022-05-07 22:54:48,127 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Located environment: name=listing, profiles=[dev], label=null, version=null, state=null
2022-05-07 22:54:48,128 INFO org.springframework.boot.logging.DeferredLog [restartedMain] Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable
2022-05-07 22:54:48,130 INFO org.springframework.boot.logging.DeferredLog [restartedMain] For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'
2022-05-07 22:54:48,731 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2022-05-07 22:54:48,869 INFO org.springframework.data.repository.config.RepositoryConfigurationDelegate [restartedMain] Finished Spring Data repository scanning in 132 ms. Found 5 MongoDB repository interfaces.
2022-05-07 22:54:49,043 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2022-05-07 22:54:49,056 INFO org.springframework.core.log.LogAccessor [restartedMain] No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2022-05-07 22:54:49,140 INFO org.springframework.cloud.context.scope.GenericScope [restartedMain] BeanFactory id=0f1c726b-3659-3469-99f7-73c389402831
2022-05-07 22:54:49,215 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'integrationChannelResolver' of type [org.springframework.integration.support.channel.BeanFactoryChannelResolver] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 22:54:49,284 INFO org.springframework.context.support.PostProcessorRegistrationDelegate$BeanPostProcessorChecker [restartedMain] Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-05-07 22:54:49,774 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat initialized with port(s): 8060 (http)
2022-05-07 22:54:49,786 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing ProtocolHandler ["http-nio-8060"]
2022-05-07 22:54:49,786 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting service [Tomcat]
2022-05-07 22:54:49,786 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.62]
2022-05-07 22:54:49,897 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Initializing Spring embedded WebApplicationContext
2022-05-07 22:54:49,897 INFO org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext [restartedMain] Root WebApplicationContext: initialization completed in 1767 ms
2022-05-07 22:54:50,031 INFO com.mongodb.diagnostics.logging.SLF4JLogger [restartedMain] Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2022-05-07 22:54:50,086 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-rtt-ClusterId{value='6276ab62c6b3424dbb173c90', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:38}] to localhost:27017
2022-05-07 22:54:50,086 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276ab62c6b3424dbb173c90', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:37}] to localhost:27017
2022-05-07 22:54:50,087 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='6276ab62c6b3424dbb173c90', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=20116800}
2022-05-07 22:54:50,123 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 22:54:50,171 WARN org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer [restartedMain] Unable to start LiveReload server
2022-05-07 22:54:50,208 WARN org.springframework.data.convert.CustomConversions [restartedMain] Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type! You might want to check your annotation setup at the converter implementation.
2022-05-07 22:54:50,871 INFO org.springframework.cloud.netflix.eureka.config.DiscoveryClientOptionalArgsConfiguration [restartedMain] Eureka HTTP Client uses RestTemplate.
2022-05-07 22:54:51,004 WARN org.springframework.cloud.loadbalancer.config.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger [restartedMain] Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-05-07 22:54:51,020 INFO org.springframework.cloud.stream.function.FunctionConfiguration$FunctionBindingRegistrar [restartedMain] Functional binding is disabled due to the presense of @EnableBinding annotation in your configuration
2022-05-07 22:54:51,117 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.input' has 1 subscriber(s).
2022-05-07 22:54:51,117 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.bidinput' has 1 subscriber(s).
2022-05-07 22:54:51,119 INFO org.springframework.core.log.LogAccessor [restartedMain] Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2022-05-07 22:54:51,120 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'listing.errorChannel' has 1 subscriber(s).
2022-05-07 22:54:51,120 INFO org.springframework.core.log.LogAccessor [restartedMain] started bean '_org.springframework.integration.errorLogger'
2022-05-07 22:54:51,126 INFO org.springframework.cloud.netflix.eureka.InstanceInfoFactory [restartedMain] Setting initial instance status as: STARTING
2022-05-07 22:54:51,244 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Initializing Eureka in region default
2022-05-07 22:54:51,249 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [restartedMain] Resolving eureka endpoints via configuration
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Disable delta property : false
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Single vip registry refresh property : null
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Force full registry fetch : false
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application is null : false
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Registered Applications size is zero : true
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Application version is -1: true
2022-05-07 22:54:51,284 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Getting all instance registry info from the eureka server
2022-05-07 22:54:51,514 INFO com.netflix.discovery.DiscoveryClient [restartedMain] The response status is 200
2022-05-07 22:54:51,520 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Starting heartbeat executor: renew interval is: 30
2022-05-07 22:54:51,528 INFO com.netflix.discovery.InstanceInfoReplicator [restartedMain] InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-05-07 22:54:51,543 INFO com.netflix.discovery.DiscoveryClient [restartedMain] Discovery Client initialized at timestamp 1651944291542 with initial instances count: 6
2022-05-07 22:54:51,544 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry [restartedMain] Registering application LISTING with eureka with status UP
2022-05-07 22:54:51,544 INFO com.netflix.discovery.DiscoveryClient$3 [restartedMain] Saw local status change event StatusChangeEvent [timestamp=1651944291544, current=UP, previous=STARTING]
2022-05-07 22:54:51,545 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060: registering service...
2022-05-07 22:54:51,546 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: ktable
2022-05-07 22:54:51,611 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: ktable
2022-05-07 22:54:51,611 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 22:54:51,611 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kafka
2022-05-07 22:54:51,648 INFO com.netflix.discovery.DiscoveryClient [DiscoveryClient-InstanceInfoReplicator-0] DiscoveryClient_LISTING/DESKTOP-UP4G20T:listing:8060 - registration status: 204
2022-05-07 22:54:51,659 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kafka
2022-05-07 22:54:51,659 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 22:54:51,659 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: kstream
2022-05-07 22:54:51,673 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: kstream
2022-05-07 22:54:51,674 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 22:54:51,674 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Creating binder: globalktable
2022-05-07 22:54:51,698 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Caching the binder: globalktable
2022-05-07 22:54:51,698 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 22:54:51,698 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 22:54:51,753 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 22:54:51,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:51,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:51,831 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944291830
2022-05-07 22:54:52,204 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-1] App info kafka.admin.client for adminclient-1 unregistered
2022-05-07 22:54:52,206 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics scheduler closed
2022-05-07 22:54:52,206 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 22:54:52,206 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-1] Metrics reporters closed
2022-05-07 22:54:52,218 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 22:54:52,250 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:52,250 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:52,250 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944292250
2022-05-07 22:54:52,257 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-1, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 22:54:52,258 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-1, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 22:54:52,258 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-1, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 22:54:52,258 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 22:54:52,258 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 22:54:52,258 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 22:54:52,260 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-1 unregistered
2022-05-07 22:54:52,289 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc.errors' has 1 subscriber(s).
2022-05-07 22:54:52,289 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc.errors' has 0 subscriber(s).
2022-05-07 22:54:52,289 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc.errors' has 1 subscriber(s).
2022-05-07 22:54:52,289 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'BIDS_PLACED_BY_BUYER.anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc.errors' has 2 subscriber(s).
2022-05-07 22:54:52,306 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 22:54:52,312 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:52,312 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:52,312 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944292312
2022-05-07 22:54:52,313 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Subscribed to topic(s): BIDS_PLACED_BY_BUYER
2022-05-07 22:54:52,316 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@1c44f0a4
2022-05-07 22:54:52,317 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: ktable
2022-05-07 22:54:52,317 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 22:54:52,317 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kstream
2022-05-07 22:54:52,317 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: globalktable
2022-05-07 22:54:52,317 INFO org.springframework.cloud.stream.binder.DefaultBinderFactory [restartedMain] Retrieving cached binder: kafka
2022-05-07 22:54:52,318 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2022-05-07 22:54:52,322 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:52,322 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:52,322 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944292322
2022-05-07 22:54:52,323 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Resetting the last seen epoch of partition BIDS_PLACED_BY_BUYER-0 to 0 since the associated topicId changed from null to 8RUW1brkRPikwmd5IUILqA
2022-05-07 22:54:52,323 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 22:54:52,324 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:54:52,326 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] (Re-)joining group
2022-05-07 22:54:52,333 INFO org.apache.kafka.common.utils.AppInfoParser [kafka-admin-client-thread | adminclient-2] App info kafka.admin.client for adminclient-2 unregistered
2022-05-07 22:54:52,334 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics scheduler closed
2022-05-07 22:54:52,335 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 22:54:52,335 INFO org.apache.kafka.common.metrics.Metrics [kafka-admin-client-thread | adminclient-2] Metrics reporters closed
2022-05-07 22:54:52,335 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 22:54:52,337 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Request joining group due to: need to re-join with the given member-id
2022-05-07 22:54:52,339 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] (Re-)joining group
2022-05-07 22:54:52,341 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:52,341 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2-dd8f42c0-3aab-405d-83dd-ddbd9b35352e', protocol='range'}
2022-05-07 22:54:52,341 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:52,341 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944292341
2022-05-07 22:54:52,343 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Finished assignment for group at generation 1: {consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2-dd8f42c0-3aab-405d-83dd-ddbd9b35352e=Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])}
2022-05-07 22:54:52,345 INFO org.apache.kafka.clients.Metadata [restartedMain] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-3, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 22:54:52,345 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-3, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Resetting generation due to: consumer pro-actively leaving the group
2022-05-07 22:54:52,346 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [restartedMain] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-3, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Request joining group due to: consumer pro-actively leaving the group
2022-05-07 22:54:52,346 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics scheduler closed
2022-05-07 22:54:52,346 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2022-05-07 22:54:52,346 INFO org.apache.kafka.common.metrics.Metrics [restartedMain] Metrics reporters closed
2022-05-07 22:54:52,347 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] App info kafka.consumer for consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-3 unregistered
2022-05-07 22:54:52,348 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518.errors' has 1 subscriber(s).
2022-05-07 22:54:52,349 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518.errors' has 0 subscriber(s).
2022-05-07 22:54:52,349 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518.errors' has 1 subscriber(s).
2022-05-07 22:54:52,349 INFO org.springframework.core.log.LogAccessor [restartedMain] Channel 'PRODUCTS_ON_AUCTION.anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518.errors' has 2 subscriber(s).
2022-05-07 22:54:52,350 INFO org.apache.kafka.common.config.AbstractConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2022-05-07 22:54:52,352 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2-dd8f42c0-3aab-405d-83dd-ddbd9b35352e', protocol='range'}
2022-05-07 22:54:52,353 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Notifying assignor about the new Assignment(partitions=[BIDS_PLACED_BY_BUYER-0])
2022-05-07 22:54:52,354 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka version: 3.0.1
2022-05-07 22:54:52,355 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka commitId: 8e30984f43e64d8b
2022-05-07 22:54:52,355 INFO org.apache.kafka.common.utils.AppInfoParser$AppInfo [restartedMain] Kafka startTimeMs: 1651944292354
2022-05-07 22:54:52,355 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Subscribed to topic(s): PRODUCTS_ON_AUCTION
2022-05-07 22:54:52,355 INFO org.springframework.core.log.LogAccessor [restartedMain] started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@2f47a5b6
2022-05-07 22:54:52,355 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Adding newly assigned partitions: BIDS_PLACED_BY_BUYER-0
2022-05-07 22:54:52,356 INFO org.apache.juli.logging.DirectJDKLog [restartedMain] Starting ProtocolHandler ["http-nio-8060"]
2022-05-07 22:54:52,360 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Resetting the last seen epoch of partition PRODUCTS_ON_AUCTION-0 to 0 since the associated topicId changed from null to dpooxllMSyGxqYtu52bpZg
2022-05-07 22:54:52,360 INFO org.apache.kafka.clients.Metadata [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Cluster ID: Fg-suBJLRSO0cNl9srhg1A
2022-05-07 22:54:52,360 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Discovered group coordinator DESKTOP-UP4G20T:9092 (id: 2147483647 rack: null)
2022-05-07 22:54:52,360 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 22:54:52,363 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] (Re-)joining group
2022-05-07 22:54:52,370 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Request joining group due to: need to re-join with the given member-id
2022-05-07 22:54:52,370 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Found no committed offset for partition BIDS_PLACED_BY_BUYER-0
2022-05-07 22:54:52,371 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] (Re-)joining group
2022-05-07 22:54:52,374 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Successfully joined group with generation Generation{generationId=1, memberId='consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4-9329ed3c-4192-4cf9-8c83-54518073851f', protocol='range'}
2022-05-07 22:54:52,374 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Finished assignment for group at generation 1: {consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4-9329ed3c-4192-4cf9-8c83-54518073851f=Assignment(partitions=[PRODUCTS_ON_AUCTION-0])}
2022-05-07 22:54:52,377 INFO org.springframework.boot.web.embedded.tomcat.TomcatWebServer [restartedMain] Tomcat started on port(s): 8060 (http) with context path ''
2022-05-07 22:54:52,378 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Successfully synced group in generation Generation{generationId=1, memberId='consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4-9329ed3c-4192-4cf9-8c83-54518073851f', protocol='range'}
2022-05-07 22:54:52,378 INFO org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration [restartedMain] Updating port to 8060
2022-05-07 22:54:52,379 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Notifying assignor about the new Assignment(partitions=[PRODUCTS_ON_AUCTION-0])
2022-05-07 22:54:52,379 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Adding newly assigned partitions: PRODUCTS_ON_AUCTION-0
2022-05-07 22:54:52,380 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 22:54:52,381 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetFetchResponseHandler [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Found no committed offset for partition PRODUCTS_ON_AUCTION-0
2022-05-07 22:54:52,385 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518-4, groupId=anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518] Resetting offset for partition PRODUCTS_ON_AUCTION-0 to position FetchPosition{offset=15, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 22:54:52,385 INFO org.apache.kafka.clients.consumer.internals.SubscriptionState [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] [Consumer clientId=consumer-anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc-2, groupId=anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc] Resetting offset for partition BIDS_PLACED_BY_BUYER-0 to position FetchPosition{offset=23, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-UP4G20T:9092 (id: 0 rack: null)], epoch=0}}.
2022-05-07 22:54:52,394 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] anonymous.89f3cb2e-12db-4506-8745-1ecd5507c518: partitions assigned: [PRODUCTS_ON_AUCTION-0]
2022-05-07 22:54:52,394 INFO org.springframework.core.log.LogAccessor [KafkaConsumerDestination{consumerDestinationName='BIDS_PLACED_BY_BUYER', partitions=1, dlqName='null'}.container-0-C-1] anonymous.04e3af7c-9946-4383-a0d3-51ffce5f14cc: partitions assigned: [BIDS_PLACED_BY_BUYER-0]
2022-05-07 22:54:52,460 INFO org.springframework.boot.StartupInfoLogger [restartedMain] Started EauctionHouseListingServiceApplication in 5.809 seconds (JVM running for 6.388)
2022-05-07 22:55:03,940 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic DELETE
2022-05-07 22:55:03,954 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Product obtained from topic to delete ProductCommand [productId=41, productName=null, shortDescription=null, detailedDescription=null, category=null, startingPrice=null, bidEndDate=null, sellerId=null]
2022-05-07 22:55:04,082 INFO com.mongodb.diagnostics.logging.SLF4JLogger [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] Opened connection [connectionId{localValue:3, serverValue:39}] to localhost:27017
2022-05-07 22:55:04,119 INFO com.cts.eauction.microservices.listing.EauctionHouseListingServiceApplication [KafkaConsumerDestination{consumerDestinationName='PRODUCTS_ON_AUCTION', partitions=1, dlqName='null'}.container-0-C-1] No Of records deleted 1
